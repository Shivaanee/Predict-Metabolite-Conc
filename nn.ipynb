{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "To predict the 6 analytes using the given spectral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "target = pd.read_csv('data/target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# convert array back to dataframe\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2790</th>\n",
       "      <th>2791</th>\n",
       "      <th>2792</th>\n",
       "      <th>2793</th>\n",
       "      <th>2794</th>\n",
       "      <th>2795</th>\n",
       "      <th>2796</th>\n",
       "      <th>2797</th>\n",
       "      <th>2798</th>\n",
       "      <th>2799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.316769</td>\n",
       "      <td>-0.315116</td>\n",
       "      <td>-0.313438</td>\n",
       "      <td>-0.311752</td>\n",
       "      <td>-0.310101</td>\n",
       "      <td>-0.308489</td>\n",
       "      <td>-0.306886</td>\n",
       "      <td>-0.305345</td>\n",
       "      <td>-0.303805</td>\n",
       "      <td>-0.302371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.308729</td>\n",
       "      <td>0.309938</td>\n",
       "      <td>0.311335</td>\n",
       "      <td>0.312953</td>\n",
       "      <td>0.314581</td>\n",
       "      <td>0.316054</td>\n",
       "      <td>0.316725</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>0.316769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.392352</td>\n",
       "      <td>-0.390931</td>\n",
       "      <td>-0.389515</td>\n",
       "      <td>-0.388140</td>\n",
       "      <td>-0.386799</td>\n",
       "      <td>-0.385506</td>\n",
       "      <td>-0.384272</td>\n",
       "      <td>-0.383046</td>\n",
       "      <td>-0.381832</td>\n",
       "      <td>-0.380493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393738</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.393555</td>\n",
       "      <td>0.393591</td>\n",
       "      <td>0.393748</td>\n",
       "      <td>0.393820</td>\n",
       "      <td>0.393732</td>\n",
       "      <td>0.393476</td>\n",
       "      <td>0.392953</td>\n",
       "      <td>0.392352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.395732</td>\n",
       "      <td>-0.394205</td>\n",
       "      <td>-0.392682</td>\n",
       "      <td>-0.391210</td>\n",
       "      <td>-0.389802</td>\n",
       "      <td>-0.388441</td>\n",
       "      <td>-0.387181</td>\n",
       "      <td>-0.385971</td>\n",
       "      <td>-0.384794</td>\n",
       "      <td>-0.383556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385905</td>\n",
       "      <td>0.386156</td>\n",
       "      <td>0.386736</td>\n",
       "      <td>0.387808</td>\n",
       "      <td>0.389403</td>\n",
       "      <td>0.391396</td>\n",
       "      <td>0.393625</td>\n",
       "      <td>0.394835</td>\n",
       "      <td>0.395313</td>\n",
       "      <td>0.395732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.353691</td>\n",
       "      <td>-0.351974</td>\n",
       "      <td>-0.350242</td>\n",
       "      <td>-0.348509</td>\n",
       "      <td>-0.346777</td>\n",
       "      <td>-0.345091</td>\n",
       "      <td>-0.343411</td>\n",
       "      <td>-0.341739</td>\n",
       "      <td>-0.340078</td>\n",
       "      <td>-0.338397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353261</td>\n",
       "      <td>0.352495</td>\n",
       "      <td>0.351930</td>\n",
       "      <td>0.351762</td>\n",
       "      <td>0.352015</td>\n",
       "      <td>0.352671</td>\n",
       "      <td>0.353454</td>\n",
       "      <td>0.353844</td>\n",
       "      <td>0.353813</td>\n",
       "      <td>0.353691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.388814</td>\n",
       "      <td>-0.387189</td>\n",
       "      <td>-0.385506</td>\n",
       "      <td>-0.383811</td>\n",
       "      <td>-0.382188</td>\n",
       "      <td>-0.380599</td>\n",
       "      <td>-0.379026</td>\n",
       "      <td>-0.377480</td>\n",
       "      <td>-0.375925</td>\n",
       "      <td>-0.374382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377174</td>\n",
       "      <td>0.378062</td>\n",
       "      <td>0.379091</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.382271</td>\n",
       "      <td>0.384355</td>\n",
       "      <td>0.386594</td>\n",
       "      <td>0.387837</td>\n",
       "      <td>0.388371</td>\n",
       "      <td>0.388814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.216063</td>\n",
       "      <td>1.212980</td>\n",
       "      <td>1.209800</td>\n",
       "      <td>1.206363</td>\n",
       "      <td>1.202908</td>\n",
       "      <td>1.199597</td>\n",
       "      <td>1.196533</td>\n",
       "      <td>1.193830</td>\n",
       "      <td>1.191242</td>\n",
       "      <td>1.188586</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.198214</td>\n",
       "      <td>-1.201348</td>\n",
       "      <td>-1.203690</td>\n",
       "      <td>-1.206748</td>\n",
       "      <td>-1.211088</td>\n",
       "      <td>-1.216074</td>\n",
       "      <td>-1.220527</td>\n",
       "      <td>-1.222032</td>\n",
       "      <td>-1.219498</td>\n",
       "      <td>-1.216063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.405710</td>\n",
       "      <td>1.402492</td>\n",
       "      <td>1.399350</td>\n",
       "      <td>1.396283</td>\n",
       "      <td>1.393269</td>\n",
       "      <td>1.390305</td>\n",
       "      <td>1.387590</td>\n",
       "      <td>1.385171</td>\n",
       "      <td>1.382781</td>\n",
       "      <td>1.380179</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.399635</td>\n",
       "      <td>-1.401556</td>\n",
       "      <td>-1.402483</td>\n",
       "      <td>-1.403973</td>\n",
       "      <td>-1.406681</td>\n",
       "      <td>-1.409943</td>\n",
       "      <td>-1.412725</td>\n",
       "      <td>-1.413162</td>\n",
       "      <td>-1.409897</td>\n",
       "      <td>-1.405710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.452745</td>\n",
       "      <td>1.448847</td>\n",
       "      <td>1.445136</td>\n",
       "      <td>1.441636</td>\n",
       "      <td>1.438428</td>\n",
       "      <td>1.435438</td>\n",
       "      <td>1.432754</td>\n",
       "      <td>1.430351</td>\n",
       "      <td>1.427990</td>\n",
       "      <td>1.425488</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.458494</td>\n",
       "      <td>-1.459141</td>\n",
       "      <td>-1.458486</td>\n",
       "      <td>-1.458382</td>\n",
       "      <td>-1.459472</td>\n",
       "      <td>-1.461106</td>\n",
       "      <td>-1.462207</td>\n",
       "      <td>-1.461516</td>\n",
       "      <td>-1.457577</td>\n",
       "      <td>-1.452745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.370582</td>\n",
       "      <td>1.367806</td>\n",
       "      <td>1.365097</td>\n",
       "      <td>1.362142</td>\n",
       "      <td>1.359241</td>\n",
       "      <td>1.356519</td>\n",
       "      <td>1.354035</td>\n",
       "      <td>1.351736</td>\n",
       "      <td>1.349495</td>\n",
       "      <td>1.346956</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.392243</td>\n",
       "      <td>-1.392203</td>\n",
       "      <td>-1.390443</td>\n",
       "      <td>-1.388581</td>\n",
       "      <td>-1.387419</td>\n",
       "      <td>-1.386407</td>\n",
       "      <td>-1.384495</td>\n",
       "      <td>-1.381759</td>\n",
       "      <td>-1.376632</td>\n",
       "      <td>-1.370582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.325771</td>\n",
       "      <td>1.323243</td>\n",
       "      <td>1.320700</td>\n",
       "      <td>1.317872</td>\n",
       "      <td>1.315010</td>\n",
       "      <td>1.312265</td>\n",
       "      <td>1.309711</td>\n",
       "      <td>1.307378</td>\n",
       "      <td>1.305048</td>\n",
       "      <td>1.302498</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.325033</td>\n",
       "      <td>-1.327913</td>\n",
       "      <td>-1.329253</td>\n",
       "      <td>-1.330607</td>\n",
       "      <td>-1.332570</td>\n",
       "      <td>-1.334584</td>\n",
       "      <td>-1.335659</td>\n",
       "      <td>-1.334793</td>\n",
       "      <td>-1.330737</td>\n",
       "      <td>-1.325771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 2800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0   -0.316769 -0.315116 -0.313438 -0.311752 -0.310101 -0.308489 -0.306886   \n",
       "1   -0.392352 -0.390931 -0.389515 -0.388140 -0.386799 -0.385506 -0.384272   \n",
       "2   -0.395732 -0.394205 -0.392682 -0.391210 -0.389802 -0.388441 -0.387181   \n",
       "3   -0.353691 -0.351974 -0.350242 -0.348509 -0.346777 -0.345091 -0.343411   \n",
       "4   -0.388814 -0.387189 -0.385506 -0.383811 -0.382188 -0.380599 -0.379026   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  1.216063  1.212980  1.209800  1.206363  1.202908  1.199597  1.196533   \n",
       "177  1.405710  1.402492  1.399350  1.396283  1.393269  1.390305  1.387590   \n",
       "178  1.452745  1.448847  1.445136  1.441636  1.438428  1.435438  1.432754   \n",
       "179  1.370582  1.367806  1.365097  1.362142  1.359241  1.356519  1.354035   \n",
       "180  1.325771  1.323243  1.320700  1.317872  1.315010  1.312265  1.309711   \n",
       "\n",
       "         7         8         9     ...      2790      2791      2792  \\\n",
       "0   -0.305345 -0.303805 -0.302371  ...  0.307467  0.308729  0.309938   \n",
       "1   -0.383046 -0.381832 -0.380493  ...  0.393738  0.393679  0.393555   \n",
       "2   -0.385971 -0.384794 -0.383556  ...  0.385905  0.386156  0.386736   \n",
       "3   -0.341739 -0.340078 -0.338397  ...  0.353261  0.352495  0.351930   \n",
       "4   -0.377480 -0.375925 -0.374382  ...  0.377174  0.378062  0.379091   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  1.193830  1.191242  1.188586  ... -1.198214 -1.201348 -1.203690   \n",
       "177  1.385171  1.382781  1.380179  ... -1.399635 -1.401556 -1.402483   \n",
       "178  1.430351  1.427990  1.425488  ... -1.458494 -1.459141 -1.458486   \n",
       "179  1.351736  1.349495  1.346956  ... -1.392243 -1.392203 -1.390443   \n",
       "180  1.307378  1.305048  1.302498  ... -1.325033 -1.327913 -1.329253   \n",
       "\n",
       "         2793      2794      2795      2796      2797      2798      2799  \n",
       "0    0.311335  0.312953  0.314581  0.316054  0.316725  0.316783  0.316769  \n",
       "1    0.393591  0.393748  0.393820  0.393732  0.393476  0.392953  0.392352  \n",
       "2    0.387808  0.389403  0.391396  0.393625  0.394835  0.395313  0.395732  \n",
       "3    0.351762  0.352015  0.352671  0.353454  0.353844  0.353813  0.353691  \n",
       "4    0.380494  0.382271  0.384355  0.386594  0.387837  0.388371  0.388814  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "176 -1.206748 -1.211088 -1.216074 -1.220527 -1.222032 -1.219498 -1.216063  \n",
       "177 -1.403973 -1.406681 -1.409943 -1.412725 -1.413162 -1.409897 -1.405710  \n",
       "178 -1.458382 -1.459472 -1.461106 -1.462207 -1.461516 -1.457577 -1.452745  \n",
       "179 -1.388581 -1.387419 -1.386407 -1.384495 -1.381759 -1.376632 -1.370582  \n",
       "180 -1.330607 -1.332570 -1.334584 -1.335659 -1.334793 -1.330737 -1.325771  \n",
       "\n",
       "[181 rows x 2800 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the columns (the wavelengths) are not necessary or useful in prediction, so doesn't matter if renamed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2790</th>\n",
       "      <th>2791</th>\n",
       "      <th>2792</th>\n",
       "      <th>2793</th>\n",
       "      <th>2794</th>\n",
       "      <th>2795</th>\n",
       "      <th>2796</th>\n",
       "      <th>2797</th>\n",
       "      <th>2798</th>\n",
       "      <th>2799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.294132</td>\n",
       "      <td>-0.292470</td>\n",
       "      <td>-0.290753</td>\n",
       "      <td>-0.289059</td>\n",
       "      <td>-0.287421</td>\n",
       "      <td>-0.285885</td>\n",
       "      <td>-0.284432</td>\n",
       "      <td>-0.283031</td>\n",
       "      <td>-0.281643</td>\n",
       "      <td>-0.280298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276976</td>\n",
       "      <td>0.278672</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>0.282665</td>\n",
       "      <td>0.285239</td>\n",
       "      <td>0.288108</td>\n",
       "      <td>0.291088</td>\n",
       "      <td>0.292727</td>\n",
       "      <td>0.293466</td>\n",
       "      <td>0.294132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.284122</td>\n",
       "      <td>-0.282493</td>\n",
       "      <td>-0.280881</td>\n",
       "      <td>-0.279314</td>\n",
       "      <td>-0.277783</td>\n",
       "      <td>-0.276313</td>\n",
       "      <td>-0.274894</td>\n",
       "      <td>-0.273518</td>\n",
       "      <td>-0.272146</td>\n",
       "      <td>-0.270753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287967</td>\n",
       "      <td>0.288118</td>\n",
       "      <td>0.287882</td>\n",
       "      <td>0.287565</td>\n",
       "      <td>0.287224</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>0.285740</td>\n",
       "      <td>0.284973</td>\n",
       "      <td>0.284122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.306980</td>\n",
       "      <td>-0.305355</td>\n",
       "      <td>-0.303725</td>\n",
       "      <td>-0.302108</td>\n",
       "      <td>-0.300526</td>\n",
       "      <td>-0.299003</td>\n",
       "      <td>-0.297521</td>\n",
       "      <td>-0.296112</td>\n",
       "      <td>-0.294748</td>\n",
       "      <td>-0.293489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290890</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.294566</td>\n",
       "      <td>0.296723</td>\n",
       "      <td>0.299148</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.304602</td>\n",
       "      <td>0.305979</td>\n",
       "      <td>0.306527</td>\n",
       "      <td>0.306980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.283304</td>\n",
       "      <td>-0.281756</td>\n",
       "      <td>-0.280143</td>\n",
       "      <td>-0.278480</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.275329</td>\n",
       "      <td>-0.273899</td>\n",
       "      <td>-0.272542</td>\n",
       "      <td>-0.271209</td>\n",
       "      <td>-0.269888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272093</td>\n",
       "      <td>0.273169</td>\n",
       "      <td>0.274347</td>\n",
       "      <td>0.275795</td>\n",
       "      <td>0.277602</td>\n",
       "      <td>0.279657</td>\n",
       "      <td>0.281763</td>\n",
       "      <td>0.282801</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.283304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.276594</td>\n",
       "      <td>-0.275093</td>\n",
       "      <td>-0.273528</td>\n",
       "      <td>-0.271935</td>\n",
       "      <td>-0.270347</td>\n",
       "      <td>-0.268851</td>\n",
       "      <td>-0.267408</td>\n",
       "      <td>-0.266029</td>\n",
       "      <td>-0.264725</td>\n",
       "      <td>-0.263381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298471</td>\n",
       "      <td>0.296658</td>\n",
       "      <td>0.294318</td>\n",
       "      <td>0.291676</td>\n",
       "      <td>0.288821</td>\n",
       "      <td>0.285722</td>\n",
       "      <td>0.282349</td>\n",
       "      <td>0.280222</td>\n",
       "      <td>0.278439</td>\n",
       "      <td>0.276594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.287983</td>\n",
       "      <td>1.285159</td>\n",
       "      <td>1.282166</td>\n",
       "      <td>1.279110</td>\n",
       "      <td>1.276117</td>\n",
       "      <td>1.273214</td>\n",
       "      <td>1.270348</td>\n",
       "      <td>1.267523</td>\n",
       "      <td>1.264811</td>\n",
       "      <td>1.262283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.271121</td>\n",
       "      <td>-1.273053</td>\n",
       "      <td>-1.275304</td>\n",
       "      <td>-1.277644</td>\n",
       "      <td>-1.279920</td>\n",
       "      <td>-1.282017</td>\n",
       "      <td>-1.283961</td>\n",
       "      <td>-1.285168</td>\n",
       "      <td>-1.286476</td>\n",
       "      <td>-1.287983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.303077</td>\n",
       "      <td>-0.301640</td>\n",
       "      <td>-0.300190</td>\n",
       "      <td>-0.298733</td>\n",
       "      <td>-0.297363</td>\n",
       "      <td>-0.296033</td>\n",
       "      <td>-0.294755</td>\n",
       "      <td>-0.293592</td>\n",
       "      <td>-0.292444</td>\n",
       "      <td>-0.291202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288615</td>\n",
       "      <td>0.290797</td>\n",
       "      <td>0.292942</td>\n",
       "      <td>0.295185</td>\n",
       "      <td>0.297425</td>\n",
       "      <td>0.299608</td>\n",
       "      <td>0.301592</td>\n",
       "      <td>0.302569</td>\n",
       "      <td>0.302859</td>\n",
       "      <td>0.303077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.113718</td>\n",
       "      <td>0.112752</td>\n",
       "      <td>0.111822</td>\n",
       "      <td>0.110825</td>\n",
       "      <td>0.109820</td>\n",
       "      <td>0.108743</td>\n",
       "      <td>0.107677</td>\n",
       "      <td>0.106608</td>\n",
       "      <td>0.105618</td>\n",
       "      <td>0.104834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096473</td>\n",
       "      <td>-0.099153</td>\n",
       "      <td>-0.101798</td>\n",
       "      <td>-0.104224</td>\n",
       "      <td>-0.106403</td>\n",
       "      <td>-0.108327</td>\n",
       "      <td>-0.110121</td>\n",
       "      <td>-0.111282</td>\n",
       "      <td>-0.112436</td>\n",
       "      <td>-0.113718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.370582</td>\n",
       "      <td>1.367806</td>\n",
       "      <td>1.365097</td>\n",
       "      <td>1.362142</td>\n",
       "      <td>1.359241</td>\n",
       "      <td>1.356519</td>\n",
       "      <td>1.354035</td>\n",
       "      <td>1.351736</td>\n",
       "      <td>1.349495</td>\n",
       "      <td>1.346956</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.392243</td>\n",
       "      <td>-1.392203</td>\n",
       "      <td>-1.390443</td>\n",
       "      <td>-1.388581</td>\n",
       "      <td>-1.387419</td>\n",
       "      <td>-1.386407</td>\n",
       "      <td>-1.384495</td>\n",
       "      <td>-1.381759</td>\n",
       "      <td>-1.376632</td>\n",
       "      <td>-1.370582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.133316</td>\n",
       "      <td>1.131173</td>\n",
       "      <td>1.128736</td>\n",
       "      <td>1.126225</td>\n",
       "      <td>1.123589</td>\n",
       "      <td>1.120866</td>\n",
       "      <td>1.118060</td>\n",
       "      <td>1.115063</td>\n",
       "      <td>1.112002</td>\n",
       "      <td>1.108749</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.103224</td>\n",
       "      <td>-1.106446</td>\n",
       "      <td>-1.110065</td>\n",
       "      <td>-1.113933</td>\n",
       "      <td>-1.117837</td>\n",
       "      <td>-1.121837</td>\n",
       "      <td>-1.126073</td>\n",
       "      <td>-1.128687</td>\n",
       "      <td>-1.130907</td>\n",
       "      <td>-1.133316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "65  -0.294132 -0.292470 -0.290753 -0.289059 -0.287421 -0.285885 -0.284432   \n",
       "67  -0.284122 -0.282493 -0.280881 -0.279314 -0.277783 -0.276313 -0.274894   \n",
       "31  -0.306980 -0.305355 -0.303725 -0.302108 -0.300526 -0.299003 -0.297521   \n",
       "12  -0.283304 -0.281756 -0.280143 -0.278480 -0.276874 -0.275329 -0.273899   \n",
       "41  -0.276594 -0.275093 -0.273528 -0.271935 -0.270347 -0.268851 -0.267408   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106  1.287983  1.285159  1.282166  1.279110  1.276117  1.273214  1.270348   \n",
       "14  -0.303077 -0.301640 -0.300190 -0.298733 -0.297363 -0.296033 -0.294755   \n",
       "92   0.113718  0.112752  0.111822  0.110825  0.109820  0.108743  0.107677   \n",
       "179  1.370582  1.367806  1.365097  1.362142  1.359241  1.356519  1.354035   \n",
       "102  1.133316  1.131173  1.128736  1.126225  1.123589  1.120866  1.118060   \n",
       "\n",
       "         7         8         9     ...      2790      2791      2792  \\\n",
       "65  -0.283031 -0.281643 -0.280298  ...  0.276976  0.278672  0.280488   \n",
       "67  -0.273518 -0.272146 -0.270753  ...  0.287967  0.288118  0.287882   \n",
       "31  -0.296112 -0.294748 -0.293489  ...  0.290890  0.292695  0.294566   \n",
       "12  -0.272542 -0.271209 -0.269888  ...  0.272093  0.273169  0.274347   \n",
       "41  -0.266029 -0.264725 -0.263381  ...  0.298471  0.296658  0.294318   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "106  1.267523  1.264811  1.262283  ... -1.271121 -1.273053 -1.275304   \n",
       "14  -0.293592 -0.292444 -0.291202  ...  0.288615  0.290797  0.292942   \n",
       "92   0.106608  0.105618  0.104834  ... -0.096473 -0.099153 -0.101798   \n",
       "179  1.351736  1.349495  1.346956  ... -1.392243 -1.392203 -1.390443   \n",
       "102  1.115063  1.112002  1.108749  ... -1.103224 -1.106446 -1.110065   \n",
       "\n",
       "         2793      2794      2795      2796      2797      2798      2799  \n",
       "65   0.282665  0.285239  0.288108  0.291088  0.292727  0.293466  0.294132  \n",
       "67   0.287565  0.287224  0.286867  0.286299  0.285740  0.284973  0.284122  \n",
       "31   0.296723  0.299148  0.301887  0.304602  0.305979  0.306527  0.306980  \n",
       "12   0.275795  0.277602  0.279657  0.281763  0.282801  0.283100  0.283304  \n",
       "41   0.291676  0.288821  0.285722  0.282349  0.280222  0.278439  0.276594  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "106 -1.277644 -1.279920 -1.282017 -1.283961 -1.285168 -1.286476 -1.287983  \n",
       "14   0.295185  0.297425  0.299608  0.301592  0.302569  0.302859  0.303077  \n",
       "92  -0.104224 -0.106403 -0.108327 -0.110121 -0.111282 -0.112436 -0.113718  \n",
       "179 -1.388581 -1.387419 -1.386407 -1.384495 -1.381759 -1.376632 -1.370582  \n",
       "102 -1.113933 -1.117837 -1.121837 -1.126073 -1.128687 -1.130907 -1.133316  \n",
       "\n",
       "[144 rows x 2800 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2790</th>\n",
       "      <th>2791</th>\n",
       "      <th>2792</th>\n",
       "      <th>2793</th>\n",
       "      <th>2794</th>\n",
       "      <th>2795</th>\n",
       "      <th>2796</th>\n",
       "      <th>2797</th>\n",
       "      <th>2798</th>\n",
       "      <th>2799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.355102</td>\n",
       "      <td>-0.353486</td>\n",
       "      <td>-0.351813</td>\n",
       "      <td>-0.350161</td>\n",
       "      <td>-0.348585</td>\n",
       "      <td>-0.347129</td>\n",
       "      <td>-0.345743</td>\n",
       "      <td>-0.344429</td>\n",
       "      <td>-0.343180</td>\n",
       "      <td>-0.341912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340416</td>\n",
       "      <td>0.341895</td>\n",
       "      <td>0.343482</td>\n",
       "      <td>0.345356</td>\n",
       "      <td>0.347572</td>\n",
       "      <td>0.350045</td>\n",
       "      <td>0.352639</td>\n",
       "      <td>0.354027</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.355102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.282375</td>\n",
       "      <td>-0.280648</td>\n",
       "      <td>-0.278907</td>\n",
       "      <td>-0.277137</td>\n",
       "      <td>-0.275392</td>\n",
       "      <td>-0.273708</td>\n",
       "      <td>-0.272107</td>\n",
       "      <td>-0.270569</td>\n",
       "      <td>-0.269033</td>\n",
       "      <td>-0.267570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297368</td>\n",
       "      <td>0.296231</td>\n",
       "      <td>0.294651</td>\n",
       "      <td>0.292879</td>\n",
       "      <td>0.291017</td>\n",
       "      <td>0.289009</td>\n",
       "      <td>0.286725</td>\n",
       "      <td>0.285213</td>\n",
       "      <td>0.283830</td>\n",
       "      <td>0.282375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2.635599</td>\n",
       "      <td>2.635815</td>\n",
       "      <td>2.636200</td>\n",
       "      <td>2.636678</td>\n",
       "      <td>2.637186</td>\n",
       "      <td>2.637641</td>\n",
       "      <td>2.637959</td>\n",
       "      <td>2.638116</td>\n",
       "      <td>2.638125</td>\n",
       "      <td>2.638064</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.634756</td>\n",
       "      <td>-2.633414</td>\n",
       "      <td>-2.632869</td>\n",
       "      <td>-2.632611</td>\n",
       "      <td>-2.632381</td>\n",
       "      <td>-2.632199</td>\n",
       "      <td>-2.632285</td>\n",
       "      <td>-2.632771</td>\n",
       "      <td>-2.634070</td>\n",
       "      <td>-2.635599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.824260</td>\n",
       "      <td>0.821456</td>\n",
       "      <td>0.818978</td>\n",
       "      <td>0.816870</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.813557</td>\n",
       "      <td>0.812046</td>\n",
       "      <td>0.810543</td>\n",
       "      <td>0.809171</td>\n",
       "      <td>0.807972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.859986</td>\n",
       "      <td>-0.854470</td>\n",
       "      <td>-0.849215</td>\n",
       "      <td>-0.844020</td>\n",
       "      <td>-0.838745</td>\n",
       "      <td>-0.833657</td>\n",
       "      <td>-0.828785</td>\n",
       "      <td>-0.826249</td>\n",
       "      <td>-0.825185</td>\n",
       "      <td>-0.824260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.015041</td>\n",
       "      <td>1.018451</td>\n",
       "      <td>1.022076</td>\n",
       "      <td>1.025791</td>\n",
       "      <td>1.029497</td>\n",
       "      <td>1.033103</td>\n",
       "      <td>1.036628</td>\n",
       "      <td>1.040053</td>\n",
       "      <td>1.043411</td>\n",
       "      <td>1.046847</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017165</td>\n",
       "      <td>-1.016343</td>\n",
       "      <td>-1.015912</td>\n",
       "      <td>-1.015459</td>\n",
       "      <td>-1.014760</td>\n",
       "      <td>-1.013998</td>\n",
       "      <td>-1.013447</td>\n",
       "      <td>-1.013470</td>\n",
       "      <td>-1.014196</td>\n",
       "      <td>-1.015041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.311459</td>\n",
       "      <td>-0.309956</td>\n",
       "      <td>-0.308470</td>\n",
       "      <td>-0.307018</td>\n",
       "      <td>-0.305663</td>\n",
       "      <td>-0.304370</td>\n",
       "      <td>-0.303054</td>\n",
       "      <td>-0.301791</td>\n",
       "      <td>-0.300531</td>\n",
       "      <td>-0.299335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303902</td>\n",
       "      <td>0.304389</td>\n",
       "      <td>0.304934</td>\n",
       "      <td>0.305798</td>\n",
       "      <td>0.307034</td>\n",
       "      <td>0.308599</td>\n",
       "      <td>0.310247</td>\n",
       "      <td>0.311081</td>\n",
       "      <td>0.311317</td>\n",
       "      <td>0.311459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.391316</td>\n",
       "      <td>-0.389854</td>\n",
       "      <td>-0.388355</td>\n",
       "      <td>-0.386846</td>\n",
       "      <td>-0.385327</td>\n",
       "      <td>-0.383907</td>\n",
       "      <td>-0.382503</td>\n",
       "      <td>-0.381139</td>\n",
       "      <td>-0.379829</td>\n",
       "      <td>-0.378499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383391</td>\n",
       "      <td>0.384632</td>\n",
       "      <td>0.385814</td>\n",
       "      <td>0.387141</td>\n",
       "      <td>0.388509</td>\n",
       "      <td>0.389851</td>\n",
       "      <td>0.390985</td>\n",
       "      <td>0.391457</td>\n",
       "      <td>0.391426</td>\n",
       "      <td>0.391316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.307925</td>\n",
       "      <td>-0.306302</td>\n",
       "      <td>-0.304696</td>\n",
       "      <td>-0.303123</td>\n",
       "      <td>-0.301648</td>\n",
       "      <td>-0.300190</td>\n",
       "      <td>-0.298805</td>\n",
       "      <td>-0.297472</td>\n",
       "      <td>-0.296194</td>\n",
       "      <td>-0.294981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297898</td>\n",
       "      <td>0.298984</td>\n",
       "      <td>0.300117</td>\n",
       "      <td>0.301462</td>\n",
       "      <td>0.303127</td>\n",
       "      <td>0.304972</td>\n",
       "      <td>0.306807</td>\n",
       "      <td>0.307662</td>\n",
       "      <td>0.307835</td>\n",
       "      <td>0.307925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.297175</td>\n",
       "      <td>-0.295772</td>\n",
       "      <td>-0.294428</td>\n",
       "      <td>-0.293066</td>\n",
       "      <td>-0.291698</td>\n",
       "      <td>-0.290370</td>\n",
       "      <td>-0.289084</td>\n",
       "      <td>-0.287829</td>\n",
       "      <td>-0.286619</td>\n",
       "      <td>-0.285454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319660</td>\n",
       "      <td>0.317251</td>\n",
       "      <td>0.314478</td>\n",
       "      <td>0.311598</td>\n",
       "      <td>0.308681</td>\n",
       "      <td>0.305740</td>\n",
       "      <td>0.302597</td>\n",
       "      <td>0.300601</td>\n",
       "      <td>0.298929</td>\n",
       "      <td>0.297175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.324047</td>\n",
       "      <td>1.320891</td>\n",
       "      <td>1.317578</td>\n",
       "      <td>1.314243</td>\n",
       "      <td>1.311018</td>\n",
       "      <td>1.307931</td>\n",
       "      <td>1.304869</td>\n",
       "      <td>1.301836</td>\n",
       "      <td>1.299072</td>\n",
       "      <td>1.296605</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.333095</td>\n",
       "      <td>-1.331216</td>\n",
       "      <td>-1.329523</td>\n",
       "      <td>-1.327962</td>\n",
       "      <td>-1.326339</td>\n",
       "      <td>-1.324890</td>\n",
       "      <td>-1.323620</td>\n",
       "      <td>-1.323171</td>\n",
       "      <td>-1.323514</td>\n",
       "      <td>-1.324047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.043058</td>\n",
       "      <td>-0.042649</td>\n",
       "      <td>-0.042349</td>\n",
       "      <td>-0.042057</td>\n",
       "      <td>-0.041766</td>\n",
       "      <td>-0.041416</td>\n",
       "      <td>-0.041089</td>\n",
       "      <td>-0.040826</td>\n",
       "      <td>-0.040622</td>\n",
       "      <td>-0.040554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071771</td>\n",
       "      <td>0.067347</td>\n",
       "      <td>0.062971</td>\n",
       "      <td>0.058871</td>\n",
       "      <td>0.055126</td>\n",
       "      <td>0.051669</td>\n",
       "      <td>0.048377</td>\n",
       "      <td>0.046426</td>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.043058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-2.130599</td>\n",
       "      <td>-2.136321</td>\n",
       "      <td>-2.142001</td>\n",
       "      <td>-2.147633</td>\n",
       "      <td>-2.153165</td>\n",
       "      <td>-2.158625</td>\n",
       "      <td>-2.164032</td>\n",
       "      <td>-2.169349</td>\n",
       "      <td>-2.174434</td>\n",
       "      <td>-2.179333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.142769</td>\n",
       "      <td>2.144785</td>\n",
       "      <td>2.145523</td>\n",
       "      <td>2.144769</td>\n",
       "      <td>2.142582</td>\n",
       "      <td>2.139368</td>\n",
       "      <td>2.135624</td>\n",
       "      <td>2.133396</td>\n",
       "      <td>2.132000</td>\n",
       "      <td>2.130599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.302385</td>\n",
       "      <td>-0.300761</td>\n",
       "      <td>-0.299060</td>\n",
       "      <td>-0.297392</td>\n",
       "      <td>-0.295759</td>\n",
       "      <td>-0.294187</td>\n",
       "      <td>-0.292654</td>\n",
       "      <td>-0.291132</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>-0.288218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297225</td>\n",
       "      <td>0.298637</td>\n",
       "      <td>0.299680</td>\n",
       "      <td>0.300593</td>\n",
       "      <td>0.301486</td>\n",
       "      <td>0.302314</td>\n",
       "      <td>0.302928</td>\n",
       "      <td>0.303056</td>\n",
       "      <td>0.302757</td>\n",
       "      <td>0.302385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.042602</td>\n",
       "      <td>1.046097</td>\n",
       "      <td>1.049645</td>\n",
       "      <td>1.053181</td>\n",
       "      <td>1.056717</td>\n",
       "      <td>1.060231</td>\n",
       "      <td>1.063713</td>\n",
       "      <td>1.067156</td>\n",
       "      <td>1.070624</td>\n",
       "      <td>1.074210</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053002</td>\n",
       "      <td>-1.050486</td>\n",
       "      <td>-1.048556</td>\n",
       "      <td>-1.046811</td>\n",
       "      <td>-1.045047</td>\n",
       "      <td>-1.043369</td>\n",
       "      <td>-1.042006</td>\n",
       "      <td>-1.041597</td>\n",
       "      <td>-1.042029</td>\n",
       "      <td>-1.042602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.295512</td>\n",
       "      <td>-0.293861</td>\n",
       "      <td>-0.292196</td>\n",
       "      <td>-0.290555</td>\n",
       "      <td>-0.288949</td>\n",
       "      <td>-0.287445</td>\n",
       "      <td>-0.286004</td>\n",
       "      <td>-0.284636</td>\n",
       "      <td>-0.283375</td>\n",
       "      <td>-0.282105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302265</td>\n",
       "      <td>0.300844</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.298380</td>\n",
       "      <td>0.297635</td>\n",
       "      <td>0.297144</td>\n",
       "      <td>0.296805</td>\n",
       "      <td>0.296547</td>\n",
       "      <td>0.296071</td>\n",
       "      <td>0.295512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.306920</td>\n",
       "      <td>-0.305128</td>\n",
       "      <td>-0.303342</td>\n",
       "      <td>-0.301641</td>\n",
       "      <td>-0.300006</td>\n",
       "      <td>-0.298441</td>\n",
       "      <td>-0.296947</td>\n",
       "      <td>-0.295537</td>\n",
       "      <td>-0.294171</td>\n",
       "      <td>-0.292817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310161</td>\n",
       "      <td>0.309765</td>\n",
       "      <td>0.309336</td>\n",
       "      <td>0.309050</td>\n",
       "      <td>0.309005</td>\n",
       "      <td>0.308928</td>\n",
       "      <td>0.308630</td>\n",
       "      <td>0.308255</td>\n",
       "      <td>0.307624</td>\n",
       "      <td>0.306920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.278903</td>\n",
       "      <td>-0.277137</td>\n",
       "      <td>-0.275327</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>-0.271788</td>\n",
       "      <td>-0.270129</td>\n",
       "      <td>-0.268531</td>\n",
       "      <td>-0.267060</td>\n",
       "      <td>-0.265643</td>\n",
       "      <td>-0.264279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279356</td>\n",
       "      <td>0.280010</td>\n",
       "      <td>0.280290</td>\n",
       "      <td>0.280419</td>\n",
       "      <td>0.280487</td>\n",
       "      <td>0.280518</td>\n",
       "      <td>0.280381</td>\n",
       "      <td>0.280104</td>\n",
       "      <td>0.279551</td>\n",
       "      <td>0.278903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.007011</td>\n",
       "      <td>-0.006555</td>\n",
       "      <td>-0.006221</td>\n",
       "      <td>-0.005950</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>-0.005384</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>-0.004327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.024290</td>\n",
       "      <td>0.020907</td>\n",
       "      <td>0.017894</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.010874</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.007011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.022560</td>\n",
       "      <td>0.022885</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.023290</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.024323</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>-0.004954</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>-0.014544</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>-0.020033</td>\n",
       "      <td>-0.022560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.269401</td>\n",
       "      <td>-0.267628</td>\n",
       "      <td>-0.265852</td>\n",
       "      <td>-0.264089</td>\n",
       "      <td>-0.262403</td>\n",
       "      <td>-0.260810</td>\n",
       "      <td>-0.259269</td>\n",
       "      <td>-0.257750</td>\n",
       "      <td>-0.256286</td>\n",
       "      <td>-0.254833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.262861</td>\n",
       "      <td>0.263794</td>\n",
       "      <td>0.264949</td>\n",
       "      <td>0.266355</td>\n",
       "      <td>0.267846</td>\n",
       "      <td>0.269143</td>\n",
       "      <td>0.269649</td>\n",
       "      <td>0.269562</td>\n",
       "      <td>0.269401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.252258</td>\n",
       "      <td>1.250115</td>\n",
       "      <td>1.247793</td>\n",
       "      <td>1.245384</td>\n",
       "      <td>1.242902</td>\n",
       "      <td>1.240403</td>\n",
       "      <td>1.237720</td>\n",
       "      <td>1.234984</td>\n",
       "      <td>1.232096</td>\n",
       "      <td>1.229042</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.246361</td>\n",
       "      <td>-1.247290</td>\n",
       "      <td>-1.248304</td>\n",
       "      <td>-1.249218</td>\n",
       "      <td>-1.249954</td>\n",
       "      <td>-1.250393</td>\n",
       "      <td>-1.250631</td>\n",
       "      <td>-1.250829</td>\n",
       "      <td>-1.251445</td>\n",
       "      <td>-1.252258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.340220</td>\n",
       "      <td>1.338327</td>\n",
       "      <td>1.336338</td>\n",
       "      <td>1.334465</td>\n",
       "      <td>1.332587</td>\n",
       "      <td>1.330704</td>\n",
       "      <td>1.328788</td>\n",
       "      <td>1.326720</td>\n",
       "      <td>1.324531</td>\n",
       "      <td>1.322221</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.329771</td>\n",
       "      <td>-1.330160</td>\n",
       "      <td>-1.330973</td>\n",
       "      <td>-1.332036</td>\n",
       "      <td>-1.333183</td>\n",
       "      <td>-1.334553</td>\n",
       "      <td>-1.336184</td>\n",
       "      <td>-1.337339</td>\n",
       "      <td>-1.338680</td>\n",
       "      <td>-1.340220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.982216</td>\n",
       "      <td>0.985589</td>\n",
       "      <td>0.989027</td>\n",
       "      <td>0.992495</td>\n",
       "      <td>0.995934</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>1.002574</td>\n",
       "      <td>1.005744</td>\n",
       "      <td>1.008968</td>\n",
       "      <td>1.012465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>-0.987004</td>\n",
       "      <td>-0.986221</td>\n",
       "      <td>-0.985336</td>\n",
       "      <td>-0.984114</td>\n",
       "      <td>-0.982767</td>\n",
       "      <td>-0.981544</td>\n",
       "      <td>-0.981173</td>\n",
       "      <td>-0.981626</td>\n",
       "      <td>-0.982216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.311672</td>\n",
       "      <td>-0.310200</td>\n",
       "      <td>-0.308715</td>\n",
       "      <td>-0.307264</td>\n",
       "      <td>-0.305858</td>\n",
       "      <td>-0.304492</td>\n",
       "      <td>-0.303156</td>\n",
       "      <td>-0.301893</td>\n",
       "      <td>-0.300633</td>\n",
       "      <td>-0.299406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288451</td>\n",
       "      <td>0.290800</td>\n",
       "      <td>0.293351</td>\n",
       "      <td>0.296289</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>0.303453</td>\n",
       "      <td>0.307365</td>\n",
       "      <td>0.309546</td>\n",
       "      <td>0.310651</td>\n",
       "      <td>0.311672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.293006</td>\n",
       "      <td>-0.291341</td>\n",
       "      <td>-0.289653</td>\n",
       "      <td>-0.287967</td>\n",
       "      <td>-0.286285</td>\n",
       "      <td>-0.284684</td>\n",
       "      <td>-0.283145</td>\n",
       "      <td>-0.281606</td>\n",
       "      <td>-0.280131</td>\n",
       "      <td>-0.278700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270372</td>\n",
       "      <td>0.272680</td>\n",
       "      <td>0.275191</td>\n",
       "      <td>0.278125</td>\n",
       "      <td>0.281475</td>\n",
       "      <td>0.285119</td>\n",
       "      <td>0.288892</td>\n",
       "      <td>0.290979</td>\n",
       "      <td>0.292029</td>\n",
       "      <td>0.293006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.885115</td>\n",
       "      <td>0.882563</td>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.877540</td>\n",
       "      <td>0.874920</td>\n",
       "      <td>0.872410</td>\n",
       "      <td>0.870097</td>\n",
       "      <td>0.868070</td>\n",
       "      <td>0.866148</td>\n",
       "      <td>0.864038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.917512</td>\n",
       "      <td>-0.916454</td>\n",
       "      <td>-0.913617</td>\n",
       "      <td>-0.910551</td>\n",
       "      <td>-0.907874</td>\n",
       "      <td>-0.905186</td>\n",
       "      <td>-0.901539</td>\n",
       "      <td>-0.897628</td>\n",
       "      <td>-0.891806</td>\n",
       "      <td>-0.885115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.300390</td>\n",
       "      <td>-0.298907</td>\n",
       "      <td>-0.297431</td>\n",
       "      <td>-0.295969</td>\n",
       "      <td>-0.294563</td>\n",
       "      <td>-0.293228</td>\n",
       "      <td>-0.291945</td>\n",
       "      <td>-0.290736</td>\n",
       "      <td>-0.289572</td>\n",
       "      <td>-0.288326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276710</td>\n",
       "      <td>0.278989</td>\n",
       "      <td>0.281532</td>\n",
       "      <td>0.284527</td>\n",
       "      <td>0.288029</td>\n",
       "      <td>0.291906</td>\n",
       "      <td>0.295952</td>\n",
       "      <td>0.298184</td>\n",
       "      <td>0.299324</td>\n",
       "      <td>0.300390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.315571</td>\n",
       "      <td>-0.313920</td>\n",
       "      <td>-0.312244</td>\n",
       "      <td>-0.310580</td>\n",
       "      <td>-0.308951</td>\n",
       "      <td>-0.307339</td>\n",
       "      <td>-0.305799</td>\n",
       "      <td>-0.304257</td>\n",
       "      <td>-0.302770</td>\n",
       "      <td>-0.301274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326986</td>\n",
       "      <td>0.326238</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.323749</td>\n",
       "      <td>0.322354</td>\n",
       "      <td>0.320878</td>\n",
       "      <td>0.319154</td>\n",
       "      <td>0.317945</td>\n",
       "      <td>0.316804</td>\n",
       "      <td>0.315571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.784769</td>\n",
       "      <td>1.786898</td>\n",
       "      <td>1.788957</td>\n",
       "      <td>1.790983</td>\n",
       "      <td>1.792974</td>\n",
       "      <td>1.794913</td>\n",
       "      <td>1.796791</td>\n",
       "      <td>1.798540</td>\n",
       "      <td>1.800246</td>\n",
       "      <td>1.802105</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.781068</td>\n",
       "      <td>-1.780773</td>\n",
       "      <td>-1.781022</td>\n",
       "      <td>-1.781357</td>\n",
       "      <td>-1.781498</td>\n",
       "      <td>-1.781549</td>\n",
       "      <td>-1.781798</td>\n",
       "      <td>-1.782299</td>\n",
       "      <td>-1.783434</td>\n",
       "      <td>-1.784769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.028007</td>\n",
       "      <td>1.025243</td>\n",
       "      <td>1.022645</td>\n",
       "      <td>1.020002</td>\n",
       "      <td>1.017313</td>\n",
       "      <td>1.014726</td>\n",
       "      <td>1.012327</td>\n",
       "      <td>1.010218</td>\n",
       "      <td>1.008186</td>\n",
       "      <td>1.005986</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.038683</td>\n",
       "      <td>-1.038212</td>\n",
       "      <td>-1.036797</td>\n",
       "      <td>-1.035974</td>\n",
       "      <td>-1.036355</td>\n",
       "      <td>-1.037335</td>\n",
       "      <td>-1.037861</td>\n",
       "      <td>-1.036885</td>\n",
       "      <td>-1.032888</td>\n",
       "      <td>-1.028007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-0.487100</td>\n",
       "      <td>-0.486026</td>\n",
       "      <td>-0.484954</td>\n",
       "      <td>-0.483942</td>\n",
       "      <td>-0.482973</td>\n",
       "      <td>-0.481994</td>\n",
       "      <td>-0.480999</td>\n",
       "      <td>-0.480051</td>\n",
       "      <td>-0.479158</td>\n",
       "      <td>-0.478353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509993</td>\n",
       "      <td>0.507287</td>\n",
       "      <td>0.504438</td>\n",
       "      <td>0.501528</td>\n",
       "      <td>0.498609</td>\n",
       "      <td>0.495626</td>\n",
       "      <td>0.492447</td>\n",
       "      <td>0.490447</td>\n",
       "      <td>0.488805</td>\n",
       "      <td>0.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.274558</td>\n",
       "      <td>-0.272970</td>\n",
       "      <td>-0.271371</td>\n",
       "      <td>-0.269774</td>\n",
       "      <td>-0.268266</td>\n",
       "      <td>-0.266871</td>\n",
       "      <td>-0.265560</td>\n",
       "      <td>-0.264335</td>\n",
       "      <td>-0.263165</td>\n",
       "      <td>-0.261902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269293</td>\n",
       "      <td>0.270468</td>\n",
       "      <td>0.271505</td>\n",
       "      <td>0.272453</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>0.274338</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>0.275233</td>\n",
       "      <td>0.274937</td>\n",
       "      <td>0.274558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-1.029213</td>\n",
       "      <td>-1.034923</td>\n",
       "      <td>-1.040618</td>\n",
       "      <td>-1.046253</td>\n",
       "      <td>-1.051790</td>\n",
       "      <td>-1.057270</td>\n",
       "      <td>-1.062724</td>\n",
       "      <td>-1.068184</td>\n",
       "      <td>-1.073584</td>\n",
       "      <td>-1.078993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033434</td>\n",
       "      <td>1.034645</td>\n",
       "      <td>1.035454</td>\n",
       "      <td>1.035526</td>\n",
       "      <td>1.034823</td>\n",
       "      <td>1.033564</td>\n",
       "      <td>1.031946</td>\n",
       "      <td>1.030893</td>\n",
       "      <td>1.030109</td>\n",
       "      <td>1.029213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-0.015992</td>\n",
       "      <td>-0.015394</td>\n",
       "      <td>-0.014927</td>\n",
       "      <td>-0.014501</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>-0.013697</td>\n",
       "      <td>-0.013297</td>\n",
       "      <td>-0.012973</td>\n",
       "      <td>-0.012751</td>\n",
       "      <td>-0.012487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044068</td>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.030289</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.015992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.293413</td>\n",
       "      <td>-0.291802</td>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.288556</td>\n",
       "      <td>-0.287001</td>\n",
       "      <td>-0.285537</td>\n",
       "      <td>-0.284146</td>\n",
       "      <td>-0.282849</td>\n",
       "      <td>-0.281577</td>\n",
       "      <td>-0.280306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271710</td>\n",
       "      <td>0.274068</td>\n",
       "      <td>0.276565</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.286127</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.291647</td>\n",
       "      <td>0.292572</td>\n",
       "      <td>0.293413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.302079</td>\n",
       "      <td>-0.300371</td>\n",
       "      <td>-0.298659</td>\n",
       "      <td>-0.297001</td>\n",
       "      <td>-0.295409</td>\n",
       "      <td>-0.293929</td>\n",
       "      <td>-0.292490</td>\n",
       "      <td>-0.291083</td>\n",
       "      <td>-0.289667</td>\n",
       "      <td>-0.288252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288581</td>\n",
       "      <td>0.290889</td>\n",
       "      <td>0.293065</td>\n",
       "      <td>0.295152</td>\n",
       "      <td>0.297166</td>\n",
       "      <td>0.299132</td>\n",
       "      <td>0.300912</td>\n",
       "      <td>0.301756</td>\n",
       "      <td>0.301964</td>\n",
       "      <td>0.302079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.352447</td>\n",
       "      <td>1.349433</td>\n",
       "      <td>1.346427</td>\n",
       "      <td>1.343414</td>\n",
       "      <td>1.340438</td>\n",
       "      <td>1.337582</td>\n",
       "      <td>1.334862</td>\n",
       "      <td>1.332465</td>\n",
       "      <td>1.330338</td>\n",
       "      <td>1.328340</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.324962</td>\n",
       "      <td>-1.326754</td>\n",
       "      <td>-1.329330</td>\n",
       "      <td>-1.332541</td>\n",
       "      <td>-1.336261</td>\n",
       "      <td>-1.340304</td>\n",
       "      <td>-1.344633</td>\n",
       "      <td>-1.347402</td>\n",
       "      <td>-1.349824</td>\n",
       "      <td>-1.352447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 2800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "19  -0.355102 -0.353486 -0.351813 -0.350161 -0.348585 -0.347129 -0.345743   \n",
       "42  -0.282375 -0.280648 -0.278907 -0.277137 -0.275392 -0.273708 -0.272107   \n",
       "153  2.635599  2.635815  2.636200  2.636678  2.637186  2.637641  2.637959   \n",
       "78   0.824260  0.821456  0.818978  0.816870  0.815100  0.813557  0.812046   \n",
       "145  1.015041  1.018451  1.022076  1.025791  1.029497  1.033103  1.036628   \n",
       "15  -0.311459 -0.309956 -0.308470 -0.307018 -0.305663 -0.304370 -0.303054   \n",
       "24  -0.391316 -0.389854 -0.388355 -0.386846 -0.385327 -0.383907 -0.382503   \n",
       "68  -0.307925 -0.306302 -0.304696 -0.303123 -0.301648 -0.300190 -0.298805   \n",
       "113 -0.297175 -0.295772 -0.294428 -0.293066 -0.291698 -0.290370 -0.289084   \n",
       "118  1.324047  1.320891  1.317578  1.314243  1.311018  1.307931  1.304869   \n",
       "93  -0.043058 -0.042649 -0.042349 -0.042057 -0.041766 -0.041416 -0.041089   \n",
       "159 -2.130599 -2.136321 -2.142001 -2.147633 -2.153165 -2.158625 -2.164032   \n",
       "69  -0.302385 -0.300761 -0.299060 -0.297392 -0.295759 -0.294187 -0.292654   \n",
       "142  1.042602  1.046097  1.049645  1.053181  1.056717  1.060231  1.063713   \n",
       "45  -0.295512 -0.293861 -0.292196 -0.290555 -0.288949 -0.287445 -0.286004   \n",
       "16  -0.306920 -0.305128 -0.303342 -0.301641 -0.300006 -0.298441 -0.296947   \n",
       "51  -0.278903 -0.277137 -0.275327 -0.273530 -0.271788 -0.270129 -0.268531   \n",
       "125 -0.007011 -0.006555 -0.006221 -0.005950 -0.005694 -0.005384 -0.005109   \n",
       "96   0.022560  0.022885  0.023109  0.023290  0.023555  0.023941  0.024323   \n",
       "56  -0.269401 -0.267628 -0.265852 -0.264089 -0.262403 -0.260810 -0.259269   \n",
       "97   1.252258  1.250115  1.247793  1.245384  1.242902  1.240403  1.237720   \n",
       "120  1.340220  1.338327  1.336338  1.334465  1.332587  1.330704  1.328788   \n",
       "143  0.982216  0.985589  0.989027  0.992495  0.995934  0.999294  1.002574   \n",
       "30  -0.311672 -0.310200 -0.308715 -0.307264 -0.305858 -0.304492 -0.303156   \n",
       "9   -0.293006 -0.291341 -0.289653 -0.287967 -0.286285 -0.284684 -0.283145   \n",
       "172  0.885115  0.882563  0.880060  0.877540  0.874920  0.872410  0.870097   \n",
       "60  -0.300390 -0.298907 -0.297431 -0.295969 -0.294563 -0.293228 -0.291945   \n",
       "18  -0.315571 -0.313920 -0.312244 -0.310580 -0.308951 -0.307339 -0.305799   \n",
       "148  1.784769  1.786898  1.788957  1.790983  1.792974  1.794913  1.796791   \n",
       "173  1.028007  1.025243  1.022645  1.020002  1.017313  1.014726  1.012327   \n",
       "109 -0.487100 -0.486026 -0.484954 -0.483942 -0.482973 -0.481994 -0.480999   \n",
       "55  -0.274558 -0.272970 -0.271371 -0.269774 -0.268266 -0.266871 -0.265560   \n",
       "140 -1.029213 -1.034923 -1.040618 -1.046253 -1.051790 -1.057270 -1.062724   \n",
       "126 -0.015992 -0.015394 -0.014927 -0.014501 -0.014100 -0.013697 -0.013297   \n",
       "66  -0.293413 -0.291802 -0.290178 -0.288556 -0.287001 -0.285537 -0.284146   \n",
       "29  -0.302079 -0.300371 -0.298659 -0.297001 -0.295409 -0.293929 -0.292490   \n",
       "117  1.352447  1.349433  1.346427  1.343414  1.340438  1.337582  1.334862   \n",
       "\n",
       "         7         8         9     ...      2790      2791      2792  \\\n",
       "19  -0.344429 -0.343180 -0.341912  ...  0.340416  0.341895  0.343482   \n",
       "42  -0.270569 -0.269033 -0.267570  ...  0.297368  0.296231  0.294651   \n",
       "153  2.638116  2.638125  2.638064  ... -2.634756 -2.633414 -2.632869   \n",
       "78   0.810543  0.809171  0.807972  ... -0.859986 -0.854470 -0.849215   \n",
       "145  1.040053  1.043411  1.046847  ... -1.017165 -1.016343 -1.015912   \n",
       "15  -0.301791 -0.300531 -0.299335  ...  0.303902  0.304389  0.304934   \n",
       "24  -0.381139 -0.379829 -0.378499  ...  0.383391  0.384632  0.385814   \n",
       "68  -0.297472 -0.296194 -0.294981  ...  0.297898  0.298984  0.300117   \n",
       "113 -0.287829 -0.286619 -0.285454  ...  0.319660  0.317251  0.314478   \n",
       "118  1.301836  1.299072  1.296605  ... -1.333095 -1.331216 -1.329523   \n",
       "93  -0.040826 -0.040622 -0.040554  ...  0.071771  0.067347  0.062971   \n",
       "159 -2.169349 -2.174434 -2.179333  ...  2.142769  2.144785  2.145523   \n",
       "69  -0.291132 -0.289632 -0.288218  ...  0.297225  0.298637  0.299680   \n",
       "142  1.067156  1.070624  1.074210  ... -1.053002 -1.050486 -1.048556   \n",
       "45  -0.284636 -0.283375 -0.282105  ...  0.302265  0.300844  0.299500   \n",
       "16  -0.295537 -0.294171 -0.292817  ...  0.310161  0.309765  0.309336   \n",
       "51  -0.267060 -0.265643 -0.264279  ...  0.279356  0.280010  0.280290   \n",
       "125 -0.004856 -0.004596 -0.004327  ...  0.027816  0.024290  0.020907   \n",
       "96   0.024684  0.025096  0.025551  ...  0.010984  0.007578  0.003674   \n",
       "56  -0.257750 -0.256286 -0.254833  ...  0.261865  0.262861  0.263794   \n",
       "97   1.234984  1.232096  1.229042  ... -1.246361 -1.247290 -1.248304   \n",
       "120  1.326720  1.324531  1.322221  ... -1.329771 -1.330160 -1.330973   \n",
       "143  1.005744  1.008968  1.012465  ... -0.988000 -0.987004 -0.986221   \n",
       "30  -0.301893 -0.300633 -0.299406  ...  0.288451  0.290800  0.293351   \n",
       "9   -0.281606 -0.280131 -0.278700  ...  0.270372  0.272680  0.275191   \n",
       "172  0.868070  0.866148  0.864038  ... -0.917512 -0.916454 -0.913617   \n",
       "60  -0.290736 -0.289572 -0.288326  ...  0.276710  0.278989  0.281532   \n",
       "18  -0.304257 -0.302770 -0.301274  ...  0.326986  0.326238  0.325063   \n",
       "148  1.798540  1.800246  1.802105  ... -1.781068 -1.780773 -1.781022   \n",
       "173  1.010218  1.008186  1.005986  ... -1.038683 -1.038212 -1.036797   \n",
       "109 -0.480051 -0.479158 -0.478353  ...  0.509993  0.507287  0.504438   \n",
       "55  -0.264335 -0.263165 -0.261902  ...  0.269293  0.270468  0.271505   \n",
       "140 -1.068184 -1.073584 -1.078993  ...  1.033434  1.034645  1.035454   \n",
       "126 -0.012973 -0.012751 -0.012487  ...  0.044068  0.040987  0.037534   \n",
       "66  -0.282849 -0.281577 -0.280306  ...  0.271710  0.274068  0.276565   \n",
       "29  -0.291083 -0.289667 -0.288252  ...  0.288581  0.290889  0.293065   \n",
       "117  1.332465  1.330338  1.328340  ... -1.324962 -1.326754 -1.329330   \n",
       "\n",
       "         2793      2794      2795      2796      2797      2798      2799  \n",
       "19   0.345356  0.347572  0.350045  0.352639  0.354027  0.354610  0.355102  \n",
       "42   0.292879  0.291017  0.289009  0.286725  0.285213  0.283830  0.282375  \n",
       "153 -2.632611 -2.632381 -2.632199 -2.632285 -2.632771 -2.634070 -2.635599  \n",
       "78  -0.844020 -0.838745 -0.833657 -0.828785 -0.826249 -0.825185 -0.824260  \n",
       "145 -1.015459 -1.014760 -1.013998 -1.013447 -1.013470 -1.014196 -1.015041  \n",
       "15   0.305798  0.307034  0.308599  0.310247  0.311081  0.311317  0.311459  \n",
       "24   0.387141  0.388509  0.389851  0.390985  0.391457  0.391426  0.391316  \n",
       "68   0.301462  0.303127  0.304972  0.306807  0.307662  0.307835  0.307925  \n",
       "113  0.311598  0.308681  0.305740  0.302597  0.300601  0.298929  0.297175  \n",
       "118 -1.327962 -1.326339 -1.324890 -1.323620 -1.323171 -1.323514 -1.324047  \n",
       "93   0.058871  0.055126  0.051669  0.048377  0.046426  0.044787  0.043058  \n",
       "159  2.144769  2.142582  2.139368  2.135624  2.133396  2.132000  2.130599  \n",
       "69   0.300593  0.301486  0.302314  0.302928  0.303056  0.302757  0.302385  \n",
       "142 -1.046811 -1.045047 -1.043369 -1.042006 -1.041597 -1.042029 -1.042602  \n",
       "45   0.298380  0.297635  0.297144  0.296805  0.296547  0.296071  0.295512  \n",
       "16   0.309050  0.309005  0.308928  0.308630  0.308255  0.307624  0.306920  \n",
       "51   0.280419  0.280487  0.280518  0.280381  0.280104  0.279551  0.278903  \n",
       "125  0.017894  0.015277  0.012989  0.010874  0.009558  0.008341  0.007011  \n",
       "96  -0.000532 -0.004954 -0.009611 -0.014544 -0.017600 -0.020033 -0.022560  \n",
       "56   0.264949  0.266355  0.267846  0.269143  0.269649  0.269562  0.269401  \n",
       "97  -1.249218 -1.249954 -1.250393 -1.250631 -1.250829 -1.251445 -1.252258  \n",
       "120 -1.332036 -1.333183 -1.334553 -1.336184 -1.337339 -1.338680 -1.340220  \n",
       "143 -0.985336 -0.984114 -0.982767 -0.981544 -0.981173 -0.981626 -0.982216  \n",
       "30   0.296289  0.299700  0.303453  0.307365  0.309546  0.310651  0.311672  \n",
       "9    0.278125  0.281475  0.285119  0.288892  0.290979  0.292029  0.293006  \n",
       "172 -0.910551 -0.907874 -0.905186 -0.901539 -0.897628 -0.891806 -0.885115  \n",
       "60   0.284527  0.288029  0.291906  0.295952  0.298184  0.299324  0.300390  \n",
       "18   0.323749  0.322354  0.320878  0.319154  0.317945  0.316804  0.315571  \n",
       "148 -1.781357 -1.781498 -1.781549 -1.781798 -1.782299 -1.783434 -1.784769  \n",
       "173 -1.035974 -1.036355 -1.037335 -1.037861 -1.036885 -1.032888 -1.028007  \n",
       "109  0.501528  0.498609  0.495626  0.492447  0.490447  0.488805  0.487100  \n",
       "55   0.272453  0.273430  0.274338  0.275053  0.275233  0.274937  0.274558  \n",
       "140  1.035526  1.034823  1.033564  1.031946  1.030893  1.030109  1.029213  \n",
       "126  0.033911  0.030289  0.026572  0.022663  0.020191  0.018142  0.015992  \n",
       "66   0.279412  0.282623  0.286127  0.289698  0.291647  0.292572  0.293413  \n",
       "29   0.295152  0.297166  0.299132  0.300912  0.301756  0.301964  0.302079  \n",
       "117 -1.332541 -1.336261 -1.340304 -1.344633 -1.347402 -1.349824 -1.352447  \n",
       "\n",
       "[37 rows x 2800 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction:\n",
    "\n",
    " Use PCA to reduce the input dimensionality if the dataset is too high-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# convert back to a dataframe\n",
    "X_train_pca = pd.DataFrame(X_train_pca)\n",
    "X_test_pca = pd.DataFrame(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-30.397715</td>\n",
       "      <td>-7.173837</td>\n",
       "      <td>0.505082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.639217</td>\n",
       "      <td>-7.951355</td>\n",
       "      <td>1.682380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-30.803980</td>\n",
       "      <td>-6.855545</td>\n",
       "      <td>0.180291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-30.928344</td>\n",
       "      <td>-7.593637</td>\n",
       "      <td>0.553239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-29.201630</td>\n",
       "      <td>-9.662276</td>\n",
       "      <td>1.238003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>73.491355</td>\n",
       "      <td>-0.817233</td>\n",
       "      <td>-12.861807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-30.279794</td>\n",
       "      <td>-7.323924</td>\n",
       "      <td>0.720564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7.762607</td>\n",
       "      <td>4.279655</td>\n",
       "      <td>-14.742861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>92.428913</td>\n",
       "      <td>-13.540680</td>\n",
       "      <td>15.012772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>69.878793</td>\n",
       "      <td>2.200257</td>\n",
       "      <td>-13.313499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2\n",
       "0   -30.397715  -7.173837   0.505082\n",
       "1   -30.639217  -7.951355   1.682380\n",
       "2   -30.803980  -6.855545   0.180291\n",
       "3   -30.928344  -7.593637   0.553239\n",
       "4   -29.201630  -9.662276   1.238003\n",
       "..         ...        ...        ...\n",
       "139  73.491355  -0.817233 -12.861807\n",
       "140 -30.279794  -7.323924   0.720564\n",
       "141   7.762607   4.279655 -14.742861\n",
       "142  92.428913 -13.540680  15.012772\n",
       "143  69.878793   2.200257 -13.313499\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31.353769</td>\n",
       "      <td>-5.490578</td>\n",
       "      <td>-0.029496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-29.071803</td>\n",
       "      <td>-9.115020</td>\n",
       "      <td>0.351931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.753934</td>\n",
       "      <td>-90.722974</td>\n",
       "      <td>21.305769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.982381</td>\n",
       "      <td>-8.221943</td>\n",
       "      <td>3.612671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34.085430</td>\n",
       "      <td>-74.027118</td>\n",
       "      <td>11.974625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-30.136958</td>\n",
       "      <td>-7.429598</td>\n",
       "      <td>1.266313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-30.365386</td>\n",
       "      <td>-4.896786</td>\n",
       "      <td>0.513040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-30.055368</td>\n",
       "      <td>-7.852576</td>\n",
       "      <td>2.747932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-28.149508</td>\n",
       "      <td>-4.202456</td>\n",
       "      <td>-6.073699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76.569013</td>\n",
       "      <td>0.869426</td>\n",
       "      <td>-11.531683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-9.851589</td>\n",
       "      <td>2.798545</td>\n",
       "      <td>-19.612455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.850689</td>\n",
       "      <td>94.218495</td>\n",
       "      <td>14.541010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-30.350933</td>\n",
       "      <td>-7.537003</td>\n",
       "      <td>1.873046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-35.359282</td>\n",
       "      <td>-76.491825</td>\n",
       "      <td>16.945608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-27.120806</td>\n",
       "      <td>-10.191789</td>\n",
       "      <td>0.899216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-30.248057</td>\n",
       "      <td>-7.643882</td>\n",
       "      <td>1.415930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-31.501428</td>\n",
       "      <td>-7.820246</td>\n",
       "      <td>0.180954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-14.918157</td>\n",
       "      <td>1.019441</td>\n",
       "      <td>-17.715787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-11.239467</td>\n",
       "      <td>-0.653864</td>\n",
       "      <td>-15.826107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-31.147900</td>\n",
       "      <td>-8.383498</td>\n",
       "      <td>0.380904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>70.816697</td>\n",
       "      <td>-1.887904</td>\n",
       "      <td>-10.057136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>67.309983</td>\n",
       "      <td>-2.203630</td>\n",
       "      <td>-12.803268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-34.116016</td>\n",
       "      <td>-73.958465</td>\n",
       "      <td>13.895607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-30.754469</td>\n",
       "      <td>-6.671349</td>\n",
       "      <td>0.159098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-30.729184</td>\n",
       "      <td>-7.435355</td>\n",
       "      <td>0.786364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>62.875315</td>\n",
       "      <td>-7.279404</td>\n",
       "      <td>13.071894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-30.330610</td>\n",
       "      <td>-7.257699</td>\n",
       "      <td>0.702954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-30.075954</td>\n",
       "      <td>-7.481759</td>\n",
       "      <td>1.108389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.008272</td>\n",
       "      <td>-80.742791</td>\n",
       "      <td>15.989256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>71.909598</td>\n",
       "      <td>-8.162476</td>\n",
       "      <td>13.692019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-23.313785</td>\n",
       "      <td>-1.401937</td>\n",
       "      <td>-4.728797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-31.064194</td>\n",
       "      <td>-8.409400</td>\n",
       "      <td>0.732484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>48.985367</td>\n",
       "      <td>66.094734</td>\n",
       "      <td>14.451243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-14.496401</td>\n",
       "      <td>1.462176</td>\n",
       "      <td>-17.982878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-30.365823</td>\n",
       "      <td>-7.571352</td>\n",
       "      <td>1.276961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-31.052657</td>\n",
       "      <td>-6.628127</td>\n",
       "      <td>-0.556607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>74.515615</td>\n",
       "      <td>1.187770</td>\n",
       "      <td>-14.670252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2\n",
       "0  -31.353769  -5.490578  -0.029496\n",
       "1  -29.071803  -9.115020   0.351931\n",
       "2   42.753934 -90.722974  21.305769\n",
       "3   36.982381  -8.221943   3.612671\n",
       "4  -34.085430 -74.027118  11.974625\n",
       "5  -30.136958  -7.429598   1.266313\n",
       "6  -30.365386  -4.896786   0.513040\n",
       "7  -30.055368  -7.852576   2.747932\n",
       "8  -28.149508  -4.202456  -6.073699\n",
       "9   76.569013   0.869426 -11.531683\n",
       "10  -9.851589   2.798545 -19.612455\n",
       "11  27.850689  94.218495  14.541010\n",
       "12 -30.350933  -7.537003   1.873046\n",
       "13 -35.359282 -76.491825  16.945608\n",
       "14 -27.120806 -10.191789   0.899216\n",
       "15 -30.248057  -7.643882   1.415930\n",
       "16 -31.501428  -7.820246   0.180954\n",
       "17 -14.918157   1.019441 -17.715787\n",
       "18 -11.239467  -0.653864 -15.826107\n",
       "19 -31.147900  -8.383498   0.380904\n",
       "20  70.816697  -1.887904 -10.057136\n",
       "21  67.309983  -2.203630 -12.803268\n",
       "22 -34.116016 -73.958465  13.895607\n",
       "23 -30.754469  -6.671349   0.159098\n",
       "24 -30.729184  -7.435355   0.786364\n",
       "25  62.875315  -7.279404  13.071894\n",
       "26 -30.330610  -7.257699   0.702954\n",
       "27 -30.075954  -7.481759   1.108389\n",
       "28   3.008272 -80.742791  15.989256\n",
       "29  71.909598  -8.162476  13.692019\n",
       "30 -23.313785  -1.401937  -4.728797\n",
       "31 -31.064194  -8.409400   0.732484\n",
       "32  48.985367  66.094734  14.451243\n",
       "33 -14.496401   1.462176 -17.982878\n",
       "34 -30.365823  -7.571352   1.276961\n",
       "35 -31.052657  -6.628127  -0.556607\n",
       "36  74.515615   1.187770 -14.670252"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               512       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11046 (43.15 KB)\n",
      "Trainable params: 11046 (43.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(units=128, input_dim=X_train_pca.shape[1], activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=6, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data for model evaluation split from training data\n",
    "X_train_pca, X_val_pca, y_train, y_val = train_test_split(X_train_pca, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 32.2818 - mae: 2.6109 - val_loss: 43.8040 - val_mae: 2.9844\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.9390 - mae: 2.5765 - val_loss: 44.7785 - val_mae: 3.0417\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.7405 - mae: 2.5983 - val_loss: 48.0682 - val_mae: 3.0987\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 33.5641 - mae: 2.5845 - val_loss: 51.3662 - val_mae: 3.0892\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.8498 - mae: 2.7120 - val_loss: 51.1884 - val_mae: 3.0752\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.8877 - mae: 2.4270 - val_loss: 50.4233 - val_mae: 3.0791\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 28.1375 - mae: 2.5306 - val_loss: 51.1347 - val_mae: 3.1534\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.8315 - mae: 2.6665 - val_loss: 50.1284 - val_mae: 3.1652\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.1535 - mae: 2.5398 - val_loss: 46.2321 - val_mae: 3.0805\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.8218 - mae: 2.7727 - val_loss: 44.9512 - val_mae: 2.9879\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.1440 - mae: 2.6033 - val_loss: 44.5445 - val_mae: 2.9482\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.8474 - mae: 2.4512 - val_loss: 44.0423 - val_mae: 2.9641\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 39.0912 - mae: 2.8506 - val_loss: 44.9842 - val_mae: 3.0028\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.3072 - mae: 2.4739 - val_loss: 44.6132 - val_mae: 2.9703\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.8392 - mae: 2.5368 - val_loss: 46.0118 - val_mae: 3.0097\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.4955 - mae: 2.5257 - val_loss: 46.5829 - val_mae: 3.0306\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.7370 - mae: 2.6250 - val_loss: 47.8757 - val_mae: 3.0743\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 34.0279 - mae: 2.7277 - val_loss: 47.4674 - val_mae: 3.0578\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.7466 - mae: 2.4760 - val_loss: 47.3302 - val_mae: 2.9906\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.5552 - mae: 2.6233 - val_loss: 46.8057 - val_mae: 2.9479\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.1147 - mae: 2.5363 - val_loss: 46.2203 - val_mae: 2.9447\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.8194 - mae: 2.4022 - val_loss: 46.1303 - val_mae: 2.9171\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 35.1996 - mae: 2.6831 - val_loss: 47.6915 - val_mae: 2.9819\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.1139 - mae: 2.4286 - val_loss: 50.2763 - val_mae: 3.1542\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.4131 - mae: 2.6666 - val_loss: 51.1178 - val_mae: 3.1769\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 41.5237 - mae: 2.8240 - val_loss: 50.7975 - val_mae: 3.1661\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.3998 - mae: 2.5270 - val_loss: 48.5290 - val_mae: 3.0828\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.3397 - mae: 2.7627 - val_loss: 46.9463 - val_mae: 3.0349\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.6070 - mae: 2.5235 - val_loss: 45.6231 - val_mae: 2.9470\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 31.1502 - mae: 2.5423 - val_loss: 46.7221 - val_mae: 2.9333\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 32.3606 - mae: 2.5990 - val_loss: 48.2458 - val_mae: 2.9876\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.0058 - mae: 2.6184 - val_loss: 48.2234 - val_mae: 3.0261\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.8494 - mae: 2.6128 - val_loss: 47.5528 - val_mae: 3.0497\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.2779 - mae: 2.5824 - val_loss: 48.2409 - val_mae: 3.1166\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.5593 - mae: 2.5203 - val_loss: 50.5694 - val_mae: 3.1703\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.4339 - mae: 2.4522 - val_loss: 52.2022 - val_mae: 3.1818\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.7026 - mae: 2.5300 - val_loss: 52.8452 - val_mae: 3.1507\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 37.2026 - mae: 2.8649 - val_loss: 49.7943 - val_mae: 3.0898\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.3225 - mae: 2.6716 - val_loss: 45.4734 - val_mae: 2.9531\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.3648 - mae: 2.6055 - val_loss: 44.5905 - val_mae: 2.8797\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.1103 - mae: 2.4672 - val_loss: 42.7823 - val_mae: 2.8776\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.3630 - mae: 2.6195 - val_loss: 47.0245 - val_mae: 3.0382\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.7846 - mae: 2.6381 - val_loss: 49.0464 - val_mae: 3.0834\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.6665 - mae: 2.5630 - val_loss: 47.8791 - val_mae: 2.9902\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.3811 - mae: 2.5075 - val_loss: 46.6764 - val_mae: 2.9281\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.5604 - mae: 2.5693 - val_loss: 43.2892 - val_mae: 2.8366\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.7034 - mae: 2.4509 - val_loss: 42.5776 - val_mae: 2.8919\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.2547 - mae: 2.5827 - val_loss: 45.4668 - val_mae: 3.0621\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 33.1097 - mae: 2.6417 - val_loss: 44.0506 - val_mae: 3.0551\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.2077 - mae: 2.5664 - val_loss: 43.5547 - val_mae: 2.9949\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.7326 - mae: 2.4724 - val_loss: 42.2639 - val_mae: 2.8620\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.0216 - mae: 2.4952 - val_loss: 40.8168 - val_mae: 2.8282\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 34.5365 - mae: 2.5396 - val_loss: 41.9100 - val_mae: 2.9385\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.1706 - mae: 2.5925 - val_loss: 43.3130 - val_mae: 2.9709\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.0803 - mae: 2.6112 - val_loss: 45.7551 - val_mae: 2.9742\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.3328 - mae: 2.4750 - val_loss: 44.6033 - val_mae: 2.9067\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.1243 - mae: 2.6127 - val_loss: 39.9594 - val_mae: 2.8173\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.8059 - mae: 2.5695 - val_loss: 40.3623 - val_mae: 2.8471\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.7756 - mae: 2.5181 - val_loss: 42.6767 - val_mae: 2.9389\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.9498 - mae: 2.6130 - val_loss: 42.9819 - val_mae: 2.9142\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.8815 - mae: 2.5892 - val_loss: 43.2885 - val_mae: 2.8246\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.9924 - mae: 2.4192 - val_loss: 42.9277 - val_mae: 2.8177\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.6651 - mae: 2.5321 - val_loss: 42.8063 - val_mae: 2.8764\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 33.1271 - mae: 2.4507 - val_loss: 44.8389 - val_mae: 3.0393\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.8907 - mae: 2.5827 - val_loss: 49.0773 - val_mae: 3.0864\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.6343 - mae: 2.5294 - val_loss: 50.9247 - val_mae: 3.0914\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.9075 - mae: 2.4894 - val_loss: 48.9001 - val_mae: 3.0498\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 34.4571 - mae: 2.6405 - val_loss: 45.7296 - val_mae: 2.9703\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.9478 - mae: 2.3990 - val_loss: 43.3630 - val_mae: 2.9088\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.6356 - mae: 2.3226 - val_loss: 46.0869 - val_mae: 2.9470\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.9828 - mae: 2.3925 - val_loss: 48.7412 - val_mae: 3.0121\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.1768 - mae: 2.5085 - val_loss: 48.6672 - val_mae: 3.0038\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 24.6824 - mae: 2.3422 - val_loss: 49.0787 - val_mae: 3.0390\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 34.5196 - mae: 2.6549 - val_loss: 47.3104 - val_mae: 3.0471\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.1186 - mae: 2.3669 - val_loss: 46.2825 - val_mae: 3.0094\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.2844 - mae: 2.5114 - val_loss: 47.0395 - val_mae: 2.9519\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.4811 - mae: 2.5294 - val_loss: 50.0948 - val_mae: 2.9684\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.3095 - mae: 2.5194 - val_loss: 48.8901 - val_mae: 2.9748\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.1183 - mae: 2.5233 - val_loss: 47.2934 - val_mae: 3.0325\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.8277 - mae: 2.5580 - val_loss: 47.4102 - val_mae: 3.0470\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.3196 - mae: 2.4627 - val_loss: 46.5816 - val_mae: 2.9639\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.6849 - mae: 2.4973 - val_loss: 47.7964 - val_mae: 2.9905\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.1602 - mae: 2.4910 - val_loss: 46.5734 - val_mae: 2.9910\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.7596 - mae: 2.2652 - val_loss: 45.9603 - val_mae: 3.0622\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 28.1701 - mae: 2.4547 - val_loss: 44.3240 - val_mae: 3.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.8381 - mae: 2.3749 - val_loss: 46.0502 - val_mae: 2.9670\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.9126 - mae: 2.5922 - val_loss: 48.1274 - val_mae: 2.9769\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.4804 - mae: 2.3830 - val_loss: 46.3048 - val_mae: 2.9369\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.6383 - mae: 2.3734 - val_loss: 45.2535 - val_mae: 2.9163\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.5336 - mae: 2.3845 - val_loss: 43.0019 - val_mae: 2.8772\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.3294 - mae: 2.5797 - val_loss: 42.2530 - val_mae: 2.8718\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.8442 - mae: 2.3741 - val_loss: 44.3872 - val_mae: 2.9162\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.1227 - mae: 2.4136 - val_loss: 44.0985 - val_mae: 2.8819\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.1268 - mae: 2.4094 - val_loss: 46.7183 - val_mae: 2.9715\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.0408 - mae: 2.4639 - val_loss: 47.2297 - val_mae: 3.0053\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.2811 - mae: 2.4473 - val_loss: 43.7790 - val_mae: 3.0060\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.8499 - mae: 2.4663 - val_loss: 44.4906 - val_mae: 3.0460\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.6244 - mae: 2.6260 - val_loss: 45.6969 - val_mae: 2.9499\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.4005 - mae: 2.3517 - val_loss: 46.6626 - val_mae: 2.9195\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.0548 - mae: 2.4555 - val_loss: 46.6261 - val_mae: 2.9668\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.9599 - mae: 2.4431\n",
      "Test Loss: 25.9599\n",
      "Test MAE: 2.4431\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_pca, y_train, epochs=100, batch_size=32, validation_data=(X_val_pca, y_val))\n",
    "\n",
    "# Test the model\n",
    "loss, mae = model.evaluate(X_test_pca, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.3561\n",
      "MSE: 25.9599\n",
      "MAE: 2.4431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate metrics\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {MSE:.4f}')\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {MAE:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the target variables using the complete dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 128)               358528    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369062 (1.41 MB)\n",
      "Trainable params: 369062 (1.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=6, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 109.0499 - mae: 4.4334 - val_loss: 91.2992 - val_mae: 4.9005\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 101.8643 - mae: 5.6191 - val_loss: 86.5615 - val_mae: 4.7888\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 92.3804 - mae: 5.1437 - val_loss: 91.2639 - val_mae: 4.9505\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 87.6013 - mae: 4.8773 - val_loss: 83.8811 - val_mae: 4.6287\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 82.9972 - mae: 4.7677 - val_loss: 77.4590 - val_mae: 4.5588\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 79.7243 - mae: 4.6571 - val_loss: 77.5201 - val_mae: 4.4384\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 74.6204 - mae: 4.6049 - val_loss: 74.9706 - val_mae: 4.4891\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 65.2502 - mae: 4.5373 - val_loss: 71.4094 - val_mae: 4.2444\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 70.0215 - mae: 4.5678 - val_loss: 70.4832 - val_mae: 4.1078\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 70.0024 - mae: 4.2904 - val_loss: 70.1851 - val_mae: 3.9980\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 64.8634 - mae: 4.1715 - val_loss: 69.3070 - val_mae: 4.2417\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 68.2757 - mae: 4.4376 - val_loss: 67.7577 - val_mae: 4.0526\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 59.8836 - mae: 4.1840 - val_loss: 64.3795 - val_mae: 3.9904\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 59.8940 - mae: 4.0339 - val_loss: 59.9357 - val_mae: 3.6697\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 55.5553 - mae: 4.0412 - val_loss: 57.5359 - val_mae: 3.5890\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 55.3639 - mae: 3.9195 - val_loss: 57.8931 - val_mae: 3.7327\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.4350 - mae: 4.0492 - val_loss: 58.4872 - val_mae: 3.8788\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 52.4353 - mae: 3.7834 - val_loss: 55.2366 - val_mae: 3.7766\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 52.6284 - mae: 3.9033 - val_loss: 55.3316 - val_mae: 3.8576\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 52.9190 - mae: 3.7916 - val_loss: 55.9997 - val_mae: 3.7288\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 55.5192 - mae: 3.8187 - val_loss: 52.7223 - val_mae: 3.7326\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 52.0286 - mae: 4.0095 - val_loss: 51.6663 - val_mae: 3.6115\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 52.5233 - mae: 3.8041 - val_loss: 52.4174 - val_mae: 3.5749\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 49.8840 - mae: 3.6710 - val_loss: 51.2491 - val_mae: 3.7175\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 51.3322 - mae: 3.9237 - val_loss: 50.2263 - val_mae: 3.6604\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 52.4705 - mae: 3.7849 - val_loss: 49.5000 - val_mae: 3.8430\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 48.3800 - mae: 3.7388 - val_loss: 46.4556 - val_mae: 3.5481\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 46.1218 - mae: 3.6627 - val_loss: 50.7266 - val_mae: 3.6181\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 48.7463 - mae: 3.6318 - val_loss: 52.3767 - val_mae: 3.6844\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 46.7782 - mae: 3.5555 - val_loss: 46.9225 - val_mae: 3.5050\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 44.8375 - mae: 3.6225 - val_loss: 46.2962 - val_mae: 3.6402\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.6016 - mae: 3.7013 - val_loss: 49.5468 - val_mae: 3.6032\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 46.9132 - mae: 3.5214 - val_loss: 46.1218 - val_mae: 3.6475\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.7451 - mae: 3.5325 - val_loss: 44.8409 - val_mae: 3.7399\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 47.3665 - mae: 3.6910 - val_loss: 49.9139 - val_mae: 3.4914\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 40.7031 - mae: 3.2414 - val_loss: 46.0371 - val_mae: 3.4628\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 40.8205 - mae: 3.3072 - val_loss: 44.2345 - val_mae: 3.4263\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 41.9188 - mae: 3.5525 - val_loss: 41.4916 - val_mae: 3.1982\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 39.5409 - mae: 3.2775 - val_loss: 45.5020 - val_mae: 3.4042\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 35.7841 - mae: 3.3790 - val_loss: 43.8700 - val_mae: 3.3301\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.1903 - mae: 3.4669 - val_loss: 42.4818 - val_mae: 3.1075\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 42.9632 - mae: 3.2955 - val_loss: 48.0068 - val_mae: 3.4388\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.6715 - mae: 3.4563 - val_loss: 42.0594 - val_mae: 3.4310\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 36.3726 - mae: 3.3208 - val_loss: 38.8683 - val_mae: 3.2694\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 34.8190 - mae: 3.1614 - val_loss: 41.5488 - val_mae: 3.2885\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 38.1574 - mae: 3.2514 - val_loss: 46.0786 - val_mae: 3.3565\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 40.6833 - mae: 3.2874 - val_loss: 39.4942 - val_mae: 3.0879\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 38.9754 - mae: 3.2027 - val_loss: 40.8644 - val_mae: 3.1392\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 34.8061 - mae: 3.1484 - val_loss: 43.2039 - val_mae: 3.2485\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 40.3735 - mae: 3.2751 - val_loss: 43.6864 - val_mae: 3.3177\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 34.7573 - mae: 3.2647 - val_loss: 38.6427 - val_mae: 3.2400\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.9325 - mae: 3.2216 - val_loss: 37.9425 - val_mae: 3.0340\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 27.5251 - mae: 2.9047 - val_loss: 38.5510 - val_mae: 3.2855\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 35.4846 - mae: 3.2467 - val_loss: 42.7519 - val_mae: 3.2459\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 37.4487 - mae: 3.2182 - val_loss: 38.3454 - val_mae: 3.1666\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 34.5235 - mae: 3.1628 - val_loss: 43.1334 - val_mae: 3.2512\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 35.2001 - mae: 3.0442 - val_loss: 42.0905 - val_mae: 3.2795\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 33.1758 - mae: 3.1892 - val_loss: 38.2730 - val_mae: 2.9619\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 38.8014 - mae: 3.0993 - val_loss: 39.7479 - val_mae: 2.9262\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.2238 - mae: 2.9177 - val_loss: 39.5535 - val_mae: 3.1056\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.6478 - mae: 2.9077 - val_loss: 40.6779 - val_mae: 3.0560\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 28.3900 - mae: 2.8389 - val_loss: 36.2463 - val_mae: 2.8785\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 33.3171 - mae: 2.9194 - val_loss: 33.8726 - val_mae: 2.7047\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 36.1570 - mae: 3.0772 - val_loss: 39.6474 - val_mae: 2.8760\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 33.2577 - mae: 2.9698 - val_loss: 36.0644 - val_mae: 2.9940\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 37.6740 - mae: 3.0904 - val_loss: 29.7176 - val_mae: 2.7430\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 36.9640 - mae: 3.0684 - val_loss: 30.2753 - val_mae: 2.7807\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.6461 - mae: 3.0083 - val_loss: 35.8275 - val_mae: 2.9698\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.8535 - mae: 3.0406 - val_loss: 32.8477 - val_mae: 2.8260\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.8762 - mae: 2.9390 - val_loss: 35.6108 - val_mae: 2.8160\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 29.1949 - mae: 2.7101 - val_loss: 31.5187 - val_mae: 2.7596\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 33.2208 - mae: 2.8645 - val_loss: 34.0990 - val_mae: 2.8712\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 26.7549 - mae: 2.6745 - val_loss: 43.1938 - val_mae: 2.9152\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.6134 - mae: 2.8013 - val_loss: 38.9308 - val_mae: 2.8610\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.0995 - mae: 2.8334 - val_loss: 27.5754 - val_mae: 2.6820\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.1332 - mae: 2.9855 - val_loss: 29.9324 - val_mae: 2.6789\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 29.2012 - mae: 2.7759 - val_loss: 30.1108 - val_mae: 2.6970\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 29.7515 - mae: 2.7371 - val_loss: 27.6114 - val_mae: 2.5992\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 23.7980 - mae: 2.5941 - val_loss: 27.4619 - val_mae: 2.6149\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.7106 - mae: 2.7476 - val_loss: 29.8452 - val_mae: 2.6140\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 28.7150 - mae: 2.6946 - val_loss: 29.7037 - val_mae: 2.6309\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 30.1106 - mae: 2.8070 - val_loss: 27.1578 - val_mae: 2.7503\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.2979 - mae: 2.9946 - val_loss: 31.2579 - val_mae: 2.8299\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.5859 - mae: 2.5249 - val_loss: 33.0242 - val_mae: 2.8985\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.5183 - mae: 2.6715 - val_loss: 31.7218 - val_mae: 2.8571\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 24.6064 - mae: 2.7656 - val_loss: 27.2190 - val_mae: 2.6572\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 25.9776 - mae: 2.7200 - val_loss: 26.6366 - val_mae: 2.7233\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.9845 - mae: 2.7646 - val_loss: 32.8280 - val_mae: 2.8300\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 29.3529 - mae: 2.6500 - val_loss: 35.6479 - val_mae: 2.9460\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.6501 - mae: 2.7929 - val_loss: 30.1951 - val_mae: 2.6054\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.8754 - mae: 2.6839 - val_loss: 30.6445 - val_mae: 2.5650\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 34.2725 - mae: 2.8439 - val_loss: 27.9509 - val_mae: 2.5937\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 22.4741 - mae: 2.6232 - val_loss: 24.6171 - val_mae: 2.4006\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7872 - mae: 2.7481 - val_loss: 26.2188 - val_mae: 2.4472\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 25.4241 - mae: 2.4984 - val_loss: 31.7610 - val_mae: 2.8571\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 27.8069 - mae: 2.5547 - val_loss: 37.0314 - val_mae: 2.9123\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 20.4114 - mae: 2.2402 - val_loss: 32.8439 - val_mae: 2.6780\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 25.7364 - mae: 2.5979 - val_loss: 29.6190 - val_mae: 2.8022\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 26.6627 - mae: 2.7198 - val_loss: 33.7895 - val_mae: 2.8984\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 29.9258 - mae: 2.6264 - val_loss: 30.2759 - val_mae: 2.7901\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 40.6203 - mae: 2.8175\n",
      "Test Loss: 40.6203\n",
      "Test MAE: 2.8175\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Test the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.2032\n",
      "MSE: 40.6203\n",
      "MAE: 2.8175\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {MSE:.4f}')\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {MAE:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Results on PCA data:\n",
    "\n",
    "R^2 Score: 0.3561\n",
    "\n",
    "MSE: 25.9599\n",
    "\n",
    "MAE: 2.4431\n",
    "\n",
    "So, it's better to use data with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's predict each target variable separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    # Hidden layers\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Test the model\n",
    "    loss, mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test MAE: {mae:.4f}')\n",
    "\n",
    "    # Calculate metrics\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    print(f'MSE: {MSE:.4f}')\n",
    "\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'MAE: {MAE:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll do this using 3 variations of the dataset:\n",
    "\n",
    "1. With the complete dataset\n",
    "\n",
    "2. With the complete dataset undergone PCA\n",
    "\n",
    "3. With the selected features dataset for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. With the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = pd.DataFrame(columns=target.columns)\n",
    "y_truth = pd.DataFrame(columns=target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 61ms/step - loss: 430.8990 - mae: 14.2599 - val_loss: 362.4518 - val_mae: 13.9739\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 356.1684 - mae: 13.0358 - val_loss: 263.0154 - val_mae: 13.1107\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 284.8849 - mae: 12.2043 - val_loss: 230.8325 - val_mae: 12.4512\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 280.9069 - mae: 12.4884 - val_loss: 221.4440 - val_mae: 12.6755\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 284.7201 - mae: 12.6910 - val_loss: 209.6848 - val_mae: 12.1798\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 282.9914 - mae: 12.7187 - val_loss: 203.2316 - val_mae: 11.7398\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 248.1707 - mae: 11.5253 - val_loss: 199.4529 - val_mae: 11.0331\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 232.2835 - mae: 10.4823 - val_loss: 192.0239 - val_mae: 10.9611\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 209.3598 - mae: 10.2060 - val_loss: 177.7803 - val_mae: 10.6649\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 204.9042 - mae: 10.4317 - val_loss: 157.4723 - val_mae: 9.5218\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 183.6341 - mae: 10.3882 - val_loss: 143.4421 - val_mae: 8.1536\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.1431 - mae: 8.9899 - val_loss: 137.2924 - val_mae: 7.8780\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.9976 - mae: 9.8603 - val_loss: 151.0751 - val_mae: 8.4950\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.2933 - mae: 9.4383 - val_loss: 147.3529 - val_mae: 8.2898\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.3950 - mae: 9.5123 - val_loss: 161.0701 - val_mae: 8.9200\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 165.1903 - mae: 9.2771 - val_loss: 171.9833 - val_mae: 9.3470\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.6400 - mae: 8.8449 - val_loss: 163.8309 - val_mae: 8.6066\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 112.6588 - mae: 7.9083 - val_loss: 152.7054 - val_mae: 7.7112\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.8171 - mae: 8.1641 - val_loss: 143.8777 - val_mae: 7.9655\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 125.5071 - mae: 7.5678 - val_loss: 135.2803 - val_mae: 8.2868\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 105.6938 - mae: 7.7975 - val_loss: 127.0340 - val_mae: 8.2769\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.5046 - mae: 8.9390 - val_loss: 125.1026 - val_mae: 7.7187\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 114.8754 - mae: 7.4563 - val_loss: 125.8261 - val_mae: 7.9271\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 132.3809 - mae: 7.7795 - val_loss: 131.4312 - val_mae: 8.3121\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 124.2863 - mae: 7.6671 - val_loss: 128.8204 - val_mae: 8.1743\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 144.3267 - mae: 8.5401 - val_loss: 121.1737 - val_mae: 7.2256\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 118.4178 - mae: 7.3164 - val_loss: 123.4915 - val_mae: 7.2950\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 137.3846 - mae: 8.0269 - val_loss: 132.1647 - val_mae: 8.1209\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.4773 - mae: 7.5632 - val_loss: 139.5828 - val_mae: 8.6791\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.1804 - mae: 7.4266 - val_loss: 117.0316 - val_mae: 7.6305\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.0564 - mae: 8.4918 - val_loss: 110.2107 - val_mae: 6.4910\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.3538 - mae: 7.6025 - val_loss: 110.6931 - val_mae: 6.5415\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.3810 - mae: 7.1171 - val_loss: 123.4424 - val_mae: 7.5031\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 93.9491 - mae: 7.3767 - val_loss: 116.8046 - val_mae: 7.1301\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.0284 - mae: 8.0589 - val_loss: 108.3356 - val_mae: 6.6058\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 124.7537 - mae: 7.5557 - val_loss: 110.1541 - val_mae: 7.0862\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.8220 - mae: 8.2214 - val_loss: 106.0121 - val_mae: 7.4679\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 111.7738 - mae: 7.8035 - val_loss: 118.9831 - val_mae: 7.9010\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 117.4187 - mae: 8.3098 - val_loss: 143.1464 - val_mae: 8.7811\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 140.1257 - mae: 8.4270 - val_loss: 142.2727 - val_mae: 8.4401\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 109.5100 - mae: 7.3409 - val_loss: 112.3054 - val_mae: 7.2738\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 107.7325 - mae: 7.3980 - val_loss: 112.4623 - val_mae: 7.3913\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 125.9563 - mae: 7.8996 - val_loss: 111.2629 - val_mae: 7.8441\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 119.9160 - mae: 8.1058 - val_loss: 109.2302 - val_mae: 7.2644\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.4340 - mae: 7.2341 - val_loss: 106.8279 - val_mae: 6.6259\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 109.1736 - mae: 7.5628 - val_loss: 114.3142 - val_mae: 7.5855\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.4092 - mae: 7.7920 - val_loss: 161.8817 - val_mae: 9.3607\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 129.2195 - mae: 8.3388 - val_loss: 139.0509 - val_mae: 8.4416\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 97.5101 - mae: 6.8053 - val_loss: 102.7147 - val_mae: 7.2834\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.2588 - mae: 7.9062 - val_loss: 100.4247 - val_mae: 7.0253\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 113.2167 - mae: 7.3233 - val_loss: 110.3594 - val_mae: 8.0975\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 123.2763 - mae: 7.7302 - val_loss: 109.4696 - val_mae: 7.9656\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 104.8415 - mae: 7.5749 - val_loss: 110.1256 - val_mae: 7.3140\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 125.4898 - mae: 7.9990 - val_loss: 109.1545 - val_mae: 7.4776\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 114.2585 - mae: 7.7073 - val_loss: 111.1552 - val_mae: 7.6689\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 97.2171 - mae: 6.9185 - val_loss: 103.8458 - val_mae: 7.2972\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 99.6186 - mae: 6.6698 - val_loss: 99.0860 - val_mae: 6.9434\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 98.9312 - mae: 6.8649 - val_loss: 104.3988 - val_mae: 7.0752\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 97.5017 - mae: 7.2349 - val_loss: 99.4899 - val_mae: 7.2835\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 86.4699 - mae: 6.6124 - val_loss: 90.4843 - val_mae: 7.0655\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.1166 - mae: 6.5191 - val_loss: 85.9846 - val_mae: 6.4118\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 113.1843 - mae: 7.2210 - val_loss: 85.3179 - val_mae: 6.6030\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 77.2846 - mae: 6.1165 - val_loss: 88.5791 - val_mae: 6.6463\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 74.4710 - mae: 6.1703 - val_loss: 99.0738 - val_mae: 7.4993\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 102.1683 - mae: 7.0431 - val_loss: 89.7212 - val_mae: 6.8460\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 105.7990 - mae: 7.0347 - val_loss: 91.6425 - val_mae: 6.1337\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 110.9981 - mae: 7.0713 - val_loss: 85.9626 - val_mae: 5.9523\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.6110 - mae: 6.3664 - val_loss: 89.4803 - val_mae: 6.7768\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 104.8360 - mae: 7.7533 - val_loss: 85.7796 - val_mae: 6.7393\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.9131 - mae: 6.2681 - val_loss: 90.2662 - val_mae: 6.5141\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 85.3420 - mae: 6.2837 - val_loss: 96.6060 - val_mae: 5.9273\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 95.2831 - mae: 6.2868 - val_loss: 98.1968 - val_mae: 6.9762\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.3712 - mae: 7.0201 - val_loss: 107.4375 - val_mae: 7.8359\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 75.5201 - mae: 6.3728 - val_loss: 87.4341 - val_mae: 5.9921\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.8076 - mae: 6.0373 - val_loss: 84.4879 - val_mae: 5.8816\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 89.9442 - mae: 6.1495 - val_loss: 80.7949 - val_mae: 6.4052\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 79.1887 - mae: 5.9528 - val_loss: 88.0424 - val_mae: 6.7203\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 96.4544 - mae: 7.3287 - val_loss: 81.9540 - val_mae: 5.9654\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 88.5756 - mae: 6.5900 - val_loss: 81.9929 - val_mae: 6.1166\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 89.2233 - mae: 6.2841 - val_loss: 85.3272 - val_mae: 6.2762\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 74.8160 - mae: 6.0344 - val_loss: 87.8694 - val_mae: 5.8376\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 77.2393 - mae: 6.0280 - val_loss: 78.0819 - val_mae: 5.5571\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 65.3182 - mae: 5.8518 - val_loss: 65.4385 - val_mae: 5.8397\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 68.1462 - mae: 5.7442 - val_loss: 69.1199 - val_mae: 6.0854\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 64.5788 - mae: 5.7609 - val_loss: 70.4540 - val_mae: 5.7424\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 94.8066 - mae: 6.7570 - val_loss: 84.2272 - val_mae: 6.3905\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 68.6469 - mae: 5.7371 - val_loss: 77.5083 - val_mae: 5.4040\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 78.0638 - mae: 5.9987 - val_loss: 83.4868 - val_mae: 5.6956\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 65.8477 - mae: 5.9663 - val_loss: 90.4859 - val_mae: 6.8148\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 89.8807 - mae: 6.6903 - val_loss: 68.7086 - val_mae: 5.8209\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 87.6728 - mae: 6.3173 - val_loss: 58.8658 - val_mae: 5.2795\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.8944 - mae: 5.3230 - val_loss: 62.0082 - val_mae: 5.6810\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 72.3093 - mae: 5.7347 - val_loss: 60.9838 - val_mae: 5.3893\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 77.5844 - mae: 5.8509 - val_loss: 64.9397 - val_mae: 5.5064\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 71.2369 - mae: 5.7967 - val_loss: 75.5785 - val_mae: 5.9196\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 67.6734 - mae: 5.8240 - val_loss: 78.2538 - val_mae: 5.5272\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 54.5903 - mae: 5.3561 - val_loss: 73.6745 - val_mae: 5.5658\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 65.9694 - mae: 5.5529 - val_loss: 61.4997 - val_mae: 5.4874\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 64.5932 - mae: 5.6159 - val_loss: 56.5506 - val_mae: 5.0757\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.1726 - mae: 6.2597 - val_loss: 67.1151 - val_mae: 5.9018\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 150.4833 - mae: 9.1492\n",
      "Test Loss: 150.4833\n",
      "Test MAE: 9.1492\n",
      "WARNING:tensorflow:6 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x30d0956c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.5497\n",
      "MSE: 150.4833\n",
      "MAE: 9.1492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 291.5979 - mae: 8.9220 - val_loss: 280.1994 - val_mae: 11.8785\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 265.3258 - mae: 10.3373 - val_loss: 264.8491 - val_mae: 10.5441\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 230.2584 - mae: 8.3897 - val_loss: 282.1357 - val_mae: 10.4003\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 271.9695 - mae: 9.0898 - val_loss: 261.9901 - val_mae: 10.6991\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 220.7639 - mae: 8.7562 - val_loss: 238.0273 - val_mae: 11.4051\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 238.2421 - mae: 9.9135 - val_loss: 238.6304 - val_mae: 11.0037\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 207.5551 - mae: 8.6469 - val_loss: 241.2042 - val_mae: 10.1897\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.8535 - mae: 8.3556 - val_loss: 224.4489 - val_mae: 9.9670\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.2553 - mae: 8.5493 - val_loss: 217.4113 - val_mae: 9.4687\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.0417 - mae: 7.3298 - val_loss: 228.0394 - val_mae: 9.0370\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 202.0705 - mae: 7.4173 - val_loss: 218.5270 - val_mae: 9.0976\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 195.7121 - mae: 7.8274 - val_loss: 200.0673 - val_mae: 9.3692\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 172.7168 - mae: 7.7914 - val_loss: 179.5017 - val_mae: 10.1001\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 180.2290 - mae: 8.7231 - val_loss: 196.2497 - val_mae: 9.0669\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 180.9067 - mae: 7.3234 - val_loss: 208.1114 - val_mae: 8.9169\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.1953 - mae: 6.8264 - val_loss: 184.7130 - val_mae: 8.7945\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 156.2862 - mae: 7.2174 - val_loss: 166.8014 - val_mae: 8.7132\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 142.9419 - mae: 6.9580 - val_loss: 166.3026 - val_mae: 8.7333\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 128.3503 - mae: 6.6918 - val_loss: 204.9456 - val_mae: 9.4647\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 147.8007 - mae: 7.5044 - val_loss: 200.8410 - val_mae: 9.6833\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 141.2894 - mae: 7.0640 - val_loss: 169.3060 - val_mae: 9.4898\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.3757 - mae: 7.6155 - val_loss: 140.8138 - val_mae: 9.3057\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 126.8971 - mae: 6.9743 - val_loss: 163.3242 - val_mae: 8.9523\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 139.9746 - mae: 6.7882 - val_loss: 166.4618 - val_mae: 8.9550\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 147.9648 - mae: 7.5969 - val_loss: 144.0081 - val_mae: 9.2451\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 77.1811 - mae: 6.1805 - val_loss: 159.1700 - val_mae: 8.8872\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 112.4860 - mae: 6.5817 - val_loss: 170.2013 - val_mae: 9.2775\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 93.9086 - mae: 6.2016 - val_loss: 172.2020 - val_mae: 9.2053\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 95.0668 - mae: 6.2401 - val_loss: 147.2392 - val_mae: 8.8199\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 93.1031 - mae: 6.1571 - val_loss: 142.5394 - val_mae: 8.9382\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 72.3463 - mae: 5.1662 - val_loss: 162.3324 - val_mae: 9.0957\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 94.8566 - mae: 5.7635 - val_loss: 161.7611 - val_mae: 8.9735\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 85.8560 - mae: 5.4281 - val_loss: 126.7934 - val_mae: 8.9794\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 96.9235 - mae: 6.6784 - val_loss: 136.4274 - val_mae: 8.5666\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 104.0744 - mae: 5.8560 - val_loss: 174.6172 - val_mae: 9.2693\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 95.5613 - mae: 5.4565 - val_loss: 142.6678 - val_mae: 8.7389\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 62.4349 - mae: 4.9200 - val_loss: 110.0830 - val_mae: 7.7562\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 82.5986 - mae: 5.9122 - val_loss: 103.2845 - val_mae: 7.2365\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 112.1793 - mae: 6.5758 - val_loss: 118.7059 - val_mae: 8.1105\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 74.3474 - mae: 4.9530 - val_loss: 148.5271 - val_mae: 8.5900\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 48.1575 - mae: 4.5245 - val_loss: 116.3420 - val_mae: 8.2102\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.1167 - mae: 4.8420 - val_loss: 104.5168 - val_mae: 7.6960\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 58.4238 - mae: 4.9032 - val_loss: 102.2187 - val_mae: 7.3565\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 67.6121 - mae: 5.1980 - val_loss: 121.1656 - val_mae: 7.6342\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 56.3918 - mae: 4.4861 - val_loss: 92.3805 - val_mae: 7.0411\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.3951 - mae: 5.5043 - val_loss: 89.6790 - val_mae: 6.7993\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 70.3787 - mae: 5.5141 - val_loss: 88.0152 - val_mae: 7.0301\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.0285 - mae: 4.5658 - val_loss: 81.5483 - val_mae: 7.1765\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.1401 - mae: 4.3738 - val_loss: 69.3747 - val_mae: 6.7192\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 42.3997 - mae: 4.3169 - val_loss: 79.4349 - val_mae: 6.4342\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 48.4556 - mae: 4.6344 - val_loss: 83.8172 - val_mae: 6.2924\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.3598 - mae: 4.3635 - val_loss: 93.0921 - val_mae: 6.6706\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 72.6817 - mae: 5.0247 - val_loss: 90.3154 - val_mae: 6.6220\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 68.0306 - mae: 4.9503 - val_loss: 81.7504 - val_mae: 6.1492\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 92.8366 - mae: 5.4223 - val_loss: 89.8847 - val_mae: 6.2667\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 63.5695 - mae: 4.7296 - val_loss: 179.7232 - val_mae: 7.9600\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.6212 - mae: 4.9885 - val_loss: 130.0375 - val_mae: 7.2039\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 44.4730 - mae: 4.2025 - val_loss: 69.5031 - val_mae: 5.8576\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 97.2765 - mae: 5.9554 - val_loss: 77.3145 - val_mae: 6.1069\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 43.1289 - mae: 4.5522 - val_loss: 92.0138 - val_mae: 6.3884\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.4455 - mae: 5.0109 - val_loss: 97.5334 - val_mae: 6.4429\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 47.1560 - mae: 4.7129 - val_loss: 82.8367 - val_mae: 6.0314\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 63.7065 - mae: 4.7944 - val_loss: 70.1062 - val_mae: 5.6891\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.8811 - mae: 4.4679 - val_loss: 72.3619 - val_mae: 6.1099\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 56.1731 - mae: 4.4415 - val_loss: 61.9402 - val_mae: 5.8196\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 46.0376 - mae: 4.0553 - val_loss: 65.3711 - val_mae: 5.5581\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 66.0596 - mae: 5.0413 - val_loss: 74.0334 - val_mae: 5.7046\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.7090 - mae: 4.4116 - val_loss: 66.0529 - val_mae: 5.6850\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 39.6310 - mae: 4.0347 - val_loss: 99.4222 - val_mae: 6.3788\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 72.7376 - mae: 4.8467 - val_loss: 75.5524 - val_mae: 5.8814\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.3000 - mae: 4.9440 - val_loss: 54.4272 - val_mae: 5.4765\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 48.7681 - mae: 4.5558 - val_loss: 52.5935 - val_mae: 5.3142\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.3070 - mae: 4.4655 - val_loss: 44.4267 - val_mae: 4.8783\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.5631 - mae: 4.2046 - val_loss: 50.7225 - val_mae: 4.8671\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 48.7121 - mae: 4.0649 - val_loss: 81.9770 - val_mae: 5.7890\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 75.1559 - mae: 4.5202 - val_loss: 78.4394 - val_mae: 6.0735\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 80.5291 - mae: 4.7748 - val_loss: 73.2431 - val_mae: 6.0213\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.4775 - mae: 4.6285 - val_loss: 62.6862 - val_mae: 5.7994\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 79.6318 - mae: 4.8581 - val_loss: 54.1549 - val_mae: 5.4955\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 53.7358 - mae: 4.2095 - val_loss: 52.2054 - val_mae: 5.1568\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 53.8378 - mae: 4.1025 - val_loss: 64.2171 - val_mae: 5.7762\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.2842 - mae: 4.1188 - val_loss: 48.1449 - val_mae: 5.2124\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 51.3721 - mae: 4.4734 - val_loss: 65.4626 - val_mae: 5.9718\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 34.8290 - mae: 3.7628 - val_loss: 121.6782 - val_mae: 7.2702\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.7711 - mae: 4.5659 - val_loss: 82.2244 - val_mae: 6.1082\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 73.0617 - mae: 5.0239 - val_loss: 57.4515 - val_mae: 5.3781\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 43.1612 - mae: 3.9632 - val_loss: 70.1601 - val_mae: 5.7451\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 36.5351 - mae: 3.5330 - val_loss: 63.7268 - val_mae: 5.3994\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 47.3424 - mae: 3.9784 - val_loss: 63.6851 - val_mae: 5.1074\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 40.9420 - mae: 3.8109 - val_loss: 53.2435 - val_mae: 4.9663\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.4881 - mae: 3.3053 - val_loss: 62.7270 - val_mae: 5.5543\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 59.4610 - mae: 3.8875 - val_loss: 89.6856 - val_mae: 6.2568\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 71.3044 - mae: 4.2629 - val_loss: 109.1297 - val_mae: 6.6485\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 65.5952 - mae: 3.9850 - val_loss: 63.2649 - val_mae: 5.5758\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.2790 - mae: 4.8203 - val_loss: 60.4652 - val_mae: 5.4590\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.6037 - mae: 3.8674 - val_loss: 155.5056 - val_mae: 7.5251\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 76.8308 - mae: 4.7114 - val_loss: 78.9672 - val_mae: 5.9505\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 51.2490 - mae: 4.4474 - val_loss: 56.9589 - val_mae: 5.4994\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 63.6367 - mae: 4.5255 - val_loss: 89.8382 - val_mae: 6.1341\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.7557 - mae: 4.0593 - val_loss: 121.5725 - val_mae: 6.9123\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 56.7199 - mae: 3.6627\n",
      "Test Loss: 56.7199\n",
      "Test MAE: 3.6627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.5683\n",
      "MSE: 56.7199\n",
      "MAE: 3.6627\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 3.0155 - mae: 1.2256 - val_loss: 1.8111 - val_mae: 0.9950\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5361 - mae: 1.5083 - val_loss: 0.9107 - val_mae: 0.6059\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.0794 - mae: 1.1848 - val_loss: 1.0181 - val_mae: 0.8542\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3766 - mae: 1.3721 - val_loss: 1.4139 - val_mae: 0.7824\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1264 - mae: 1.2446 - val_loss: 0.9303 - val_mae: 0.6138\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.1423 - mae: 1.2193 - val_loss: 1.3045 - val_mae: 0.6796\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9139 - mae: 0.9750 - val_loss: 0.7743 - val_mae: 0.4967\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4396 - mae: 0.8619 - val_loss: 0.9103 - val_mae: 0.5557\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5325 - mae: 0.8906 - val_loss: 0.7868 - val_mae: 0.5626\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1140 - mae: 0.7709 - val_loss: 0.9144 - val_mae: 0.5180\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9692 - mae: 0.6980 - val_loss: 0.8086 - val_mae: 0.5145\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2802 - mae: 0.7747 - val_loss: 0.7705 - val_mae: 0.4957\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8537 - mae: 0.6416 - val_loss: 0.7892 - val_mae: 0.4832\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8990 - mae: 0.6850 - val_loss: 0.7307 - val_mae: 0.4732\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8308 - mae: 0.6288 - val_loss: 0.7539 - val_mae: 0.4756\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6303 - mae: 0.5380 - val_loss: 0.7504 - val_mae: 0.4807\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7509 - mae: 0.5793 - val_loss: 0.7498 - val_mae: 0.5028\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6574 - mae: 0.5771 - val_loss: 0.7436 - val_mae: 0.4663\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6735 - mae: 0.5353 - val_loss: 0.7232 - val_mae: 0.4725\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5743 - mae: 0.5132 - val_loss: 0.7227 - val_mae: 0.4700\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4565 - mae: 0.4582 - val_loss: 0.7388 - val_mae: 0.4459\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5281 - mae: 0.4675 - val_loss: 0.7581 - val_mae: 0.4336\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4944 - mae: 0.4264 - val_loss: 0.7482 - val_mae: 0.4629\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5508 - mae: 0.5011 - val_loss: 0.7336 - val_mae: 0.5023\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5839 - mae: 0.5132 - val_loss: 0.7275 - val_mae: 0.4746\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5437 - mae: 0.4692 - val_loss: 0.7735 - val_mae: 0.4557\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6162 - mae: 0.4371 - val_loss: 0.7728 - val_mae: 0.4800\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5105 - mae: 0.4499 - val_loss: 0.7544 - val_mae: 0.4638\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5071 - mae: 0.4837 - val_loss: 0.7476 - val_mae: 0.4630\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4653 - mae: 0.4073 - val_loss: 0.7663 - val_mae: 0.4964\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5008 - mae: 0.4157 - val_loss: 0.7659 - val_mae: 0.4789\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5084 - mae: 0.4121 - val_loss: 0.7400 - val_mae: 0.4520\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4579 - mae: 0.3857 - val_loss: 0.7281 - val_mae: 0.4698\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4520 - mae: 0.3835 - val_loss: 0.7254 - val_mae: 0.4606\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4435 - mae: 0.3907 - val_loss: 0.7255 - val_mae: 0.4427\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4715 - mae: 0.4082 - val_loss: 0.7293 - val_mae: 0.4520\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4933 - mae: 0.4416 - val_loss: 0.7184 - val_mae: 0.4696\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4822 - mae: 0.4314 - val_loss: 0.7386 - val_mae: 0.5008\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4881 - mae: 0.4458 - val_loss: 0.7594 - val_mae: 0.4731\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5020 - mae: 0.3784 - val_loss: 0.7551 - val_mae: 0.4804\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5553 - mae: 0.4025 - val_loss: 0.7489 - val_mae: 0.4693\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3998 - mae: 0.3665 - val_loss: 0.7398 - val_mae: 0.5125\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4497 - mae: 0.4389 - val_loss: 0.7385 - val_mae: 0.4845\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5364 - mae: 0.4280 - val_loss: 0.7383 - val_mae: 0.4756\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4495 - mae: 0.3580 - val_loss: 0.7455 - val_mae: 0.4753\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5197 - mae: 0.3785 - val_loss: 0.7535 - val_mae: 0.4424\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3827 - mae: 0.3090 - val_loss: 0.7574 - val_mae: 0.4473\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3173 - mae: 0.3026 - val_loss: 0.7730 - val_mae: 0.4843\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5034 - mae: 0.4034 - val_loss: 0.7523 - val_mae: 0.4919\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4122 - mae: 0.3829 - val_loss: 0.7597 - val_mae: 0.4618\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3773 - mae: 0.3584 - val_loss: 0.7659 - val_mae: 0.4913\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4553 - mae: 0.3759 - val_loss: 0.7593 - val_mae: 0.4558\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3747 - mae: 0.3287 - val_loss: 0.7607 - val_mae: 0.4606\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4877 - mae: 0.3381 - val_loss: 0.7483 - val_mae: 0.4415\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4548 - mae: 0.3391 - val_loss: 0.7183 - val_mae: 0.4572\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4094 - mae: 0.3993 - val_loss: 0.7128 - val_mae: 0.4678\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4289 - mae: 0.3788 - val_loss: 0.7175 - val_mae: 0.4817\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3483 - mae: 0.3292 - val_loss: 0.7402 - val_mae: 0.4830\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5364 - mae: 0.4236 - val_loss: 0.7644 - val_mae: 0.4984\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4304 - mae: 0.3779 - val_loss: 0.7456 - val_mae: 0.4407\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3755 - mae: 0.3230 - val_loss: 0.7563 - val_mae: 0.4519\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3897 - mae: 0.3143 - val_loss: 0.7486 - val_mae: 0.4725\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4624 - mae: 0.3805 - val_loss: 0.7512 - val_mae: 0.4804\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4722 - mae: 0.3664 - val_loss: 0.7561 - val_mae: 0.4377\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5293 - mae: 0.3857 - val_loss: 0.7835 - val_mae: 0.4400\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4379 - mae: 0.3702 - val_loss: 0.7180 - val_mae: 0.4767\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5328 - mae: 0.4065 - val_loss: 0.7438 - val_mae: 0.4779\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4207 - mae: 0.3685 - val_loss: 0.7737 - val_mae: 0.4737\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3549 - mae: 0.3360 - val_loss: 0.7747 - val_mae: 0.4689\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4203 - mae: 0.3717 - val_loss: 0.7320 - val_mae: 0.4810\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3671 - mae: 0.3801 - val_loss: 0.7617 - val_mae: 0.5164\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5358 - mae: 0.4020 - val_loss: 0.7145 - val_mae: 0.4660\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3692 - mae: 0.3739 - val_loss: 0.7109 - val_mae: 0.4780\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4590 - mae: 0.3701 - val_loss: 0.7109 - val_mae: 0.4887\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4180 - mae: 0.3996 - val_loss: 0.7259 - val_mae: 0.4836\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4509 - mae: 0.3865 - val_loss: 0.7263 - val_mae: 0.4998\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3740 - mae: 0.3841 - val_loss: 0.7195 - val_mae: 0.4960\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2883 - mae: 0.3298 - val_loss: 0.7372 - val_mae: 0.4897\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3406 - mae: 0.3337 - val_loss: 0.7607 - val_mae: 0.4779\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2961 - mae: 0.3039 - val_loss: 0.7748 - val_mae: 0.5090\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3066 - mae: 0.3359 - val_loss: 0.8133 - val_mae: 0.5349\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2921 - mae: 0.3420 - val_loss: 0.7569 - val_mae: 0.5146\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3721 - mae: 0.3630 - val_loss: 0.7310 - val_mae: 0.5083\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4861 - mae: 0.4172 - val_loss: 0.7240 - val_mae: 0.4978\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4416 - mae: 0.3744 - val_loss: 0.7379 - val_mae: 0.4986\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4019 - mae: 0.3541 - val_loss: 0.7216 - val_mae: 0.4994\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4616 - mae: 0.3665 - val_loss: 0.7144 - val_mae: 0.4945\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3606 - mae: 0.3427 - val_loss: 0.7172 - val_mae: 0.4927\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4095 - mae: 0.3753 - val_loss: 0.7178 - val_mae: 0.4956\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4471 - mae: 0.3780 - val_loss: 0.7282 - val_mae: 0.4856\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4524 - mae: 0.3808 - val_loss: 0.7210 - val_mae: 0.5031\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4930 - mae: 0.3916 - val_loss: 0.7340 - val_mae: 0.5152\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3506 - mae: 0.3563 - val_loss: 0.7278 - val_mae: 0.5099\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3456 - mae: 0.3570 - val_loss: 0.7267 - val_mae: 0.5107\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3391 - mae: 0.3583 - val_loss: 0.7534 - val_mae: 0.4867\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3670 - mae: 0.3503 - val_loss: 0.7315 - val_mae: 0.5102\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4404 - mae: 0.3905 - val_loss: 0.7336 - val_mae: 0.5177\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3817 - mae: 0.3517 - val_loss: 0.7304 - val_mae: 0.4978\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4073 - mae: 0.3713 - val_loss: 0.7607 - val_mae: 0.4908\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4196 - mae: 0.3461 - val_loss: 0.7501 - val_mae: 0.5112\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5292 - mae: 0.3870\n",
      "Test Loss: 0.5292\n",
      "Test MAE: 0.3870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.1560\n",
      "MSE: 0.5292\n",
      "MAE: 0.3870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.2483 - mae: 1.2836 - val_loss: 1.2196 - val_mae: 0.8011\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.4364 - mae: 1.5224 - val_loss: 0.4782 - val_mae: 0.4705\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2671 - mae: 1.2569 - val_loss: 0.4989 - val_mae: 0.5201\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.4503 - mae: 1.2742 - val_loss: 1.0341 - val_mae: 0.5846\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.8865 - mae: 1.1789 - val_loss: 0.8571 - val_mae: 0.5975\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6440 - mae: 1.1744 - val_loss: 0.5870 - val_mae: 0.5358\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0324 - mae: 1.0391 - val_loss: 0.4784 - val_mae: 0.4359\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0666 - mae: 0.9368 - val_loss: 0.4081 - val_mae: 0.3950\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4284 - mae: 0.8485 - val_loss: 0.3168 - val_mae: 0.3743\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8217 - mae: 0.8720 - val_loss: 0.3768 - val_mae: 0.4178\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2726 - mae: 0.7795 - val_loss: 0.4134 - val_mae: 0.3983\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5413 - mae: 0.7475 - val_loss: 0.3737 - val_mae: 0.3470\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6770 - mae: 0.5863 - val_loss: 0.2841 - val_mae: 0.3416\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7986 - mae: 0.6074 - val_loss: 0.2638 - val_mae: 0.3534\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8804 - mae: 0.5875 - val_loss: 0.3460 - val_mae: 0.3698\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6592 - mae: 0.5330 - val_loss: 0.4530 - val_mae: 0.3784\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4502 - mae: 0.4527 - val_loss: 0.4654 - val_mae: 0.3879\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5290 - mae: 0.5206 - val_loss: 0.4079 - val_mae: 0.3856\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4402 - mae: 0.4616 - val_loss: 0.3815 - val_mae: 0.3935\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5174 - mae: 0.4987 - val_loss: 0.3843 - val_mae: 0.3798\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4539 - mae: 0.4727 - val_loss: 0.3596 - val_mae: 0.3614\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4641 - mae: 0.4532 - val_loss: 0.3621 - val_mae: 0.3560\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4109 - mae: 0.4501 - val_loss: 0.3722 - val_mae: 0.3697\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5804 - mae: 0.4703 - val_loss: 0.3452 - val_mae: 0.3572\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4469 - mae: 0.4357 - val_loss: 0.3184 - val_mae: 0.3560\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4226 - mae: 0.4557 - val_loss: 0.3091 - val_mae: 0.3558\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4321 - mae: 0.4361 - val_loss: 0.3468 - val_mae: 0.3553\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3518 - mae: 0.3867 - val_loss: 0.3578 - val_mae: 0.3413\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4357 - mae: 0.4304 - val_loss: 0.3522 - val_mae: 0.3401\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3644 - mae: 0.3907 - val_loss: 0.3292 - val_mae: 0.3390\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4009 - mae: 0.4310 - val_loss: 0.3482 - val_mae: 0.3515\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4196 - mae: 0.4209 - val_loss: 0.3250 - val_mae: 0.3434\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3825 - mae: 0.4173 - val_loss: 0.3409 - val_mae: 0.3529\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4370 - mae: 0.4555 - val_loss: 0.3404 - val_mae: 0.3554\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4139 - mae: 0.4231 - val_loss: 0.3308 - val_mae: 0.3363\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3887 - mae: 0.3965 - val_loss: 0.3449 - val_mae: 0.3453\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3874 - mae: 0.3954 - val_loss: 0.3170 - val_mae: 0.3228\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3140 - mae: 0.3534 - val_loss: 0.3167 - val_mae: 0.3149\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2949 - mae: 0.3515 - val_loss: 0.3111 - val_mae: 0.3125\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2793 - mae: 0.3420 - val_loss: 0.3245 - val_mae: 0.3100\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3396 - mae: 0.3661 - val_loss: 0.3381 - val_mae: 0.3269\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3902 - mae: 0.3916 - val_loss: 0.3370 - val_mae: 0.3254\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2973 - mae: 0.3683 - val_loss: 0.3538 - val_mae: 0.3489\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2680 - mae: 0.3376 - val_loss: 0.3573 - val_mae: 0.3237\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3490 - mae: 0.3836 - val_loss: 0.3492 - val_mae: 0.3201\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2634 - mae: 0.3047 - val_loss: 0.3421 - val_mae: 0.3154\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2633 - mae: 0.3175 - val_loss: 0.3246 - val_mae: 0.3220\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3554 - mae: 0.3778 - val_loss: 0.3097 - val_mae: 0.3485\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2802 - mae: 0.3418 - val_loss: 0.2748 - val_mae: 0.3465\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3097 - mae: 0.3539 - val_loss: 0.2740 - val_mae: 0.3423\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3295 - mae: 0.3784 - val_loss: 0.2994 - val_mae: 0.3548\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2721 - mae: 0.3471 - val_loss: 0.3157 - val_mae: 0.3597\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2692 - mae: 0.3388 - val_loss: 0.2887 - val_mae: 0.3442\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2312 - mae: 0.3124 - val_loss: 0.2667 - val_mae: 0.3320\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2234 - mae: 0.2941 - val_loss: 0.2597 - val_mae: 0.3278\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3115 - mae: 0.3404 - val_loss: 0.2920 - val_mae: 0.3380\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2727 - mae: 0.3279 - val_loss: 0.3314 - val_mae: 0.3653\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2858 - mae: 0.3548 - val_loss: 0.3670 - val_mae: 0.3729\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2804 - mae: 0.3291 - val_loss: 0.3033 - val_mae: 0.3210\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3019 - mae: 0.3293 - val_loss: 0.2387 - val_mae: 0.3363\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2982 - mae: 0.3343 - val_loss: 0.2589 - val_mae: 0.3274\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2550 - mae: 0.3169 - val_loss: 0.2975 - val_mae: 0.3618\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2490 - mae: 0.3002 - val_loss: 0.3472 - val_mae: 0.3412\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2738 - mae: 0.2905 - val_loss: 0.3657 - val_mae: 0.3320\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2522 - mae: 0.2847 - val_loss: 0.3381 - val_mae: 0.3187\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2325 - mae: 0.2793 - val_loss: 0.3001 - val_mae: 0.3283\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2547 - mae: 0.3111 - val_loss: 0.2721 - val_mae: 0.3633\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3010 - mae: 0.3880 - val_loss: 0.2589 - val_mae: 0.3597\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2212 - mae: 0.3263 - val_loss: 0.2587 - val_mae: 0.3224\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2536 - mae: 0.2948 - val_loss: 0.2366 - val_mae: 0.3113\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2584 - mae: 0.2985 - val_loss: 0.2265 - val_mae: 0.2884\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2183 - mae: 0.2641 - val_loss: 0.2052 - val_mae: 0.2823\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3377 - mae: 0.3266 - val_loss: 0.2444 - val_mae: 0.2873\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2720 - mae: 0.2779 - val_loss: 0.3073 - val_mae: 0.3232\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2751 - mae: 0.2879 - val_loss: 0.3430 - val_mae: 0.3484\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2680 - mae: 0.2920 - val_loss: 0.3205 - val_mae: 0.3382\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2736 - mae: 0.2878 - val_loss: 0.2572 - val_mae: 0.3179\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2619 - mae: 0.3096 - val_loss: 0.2430 - val_mae: 0.3160\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2830 - mae: 0.3123 - val_loss: 0.2416 - val_mae: 0.3097\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3032 - mae: 0.3134 - val_loss: 0.2758 - val_mae: 0.3181\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2320 - mae: 0.2795 - val_loss: 0.2804 - val_mae: 0.3217\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2279 - mae: 0.2773 - val_loss: 0.2613 - val_mae: 0.3173\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2545 - mae: 0.3007 - val_loss: 0.2456 - val_mae: 0.3092\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2869 - mae: 0.3101 - val_loss: 0.2517 - val_mae: 0.3155\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.3082 - val_loss: 0.2880 - val_mae: 0.3390\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2424 - mae: 0.3146 - val_loss: 0.3272 - val_mae: 0.4184\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2556 - mae: 0.3389 - val_loss: 0.2682 - val_mae: 0.3422\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2881 - mae: 0.3377 - val_loss: 0.2321 - val_mae: 0.3390\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2586 - mae: 0.3184 - val_loss: 0.2305 - val_mae: 0.3245\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2373 - mae: 0.2989 - val_loss: 0.2324 - val_mae: 0.3191\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2646 - mae: 0.3203 - val_loss: 0.2502 - val_mae: 0.3233\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2889 - mae: 0.3303 - val_loss: 0.3277 - val_mae: 0.3470\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2373 - mae: 0.2987 - val_loss: 0.3453 - val_mae: 0.3675\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2535 - mae: 0.3161 - val_loss: 0.3372 - val_mae: 0.3607\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3079 - mae: 0.3384 - val_loss: 0.3492 - val_mae: 0.3620\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2983 - mae: 0.3466 - val_loss: 0.3415 - val_mae: 0.3637\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3301 - mae: 0.3273 - val_loss: 0.2723 - val_mae: 0.3360\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3119 - mae: 0.3428 - val_loss: 0.2906 - val_mae: 0.3284\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2699 - mae: 0.3060 - val_loss: 0.4047 - val_mae: 0.3951\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2370 - mae: 0.3108 - val_loss: 0.3428 - val_mae: 0.4020\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3544 - mae: 0.3946\n",
      "Test Loss: 0.3544\n",
      "Test MAE: 0.3946\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "R^2 Score: 0.1442\n",
      "MSE: 0.3544\n",
      "MAE: 0.3946\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 4.5201 - mae: 1.3178 - val_loss: 0.6157 - val_mae: 0.4611\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.1411 - mae: 1.6593 - val_loss: 0.7821 - val_mae: 0.5262\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.8320 - mae: 1.2407 - val_loss: 0.7280 - val_mae: 0.7223\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.2212 - mae: 1.3829 - val_loss: 0.6465 - val_mae: 0.6766\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.4847 - mae: 1.1140 - val_loss: 3.9373 - val_mae: 0.9869\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.8261 - mae: 1.2096 - val_loss: 3.4727 - val_mae: 0.9944\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.8822 - mae: 1.1139 - val_loss: 0.6576 - val_mae: 0.6558\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2812 - mae: 1.2868 - val_loss: 0.1969 - val_mae: 0.3267\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3593 - mae: 1.0389 - val_loss: 0.2309 - val_mae: 0.3125\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.5912 - mae: 1.0055 - val_loss: 0.1809 - val_mae: 0.3072\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2824 - mae: 0.8902 - val_loss: 0.4076 - val_mae: 0.4781\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7805 - mae: 0.8548 - val_loss: 0.2962 - val_mae: 0.4341\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2573 - mae: 0.6907 - val_loss: 0.2853 - val_mae: 0.3589\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0170 - mae: 0.7080 - val_loss: 0.2211 - val_mae: 0.2884\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6480 - mae: 0.7712 - val_loss: 0.3434 - val_mae: 0.4287\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7132 - mae: 0.6168 - val_loss: 0.7817 - val_mae: 0.6475\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1991 - mae: 0.7090 - val_loss: 0.7920 - val_mae: 0.6403\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.9177 - mae: 0.6330 - val_loss: 0.4154 - val_mae: 0.4412\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7917 - mae: 0.5347 - val_loss: 0.2416 - val_mae: 0.3044\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6697 - mae: 0.4946 - val_loss: 0.1726 - val_mae: 0.2365\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8884 - mae: 0.5874 - val_loss: 0.2982 - val_mae: 0.3726\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6821 - mae: 0.5029 - val_loss: 0.3395 - val_mae: 0.4087\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5767 - mae: 0.4836 - val_loss: 0.2479 - val_mae: 0.3409\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4626 - mae: 0.4199 - val_loss: 0.2219 - val_mae: 0.3127\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7994 - mae: 0.5207 - val_loss: 0.2799 - val_mae: 0.3417\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1179 - mae: 0.6179 - val_loss: 0.2366 - val_mae: 0.3261\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4260 - mae: 0.4014 - val_loss: 0.2516 - val_mae: 0.3388\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4822 - mae: 0.4442 - val_loss: 0.2287 - val_mae: 0.3208\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3629 - mae: 0.3528 - val_loss: 0.2572 - val_mae: 0.3459\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2529 - mae: 0.2995 - val_loss: 0.2334 - val_mae: 0.3323\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5041 - mae: 0.4316 - val_loss: 0.3147 - val_mae: 0.3844\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3800 - mae: 0.3919 - val_loss: 0.4202 - val_mae: 0.4462\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4806 - mae: 0.3706 - val_loss: 0.3380 - val_mae: 0.4007\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5454 - mae: 0.3678 - val_loss: 0.1626 - val_mae: 0.2782\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7819 - mae: 0.3847 - val_loss: 0.3012 - val_mae: 0.3850\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4766 - mae: 0.3885 - val_loss: 0.4104 - val_mae: 0.4415\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2381 - mae: 0.3089 - val_loss: 0.3434 - val_mae: 0.4121\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3732 - mae: 0.3458 - val_loss: 0.2405 - val_mae: 0.3522\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - mae: 0.5030 - val_loss: 0.1787 - val_mae: 0.3045\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4601 - mae: 0.4081 - val_loss: 0.1719 - val_mae: 0.2925\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5002 - mae: 0.3638 - val_loss: 0.2504 - val_mae: 0.3512\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4406 - mae: 0.3805 - val_loss: 0.3003 - val_mae: 0.3768\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4847 - mae: 0.3720 - val_loss: 0.2308 - val_mae: 0.3327\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3556 - mae: 0.3600 - val_loss: 0.1840 - val_mae: 0.2975\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3605 - mae: 0.3538 - val_loss: 0.2128 - val_mae: 0.3149\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3931 - mae: 0.3687 - val_loss: 0.1834 - val_mae: 0.2965\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4972 - mae: 0.3981 - val_loss: 0.2532 - val_mae: 0.3476\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5626 - mae: 0.4121 - val_loss: 0.3711 - val_mae: 0.4181\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2716 - mae: 0.3043 - val_loss: 0.3895 - val_mae: 0.4309\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3522 - mae: 0.3598 - val_loss: 0.4236 - val_mae: 0.4461\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4208 - mae: 0.3835 - val_loss: 0.5038 - val_mae: 0.4866\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3744 - mae: 0.3434 - val_loss: 0.4287 - val_mae: 0.4535\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2321 - mae: 0.2777 - val_loss: 0.2870 - val_mae: 0.3824\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3179 - mae: 0.3276 - val_loss: 0.2173 - val_mae: 0.3376\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2877 - mae: 0.3117 - val_loss: 0.2359 - val_mae: 0.3478\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4244 - mae: 0.3541 - val_loss: 0.2191 - val_mae: 0.3307\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2911 - mae: 0.3415 - val_loss: 0.2675 - val_mae: 0.3587\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2509 - mae: 0.2999 - val_loss: 0.3141 - val_mae: 0.3860\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3965 - mae: 0.3468 - val_loss: 0.2474 - val_mae: 0.3441\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2717 - mae: 0.3114 - val_loss: 0.2399 - val_mae: 0.3484\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1296 - mae: 0.2392 - val_loss: 0.1776 - val_mae: 0.2988\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5114 - mae: 0.4046 - val_loss: 0.2396 - val_mae: 0.3482\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2553 - mae: 0.2994 - val_loss: 0.4855 - val_mae: 0.4809\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3362 - mae: 0.3427 - val_loss: 0.4797 - val_mae: 0.4811\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2552 - mae: 0.3032 - val_loss: 0.3563 - val_mae: 0.4223\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2906 - mae: 0.3333 - val_loss: 0.2979 - val_mae: 0.3935\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3233 - mae: 0.3249 - val_loss: 0.3473 - val_mae: 0.4210\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2415 - mae: 0.2874 - val_loss: 0.2854 - val_mae: 0.3816\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3044 - mae: 0.3211 - val_loss: 0.2165 - val_mae: 0.3387\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2684 - mae: 0.3137 - val_loss: 0.1466 - val_mae: 0.2894\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5098 - mae: 0.3465 - val_loss: 0.2750 - val_mae: 0.3757\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2042 - mae: 0.2860 - val_loss: 0.4254 - val_mae: 0.4529\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4174 - mae: 0.3242 - val_loss: 0.3516 - val_mae: 0.4140\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3369 - mae: 0.3119 - val_loss: 0.1616 - val_mae: 0.2968\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2543 - mae: 0.3170 - val_loss: 0.1069 - val_mae: 0.2492\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4630 - mae: 0.3908 - val_loss: 0.2243 - val_mae: 0.3449\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2858 - mae: 0.2939 - val_loss: 0.3918 - val_mae: 0.4340\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4003 - mae: 0.3592 - val_loss: 0.3154 - val_mae: 0.3981\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2489 - mae: 0.2993 - val_loss: 0.1955 - val_mae: 0.3213\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2411 - mae: 0.3020 - val_loss: 0.2012 - val_mae: 0.3187\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2772 - mae: 0.3048 - val_loss: 0.2404 - val_mae: 0.3496\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2240 - mae: 0.2878 - val_loss: 0.2797 - val_mae: 0.3784\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2349 - mae: 0.3005 - val_loss: 0.3433 - val_mae: 0.4133\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2885 - mae: 0.3137 - val_loss: 0.4291 - val_mae: 0.4531\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2928 - mae: 0.3266 - val_loss: 0.3578 - val_mae: 0.4204\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2625 - mae: 0.3026 - val_loss: 0.1892 - val_mae: 0.3166\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2530 - mae: 0.2984 - val_loss: 0.0602 - val_mae: 0.1834\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2343 - mae: 0.2973 - val_loss: 0.1568 - val_mae: 0.2974\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1582 - mae: 0.2581 - val_loss: 0.3962 - val_mae: 0.4408\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3936 - mae: 0.3532 - val_loss: 0.3756 - val_mae: 0.4368\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2271 - mae: 0.2941 - val_loss: 0.1658 - val_mae: 0.3009\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1988 - mae: 0.2830 - val_loss: 0.1323 - val_mae: 0.2622\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3297 - mae: 0.3390 - val_loss: 0.2602 - val_mae: 0.3698\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3234 - mae: 0.3351 - val_loss: 0.3493 - val_mae: 0.4273\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1809 - mae: 0.2790 - val_loss: 0.3281 - val_mae: 0.4177\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2729 - mae: 0.3119 - val_loss: 0.3063 - val_mae: 0.4020\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3406 - mae: 0.3588 - val_loss: 0.2972 - val_mae: 0.3950\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3169 - mae: 0.3174 - val_loss: 0.2274 - val_mae: 0.3493\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3049 - mae: 0.3292 - val_loss: 0.2739 - val_mae: 0.3873\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2838 - mae: 0.3177 - val_loss: 0.3451 - val_mae: 0.4211\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1923 - mae: 0.2826\n",
      "Test Loss: 0.1923\n",
      "Test MAE: 0.2826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.8572\n",
      "MSE: 0.1923\n",
      "MAE: 0.2826\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.6025 - mae: 1.1446 - val_loss: 1.7000 - val_mae: 0.9857\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.6519 - mae: 1.3215 - val_loss: 2.0396 - val_mae: 0.9646\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.6195 - mae: 1.6759 - val_loss: 1.8336 - val_mae: 1.0505\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.0975 - mae: 1.3151 - val_loss: 2.3535 - val_mae: 1.2213\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.4721 - mae: 1.2799 - val_loss: 1.7206 - val_mae: 0.8043\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.7412 - mae: 1.3053 - val_loss: 2.2410 - val_mae: 0.8963\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8861 - mae: 1.2104 - val_loss: 0.7941 - val_mae: 0.5476\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.2187 - mae: 1.1167 - val_loss: 0.9881 - val_mae: 0.6431\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7462 - mae: 0.9657 - val_loss: 1.2271 - val_mae: 0.7941\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6917 - mae: 0.9336 - val_loss: 0.8796 - val_mae: 0.6307\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.8897 - mae: 0.9889 - val_loss: 1.1698 - val_mae: 0.7030\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.8094 - mae: 0.9287 - val_loss: 1.2762 - val_mae: 0.6456\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6685 - mae: 0.8762 - val_loss: 1.1454 - val_mae: 0.6774\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.4407 - mae: 0.8540 - val_loss: 1.2085 - val_mae: 0.7590\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.4603 - mae: 0.8617 - val_loss: 1.1725 - val_mae: 0.7308\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.8772 - mae: 0.8586 - val_loss: 0.9831 - val_mae: 0.6373\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6283 - mae: 0.7802 - val_loss: 0.9151 - val_mae: 0.5578\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4124 - mae: 0.7579 - val_loss: 0.8773 - val_mae: 0.5789\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6971 - mae: 0.5790 - val_loss: 0.8326 - val_mae: 0.5256\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9142 - mae: 0.6252 - val_loss: 0.7586 - val_mae: 0.4948\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - mae: 0.5864 - val_loss: 0.7471 - val_mae: 0.4805\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8478 - mae: 0.6324 - val_loss: 0.8091 - val_mae: 0.5387\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9579 - mae: 0.6532 - val_loss: 0.8045 - val_mae: 0.5399\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8117 - mae: 0.6112 - val_loss: 0.8382 - val_mae: 0.5308\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8237 - mae: 0.5935 - val_loss: 0.8167 - val_mae: 0.5137\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6564 - mae: 0.5290 - val_loss: 0.8010 - val_mae: 0.4862\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7185 - mae: 0.5353 - val_loss: 0.7936 - val_mae: 0.4664\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6769 - mae: 0.4940 - val_loss: 0.7630 - val_mae: 0.4965\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6296 - mae: 0.5093 - val_loss: 0.7551 - val_mae: 0.4940\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6653 - mae: 0.5033 - val_loss: 0.8009 - val_mae: 0.4814\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5349 - mae: 0.4500 - val_loss: 0.8974 - val_mae: 0.5149\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4793 - mae: 0.4212 - val_loss: 0.9834 - val_mae: 0.5780\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5629 - mae: 0.4558 - val_loss: 0.8060 - val_mae: 0.5004\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5663 - mae: 0.4802 - val_loss: 0.7752 - val_mae: 0.5143\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5936 - mae: 0.4857 - val_loss: 0.7356 - val_mae: 0.5137\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5255 - mae: 0.4764 - val_loss: 0.7181 - val_mae: 0.5187\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5779 - mae: 0.4751 - val_loss: 0.7134 - val_mae: 0.5134\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5097 - mae: 0.4700 - val_loss: 0.7636 - val_mae: 0.4815\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5490 - mae: 0.4368 - val_loss: 0.7780 - val_mae: 0.4667\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6310 - mae: 0.4596 - val_loss: 0.7316 - val_mae: 0.4948\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4458 - mae: 0.4260 - val_loss: 0.7131 - val_mae: 0.4834\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5192 - mae: 0.4283 - val_loss: 0.7225 - val_mae: 0.4559\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6376 - mae: 0.4381 - val_loss: 0.7258 - val_mae: 0.4619\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4722 - mae: 0.3736 - val_loss: 0.7128 - val_mae: 0.4744\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5671 - mae: 0.4478 - val_loss: 0.7195 - val_mae: 0.4847\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5286 - mae: 0.4182 - val_loss: 0.7504 - val_mae: 0.4847\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4580 - mae: 0.3979 - val_loss: 0.7775 - val_mae: 0.4801\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4546 - mae: 0.3604 - val_loss: 0.7876 - val_mae: 0.4896\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4855 - mae: 0.3945 - val_loss: 0.7921 - val_mae: 0.4883\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3742 - mae: 0.3495 - val_loss: 0.7756 - val_mae: 0.4897\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4063 - mae: 0.3786 - val_loss: 0.7931 - val_mae: 0.4990\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3812 - mae: 0.3655 - val_loss: 0.8682 - val_mae: 0.5443\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4719 - mae: 0.4011 - val_loss: 0.8018 - val_mae: 0.4956\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4919 - mae: 0.4071 - val_loss: 0.7174 - val_mae: 0.4534\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4924 - mae: 0.3850 - val_loss: 0.7240 - val_mae: 0.4627\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4053 - mae: 0.3616 - val_loss: 0.7366 - val_mae: 0.4738\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4099 - mae: 0.3673 - val_loss: 0.7783 - val_mae: 0.5087\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6298 - mae: 0.4637 - val_loss: 0.7593 - val_mae: 0.5116\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4905 - mae: 0.4058 - val_loss: 0.7104 - val_mae: 0.4799\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5360 - mae: 0.3780 - val_loss: 0.7495 - val_mae: 0.4600\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4712 - mae: 0.3607 - val_loss: 0.7263 - val_mae: 0.4557\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4730 - mae: 0.3724 - val_loss: 0.6834 - val_mae: 0.4403\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4263 - mae: 0.3579 - val_loss: 0.6598 - val_mae: 0.4683\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4606 - mae: 0.3907 - val_loss: 0.6850 - val_mae: 0.4692\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5124 - mae: 0.4442 - val_loss: 0.7458 - val_mae: 0.4633\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5075 - mae: 0.4497 - val_loss: 0.6986 - val_mae: 0.5035\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4822 - mae: 0.4357 - val_loss: 0.6821 - val_mae: 0.4970\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4247 - mae: 0.3980 - val_loss: 0.6969 - val_mae: 0.4923\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4574 - mae: 0.3729 - val_loss: 0.7577 - val_mae: 0.5073\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4672 - mae: 0.3895 - val_loss: 0.7221 - val_mae: 0.4973\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4740 - mae: 0.3830 - val_loss: 0.7102 - val_mae: 0.4984\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4826 - mae: 0.3975 - val_loss: 0.7251 - val_mae: 0.5008\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4426 - mae: 0.4016 - val_loss: 0.7464 - val_mae: 0.4992\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4342 - mae: 0.3905 - val_loss: 0.7626 - val_mae: 0.5008\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4743 - mae: 0.4114 - val_loss: 0.7574 - val_mae: 0.4992\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3602 - mae: 0.3634 - val_loss: 0.7762 - val_mae: 0.5153\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5154 - mae: 0.4260 - val_loss: 0.7508 - val_mae: 0.4915\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4183 - mae: 0.3603 - val_loss: 0.7011 - val_mae: 0.4717\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5019 - mae: 0.4104 - val_loss: 0.7033 - val_mae: 0.4722\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4939 - mae: 0.4154 - val_loss: 0.7512 - val_mae: 0.4981\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4906 - mae: 0.3867 - val_loss: 0.7544 - val_mae: 0.5026\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3927 - mae: 0.3503 - val_loss: 0.7580 - val_mae: 0.5140\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4177 - mae: 0.3805 - val_loss: 0.7405 - val_mae: 0.5137\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4904 - mae: 0.4158 - val_loss: 0.7214 - val_mae: 0.5138\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4807 - mae: 0.4389 - val_loss: 0.7479 - val_mae: 0.5161\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4314 - mae: 0.3895 - val_loss: 0.7667 - val_mae: 0.5255\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3799 - mae: 0.3957 - val_loss: 0.7254 - val_mae: 0.5045\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4710 - mae: 0.4338 - val_loss: 0.7113 - val_mae: 0.4886\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3975 - mae: 0.3890 - val_loss: 0.6940 - val_mae: 0.4756\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3921 - mae: 0.3753 - val_loss: 0.7494 - val_mae: 0.4986\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4797 - mae: 0.4205 - val_loss: 0.8313 - val_mae: 0.5442\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4807 - mae: 0.4070 - val_loss: 0.7594 - val_mae: 0.5039\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3854 - mae: 0.3518 - val_loss: 0.7367 - val_mae: 0.5024\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4601 - mae: 0.3975 - val_loss: 0.7265 - val_mae: 0.5075\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5132 - mae: 0.4255 - val_loss: 0.7178 - val_mae: 0.5024\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4605 - mae: 0.4055 - val_loss: 0.6792 - val_mae: 0.4773\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3980 - mae: 0.3593 - val_loss: 0.6595 - val_mae: 0.4597\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4214 - mae: 0.3804 - val_loss: 0.6578 - val_mae: 0.4521\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4305 - mae: 0.3554 - val_loss: 0.7080 - val_mae: 0.4768\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4967 - mae: 0.3958 - val_loss: 0.7538 - val_mae: 0.5108\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5661 - mae: 0.4146\n",
      "Test Loss: 0.5661\n",
      "Test MAE: 0.4146\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.2993\n",
      "MSE: 0.5661\n",
      "MAE: 0.4146\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "for col in target.columns:\n",
    "    y = target[col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # split training data into training and validation data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = NN_model(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    y_predicted[col] = model.predict(X_test).flatten()\n",
    "    y_truth[col] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.024462</td>\n",
       "      <td>4.836507</td>\n",
       "      <td>0.581650</td>\n",
       "      <td>0.420489</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>0.586327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.768311</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>0.226264</td>\n",
       "      <td>0.303186</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>0.338433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.140375</td>\n",
       "      <td>0.171545</td>\n",
       "      <td>0.144541</td>\n",
       "      <td>0.154827</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>0.183050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.868496</td>\n",
       "      <td>33.733025</td>\n",
       "      <td>0.144541</td>\n",
       "      <td>0.342344</td>\n",
       "      <td>2.722680</td>\n",
       "      <td>0.109338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.520661</td>\n",
       "      <td>0.101497</td>\n",
       "      <td>0.048329</td>\n",
       "      <td>0.072261</td>\n",
       "      <td>0.180340</td>\n",
       "      <td>0.049769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      20.024462       4.836507       0.581650       0.420489       0.110299   \n",
       "1      24.768311       0.306895       0.226264       0.303186       0.110299   \n",
       "2      -0.140375       0.171545       0.144541       0.154827       0.110299   \n",
       "3      19.868496      33.733025       0.144541       0.342344       2.722680   \n",
       "4       3.520661       0.101497       0.048329       0.072261       0.180340   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0       0.586327  \n",
       "1       0.338433  \n",
       "2       0.183050  \n",
       "3       0.109338  \n",
       "4       0.049769  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.739658</td>\n",
       "      <td>40.735563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.91524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.660000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      30.000000      25.000000            0.5            2.0        0.00000   \n",
       "1      50.000000       0.000000            0.0            0.0        0.00000   \n",
       "2       0.000000       0.000000            0.0            1.5        0.00000   \n",
       "3      34.739658      40.735563            0.0            0.0        3.91524   \n",
       "4       8.660000       2.180000            0.0            0.0        0.72000   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0            1.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42913293043177275"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for all target variables\n",
    "r2 = r2_score(y_truth, y_predicted)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <td>0.549681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <td>0.568295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <td>0.156038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <td>0.144207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <td>0.857244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formate (g/L)</th>\n",
       "      <td>0.299333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R^2 Score\n",
       "Glucose (g/L)   0.549681\n",
       "Lactate (g/L)   0.568295\n",
       "Ethanol (g/L)   0.156038\n",
       "Acetate (g/L)   0.144207\n",
       "Biomass (g/L)   0.857244\n",
       "Formate (g/L)   0.299333"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for each target variable\n",
    "r2 = r2_score(y_truth, y_predicted, multioutput='raw_values')\n",
    "\n",
    "# convert to a dataframe\n",
    "r2 = pd.DataFrame(r2, index=target.columns, columns=['R^2 Score'])\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The combined r2 score is: **0.42913293043177275** [curr]\n",
    "\n",
    "The combined r2 score is: **0.35816286323129254** *[2]*\n",
    "\n",
    "The combined r2 score is: **0.2843934946185081** *[3]*\n",
    "\n",
    "The combined r2 score is: **0.33809704738378416** *[4]*\n",
    "\n",
    "\n",
    "Which is an average score.\n",
    "\n",
    "Individually for each target variable, the r2 score has high variability. With Biomass being predicted most accurately with a score of 0.857244, and acetate being predicted most poorly with a score of 0.144207."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. With the complete dataset undergone PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = pd.DataFrame(columns=target.columns)\n",
    "y_truth = pd.DataFrame(columns=target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 392.6013 - mae: 13.4916 - val_loss: 332.9871 - val_mae: 14.1526\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.3870 - mae: 11.9153 - val_loss: 275.4960 - val_mae: 13.5173\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 300.3630 - mae: 12.7339 - val_loss: 252.5392 - val_mae: 13.2818\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 269.3015 - mae: 12.1427 - val_loss: 244.6939 - val_mae: 12.9784\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 285.2235 - mae: 12.8012 - val_loss: 240.3986 - val_mae: 12.8313\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 286.8362 - mae: 12.8263 - val_loss: 231.1400 - val_mae: 12.7048\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 228.8675 - mae: 11.1457 - val_loss: 224.3524 - val_mae: 12.6588\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 257.5343 - mae: 11.9289 - val_loss: 218.4052 - val_mae: 12.5742\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 242.2591 - mae: 11.8830 - val_loss: 213.7852 - val_mae: 12.4542\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.9006 - mae: 11.6143 - val_loss: 207.6593 - val_mae: 12.2381\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 219.3329 - mae: 11.1024 - val_loss: 200.9764 - val_mae: 12.0413\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 198.9117 - mae: 10.9682 - val_loss: 191.8425 - val_mae: 11.7053\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 201.8862 - mae: 10.9788 - val_loss: 184.6101 - val_mae: 11.3816\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 214.2446 - mae: 11.1423 - val_loss: 177.7705 - val_mae: 11.0073\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 202.6558 - mae: 10.7314 - val_loss: 171.3606 - val_mae: 10.6358\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 208.0904 - mae: 10.7289 - val_loss: 167.0846 - val_mae: 10.3330\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 183.0582 - mae: 10.7530 - val_loss: 160.9156 - val_mae: 9.9443\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 177.7901 - mae: 10.1471 - val_loss: 154.4648 - val_mae: 9.5135\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 165.8016 - mae: 10.0129 - val_loss: 148.3249 - val_mae: 9.0046\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 167.7606 - mae: 9.7805 - val_loss: 146.2701 - val_mae: 8.8351\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 166.5635 - mae: 10.1153 - val_loss: 145.2905 - val_mae: 8.7222\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.7370 - mae: 9.5831 - val_loss: 143.6439 - val_mae: 8.4641\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.9014 - mae: 10.4087 - val_loss: 144.4069 - val_mae: 8.4102\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 151.5508 - mae: 9.2614 - val_loss: 146.6925 - val_mae: 8.5139\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 156.5654 - mae: 9.4489 - val_loss: 151.2426 - val_mae: 8.7501\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.1231 - mae: 9.6568 - val_loss: 157.5204 - val_mae: 8.9791\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.1182 - mae: 9.7997 - val_loss: 164.9353 - val_mae: 9.2080\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.4600 - mae: 8.7938 - val_loss: 168.9886 - val_mae: 9.3296\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 137.9079 - mae: 9.1101 - val_loss: 168.7696 - val_mae: 9.1944\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 139.6238 - mae: 9.0800 - val_loss: 166.9022 - val_mae: 8.9324\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 146.2669 - mae: 9.2152 - val_loss: 166.6445 - val_mae: 8.7678\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 148.8496 - mae: 8.9208 - val_loss: 168.1214 - val_mae: 8.7355\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 118.0606 - mae: 7.8814 - val_loss: 169.6323 - val_mae: 8.7554\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 146.7439 - mae: 8.7829 - val_loss: 168.5230 - val_mae: 8.5911\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 131.2964 - mae: 8.2322 - val_loss: 164.2701 - val_mae: 8.5559\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 125.1765 - mae: 8.1505 - val_loss: 160.8023 - val_mae: 8.6773\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 119.3868 - mae: 8.2537 - val_loss: 158.6029 - val_mae: 8.5692\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 116.4603 - mae: 7.8868 - val_loss: 157.8481 - val_mae: 8.4602\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 135.6921 - mae: 8.5491 - val_loss: 156.6868 - val_mae: 8.4062\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.5226 - mae: 8.1937 - val_loss: 158.6907 - val_mae: 8.7708\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 153.7593 - mae: 8.9706 - val_loss: 162.1233 - val_mae: 8.9131\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 108.3104 - mae: 7.5559 - val_loss: 162.4930 - val_mae: 8.8880\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 120.4406 - mae: 8.0694 - val_loss: 162.5607 - val_mae: 8.8209\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 135.7471 - mae: 8.6253 - val_loss: 165.6491 - val_mae: 8.8849\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 127.4640 - mae: 8.5195 - val_loss: 164.3635 - val_mae: 8.8643\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 117.8496 - mae: 8.2145 - val_loss: 161.3213 - val_mae: 8.6975\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 138.0135 - mae: 8.7125 - val_loss: 162.0528 - val_mae: 8.7251\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.2794 - mae: 8.8822 - val_loss: 167.4474 - val_mae: 8.9686\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 127.6065 - mae: 8.2744 - val_loss: 165.9848 - val_mae: 8.7362\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 139.0412 - mae: 8.5647 - val_loss: 164.6433 - val_mae: 8.5308\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 127.2035 - mae: 8.1775 - val_loss: 162.6037 - val_mae: 8.5885\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 124.6795 - mae: 8.3033 - val_loss: 159.8779 - val_mae: 8.6696\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 128.3506 - mae: 8.4034 - val_loss: 157.4785 - val_mae: 8.6162\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 129.0181 - mae: 8.2356 - val_loss: 158.1317 - val_mae: 8.6733\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 148.3336 - mae: 9.1335 - val_loss: 161.8436 - val_mae: 8.8443\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 135.3282 - mae: 8.2699 - val_loss: 166.1584 - val_mae: 9.0360\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 141.0623 - mae: 8.5729 - val_loss: 171.5967 - val_mae: 9.1906\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 143.8252 - mae: 8.7987 - val_loss: 175.0100 - val_mae: 9.2414\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 118.9297 - mae: 8.4454 - val_loss: 178.9924 - val_mae: 9.2923\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 117.2707 - mae: 7.9950 - val_loss: 175.9020 - val_mae: 8.9408\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 121.8100 - mae: 8.0855 - val_loss: 167.3861 - val_mae: 8.7215\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 110.7369 - mae: 7.4129 - val_loss: 162.3584 - val_mae: 8.6326\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 116.5097 - mae: 7.7544 - val_loss: 162.1653 - val_mae: 8.7586\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 115.2930 - mae: 7.7938 - val_loss: 161.7344 - val_mae: 8.7798\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 127.1543 - mae: 8.4334 - val_loss: 162.9393 - val_mae: 8.9109\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.7421 - mae: 7.9793 - val_loss: 164.2252 - val_mae: 8.9885\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 130.4991 - mae: 8.5698 - val_loss: 164.1299 - val_mae: 8.9384\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 124.7359 - mae: 8.2273 - val_loss: 165.4530 - val_mae: 8.9536\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 140.8019 - mae: 8.7289 - val_loss: 170.4825 - val_mae: 9.1198\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 115.9825 - mae: 7.9701 - val_loss: 173.8163 - val_mae: 9.2841\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 140.3722 - mae: 8.7700 - val_loss: 175.5503 - val_mae: 9.3117\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 103.3036 - mae: 7.4438 - val_loss: 173.1031 - val_mae: 9.0930\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 113.5523 - mae: 7.7139 - val_loss: 168.1132 - val_mae: 8.7143\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 124.7244 - mae: 7.9465 - val_loss: 165.2545 - val_mae: 8.4217\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.3120 - mae: 7.8209 - val_loss: 167.4341 - val_mae: 8.5782\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 140.3042 - mae: 8.9143 - val_loss: 167.4817 - val_mae: 8.7037\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 129.4042 - mae: 8.2116 - val_loss: 164.8500 - val_mae: 8.7703\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 114.2566 - mae: 7.7927 - val_loss: 161.3766 - val_mae: 8.5958\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.9112 - mae: 8.1426 - val_loss: 161.8607 - val_mae: 8.6526\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 111.9525 - mae: 7.8576 - val_loss: 164.0057 - val_mae: 8.7542\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.4122 - mae: 8.1597 - val_loss: 167.5149 - val_mae: 8.9078\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 131.3132 - mae: 8.4428 - val_loss: 173.5943 - val_mae: 9.1486\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 117.2458 - mae: 8.0751 - val_loss: 176.1006 - val_mae: 9.2952\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 129.5960 - mae: 8.7295 - val_loss: 175.6570 - val_mae: 9.2335\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 124.3750 - mae: 8.2443 - val_loss: 173.5322 - val_mae: 8.9995\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 114.5897 - mae: 7.8569 - val_loss: 171.5863 - val_mae: 8.6095\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 108.4410 - mae: 7.5081 - val_loss: 173.9647 - val_mae: 8.7122\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 116.3203 - mae: 8.1581 - val_loss: 173.7159 - val_mae: 8.8822\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.0368 - mae: 8.1688 - val_loss: 169.6779 - val_mae: 8.8139\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 128.9426 - mae: 7.9913 - val_loss: 167.5730 - val_mae: 8.6998\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.2818 - mae: 7.5770 - val_loss: 163.9085 - val_mae: 8.2970\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 110.7369 - mae: 7.8327 - val_loss: 163.7331 - val_mae: 8.2642\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 133.0575 - mae: 8.3825 - val_loss: 169.5722 - val_mae: 8.7964\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 112.7524 - mae: 7.6349 - val_loss: 173.4587 - val_mae: 9.0481\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 127.8468 - mae: 8.0994 - val_loss: 168.6643 - val_mae: 8.8164\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 123.2476 - mae: 8.1495 - val_loss: 168.7755 - val_mae: 8.7290\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 118.2178 - mae: 7.9103 - val_loss: 167.5038 - val_mae: 8.6813\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 117.4759 - mae: 7.6936 - val_loss: 165.7961 - val_mae: 8.6179\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 123.9256 - mae: 7.9307 - val_loss: 164.4214 - val_mae: 8.5981\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 115.3392 - mae: 7.7684 - val_loss: 163.8424 - val_mae: 8.6770\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 314.9093 - mae: 12.7537\n",
      "Test Loss: 314.9093\n",
      "Test MAE: 12.7537\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.0576\n",
      "MSE: 314.9093\n",
      "MAE: 12.7537\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 34ms/step - loss: 286.2169 - mae: 9.3784 - val_loss: 294.1033 - val_mae: 11.0239\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 233.7071 - mae: 8.7785 - val_loss: 278.5445 - val_mae: 11.0424\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 254.1340 - mae: 9.9118 - val_loss: 271.4961 - val_mae: 10.9943\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.4128 - mae: 9.8153 - val_loss: 266.5729 - val_mae: 11.0056\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.5035 - mae: 9.3086 - val_loss: 262.4014 - val_mae: 10.9177\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.3070 - mae: 9.5012 - val_loss: 259.3033 - val_mae: 10.7616\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.2724 - mae: 9.2622 - val_loss: 260.7958 - val_mae: 10.6709\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 228.0729 - mae: 8.8356 - val_loss: 257.5289 - val_mae: 10.6577\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 224.3325 - mae: 8.1984 - val_loss: 253.0951 - val_mae: 10.6015\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 216.7665 - mae: 8.6958 - val_loss: 246.8763 - val_mae: 10.5463\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 222.2216 - mae: 8.8854 - val_loss: 242.7679 - val_mae: 10.5385\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 213.7919 - mae: 8.6884 - val_loss: 241.9697 - val_mae: 10.3947\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 215.9544 - mae: 8.9807 - val_loss: 242.0135 - val_mae: 10.1958\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 231.5662 - mae: 9.0473 - val_loss: 244.7859 - val_mae: 10.0080\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 225.1050 - mae: 8.5116 - val_loss: 249.0471 - val_mae: 9.8922\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 204.1807 - mae: 8.0409 - val_loss: 251.4750 - val_mae: 9.7753\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 193.3673 - mae: 7.7720 - val_loss: 246.0592 - val_mae: 9.7887\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 211.6784 - mae: 7.9063 - val_loss: 245.3426 - val_mae: 9.7887\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 217.7459 - mae: 8.1180 - val_loss: 245.4894 - val_mae: 9.7856\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 185.7733 - mae: 7.3873 - val_loss: 246.6510 - val_mae: 9.8572\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 197.3515 - mae: 7.9713 - val_loss: 245.3013 - val_mae: 9.8833\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 222.3743 - mae: 8.9668 - val_loss: 237.7040 - val_mae: 9.9427\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 204.2199 - mae: 8.1925 - val_loss: 231.4472 - val_mae: 10.2221\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 193.2456 - mae: 8.6029 - val_loss: 232.3749 - val_mae: 10.1366\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 185.7625 - mae: 8.1377 - val_loss: 232.5458 - val_mae: 9.8837\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 192.6936 - mae: 7.9256 - val_loss: 236.5536 - val_mae: 9.8726\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 207.4493 - mae: 8.0401 - val_loss: 237.8311 - val_mae: 9.8178\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 189.3896 - mae: 7.5615 - val_loss: 236.4602 - val_mae: 9.7354\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.6973 - mae: 7.8311 - val_loss: 237.5986 - val_mae: 9.5669\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 210.9888 - mae: 8.4420 - val_loss: 233.9170 - val_mae: 9.5214\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 198.0836 - mae: 8.1119 - val_loss: 228.0074 - val_mae: 9.6303\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 183.8388 - mae: 7.7907 - val_loss: 226.3079 - val_mae: 9.6891\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 179.9003 - mae: 7.9960 - val_loss: 223.2333 - val_mae: 9.8740\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.7431 - mae: 8.1443 - val_loss: 225.7799 - val_mae: 9.7364\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.8340 - mae: 8.3199 - val_loss: 229.1194 - val_mae: 9.8936\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 187.4887 - mae: 8.0521 - val_loss: 228.1532 - val_mae: 9.8497\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 185.8011 - mae: 7.5767 - val_loss: 223.1578 - val_mae: 9.7267\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 200.0535 - mae: 8.0310 - val_loss: 220.2772 - val_mae: 9.5769\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 173.4229 - mae: 7.3713 - val_loss: 216.3966 - val_mae: 9.5615\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 174.0585 - mae: 7.5873 - val_loss: 215.6882 - val_mae: 9.4605\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 195.1965 - mae: 8.2321 - val_loss: 211.4841 - val_mae: 9.5330\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 180.6284 - mae: 7.8837 - val_loss: 211.4241 - val_mae: 9.3942\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 184.1738 - mae: 7.4633 - val_loss: 212.7609 - val_mae: 9.3854\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 190.8496 - mae: 8.0072 - val_loss: 211.9651 - val_mae: 9.4500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 187.5565 - mae: 8.0476 - val_loss: 211.6868 - val_mae: 9.2894\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.2206 - mae: 7.3506 - val_loss: 213.8244 - val_mae: 9.2521\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 178.5564 - mae: 7.2701 - val_loss: 208.6466 - val_mae: 9.2543\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 169.2155 - mae: 7.7134 - val_loss: 202.8112 - val_mae: 9.1953\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 186.6451 - mae: 7.9605 - val_loss: 198.5045 - val_mae: 9.1956\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 134.3138 - mae: 6.9309 - val_loss: 198.8499 - val_mae: 9.1556\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.8476 - mae: 7.5484 - val_loss: 196.8497 - val_mae: 9.2316\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 174.5824 - mae: 7.6402 - val_loss: 195.1527 - val_mae: 9.1506\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.0605 - mae: 7.5070 - val_loss: 192.5952 - val_mae: 9.0121\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 172.0402 - mae: 7.5841 - val_loss: 193.6946 - val_mae: 9.0750\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.8882 - mae: 6.9736 - val_loss: 185.6112 - val_mae: 9.2002\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 169.2662 - mae: 7.7847 - val_loss: 178.7314 - val_mae: 9.1763\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.3120 - mae: 7.7014 - val_loss: 178.4750 - val_mae: 9.0564\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 139.4870 - mae: 7.0384 - val_loss: 174.3349 - val_mae: 8.9935\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.1561 - mae: 7.7904 - val_loss: 173.3683 - val_mae: 8.9279\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 130.0784 - mae: 6.9563 - val_loss: 178.4681 - val_mae: 9.0237\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 133.9852 - mae: 6.5508 - val_loss: 175.6045 - val_mae: 9.0952\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 140.8481 - mae: 7.2894 - val_loss: 163.8162 - val_mae: 8.8011\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 126.6567 - mae: 7.3622 - val_loss: 163.6017 - val_mae: 8.7059\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 146.4577 - mae: 7.1187 - val_loss: 164.6338 - val_mae: 8.7168\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 123.5386 - mae: 6.4062 - val_loss: 168.2027 - val_mae: 8.5763\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 148.5863 - mae: 6.8818 - val_loss: 160.5704 - val_mae: 8.5488\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 137.1206 - mae: 7.3232 - val_loss: 147.9468 - val_mae: 8.6211\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 147.3794 - mae: 7.4783 - val_loss: 149.5133 - val_mae: 8.5419\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 116.9966 - mae: 6.8518 - val_loss: 156.0496 - val_mae: 8.4899\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 134.4088 - mae: 6.9389 - val_loss: 151.0350 - val_mae: 8.5238\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 131.2247 - mae: 6.2891 - val_loss: 145.9188 - val_mae: 8.2981\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 97.3996 - mae: 6.1587 - val_loss: 141.3233 - val_mae: 8.1473\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 127.1064 - mae: 6.6067 - val_loss: 141.8498 - val_mae: 8.0716\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 116.4926 - mae: 6.4964 - val_loss: 143.6041 - val_mae: 7.8378\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 103.5575 - mae: 6.0979 - val_loss: 139.9810 - val_mae: 7.8447\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 99.1309 - mae: 6.0281 - val_loss: 136.6507 - val_mae: 8.0059\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 122.2866 - mae: 6.9129 - val_loss: 138.8029 - val_mae: 8.0372\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 126.9211 - mae: 6.8271 - val_loss: 130.0407 - val_mae: 7.7891\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 103.3400 - mae: 6.1508 - val_loss: 129.1029 - val_mae: 7.5881\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.2022 - mae: 5.7581 - val_loss: 132.1285 - val_mae: 7.5019\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 96.2356 - mae: 6.1008 - val_loss: 129.8036 - val_mae: 7.5138\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 119.7589 - mae: 6.2882 - val_loss: 128.1662 - val_mae: 7.5596\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 93.8792 - mae: 6.5217 - val_loss: 130.1993 - val_mae: 7.6131\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.0431 - mae: 5.7383 - val_loss: 128.9402 - val_mae: 7.5813\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 87.9108 - mae: 6.0008 - val_loss: 131.5942 - val_mae: 7.6572\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.7124 - mae: 5.5970 - val_loss: 122.3448 - val_mae: 7.5630\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.0081 - mae: 5.5682 - val_loss: 118.7674 - val_mae: 7.4197\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 99.4689 - mae: 6.3956 - val_loss: 117.8157 - val_mae: 7.3027\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.9394 - mae: 5.4876 - val_loss: 117.9607 - val_mae: 7.1870\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.4908 - mae: 5.6492 - val_loss: 122.4681 - val_mae: 7.3311\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 58.6983 - mae: 5.2108 - val_loss: 122.5506 - val_mae: 7.2413\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.8462 - mae: 5.8757 - val_loss: 115.2200 - val_mae: 6.9222\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 96.5316 - mae: 5.5364 - val_loss: 111.1822 - val_mae: 6.8894\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 74.8066 - mae: 5.7139 - val_loss: 113.3873 - val_mae: 7.0735\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.6704 - mae: 5.6708 - val_loss: 124.4761 - val_mae: 7.4855\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.9902 - mae: 5.1343 - val_loss: 124.7408 - val_mae: 7.4760\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 115.1708 - mae: 6.2019 - val_loss: 113.1200 - val_mae: 6.9815\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 99.0787 - mae: 6.3127 - val_loss: 110.6418 - val_mae: 6.7436\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 86.9245 - mae: 5.7693 - val_loss: 113.3587 - val_mae: 6.7867\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.1042 - mae: 5.2987 - val_loss: 120.7297 - val_mae: 6.8755\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51.9215 - mae: 4.1020\n",
      "Test Loss: 51.9215\n",
      "Test MAE: 4.1020\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.6048\n",
      "MSE: 51.9215\n",
      "MAE: 4.1020\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 28.6021 - mae: 3.4532 - val_loss: 1.8160 - val_mae: 1.0341\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.7944 - mae: 2.2600 - val_loss: 1.5957 - val_mae: 0.8424\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.6298 - mae: 2.4787 - val_loss: 1.0748 - val_mae: 0.6134\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3257 - mae: 2.1426 - val_loss: 1.1780 - val_mae: 0.6395\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.5816 - mae: 1.6999 - val_loss: 1.2636 - val_mae: 0.6958\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.3595 - mae: 1.6252 - val_loss: 1.1366 - val_mae: 0.7151\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3665 - mae: 1.2331 - val_loss: 0.9258 - val_mae: 0.6474\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.0602 - mae: 1.2256 - val_loss: 0.8955 - val_mae: 0.6051\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8791 - mae: 1.1709 - val_loss: 0.9668 - val_mae: 0.6467\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.0602 - mae: 1.0835 - val_loss: 0.9563 - val_mae: 0.6439\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9688 - mae: 1.0072 - val_loss: 0.9219 - val_mae: 0.6387\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9077 - mae: 0.9396 - val_loss: 0.8677 - val_mae: 0.6351\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6047 - mae: 0.9185 - val_loss: 0.8202 - val_mae: 0.6195\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5551 - mae: 0.8479 - val_loss: 0.7986 - val_mae: 0.6020\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2664 - mae: 0.8018 - val_loss: 0.7915 - val_mae: 0.5818\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7284 - mae: 0.8833 - val_loss: 0.7769 - val_mae: 0.5620\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2020 - mae: 0.7602 - val_loss: 0.7515 - val_mae: 0.5314\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0984 - mae: 0.7511 - val_loss: 0.7519 - val_mae: 0.5231\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0671 - mae: 0.7382 - val_loss: 0.7496 - val_mae: 0.5156\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3488 - mae: 0.7794 - val_loss: 0.7528 - val_mae: 0.5214\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1543 - mae: 0.7029 - val_loss: 0.7516 - val_mae: 0.5339\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0075 - mae: 0.6301 - val_loss: 0.7625 - val_mae: 0.5509\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2290 - mae: 0.6965 - val_loss: 0.7727 - val_mae: 0.5540\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0341 - mae: 0.6868 - val_loss: 0.7685 - val_mae: 0.5534\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8503 - mae: 0.6213 - val_loss: 0.7550 - val_mae: 0.5480\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9262 - mae: 0.6544 - val_loss: 0.7454 - val_mae: 0.5277\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8830 - mae: 0.6566 - val_loss: 0.7438 - val_mae: 0.5155\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7171 - mae: 0.5757 - val_loss: 0.7440 - val_mae: 0.5066\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8840 - mae: 0.6011 - val_loss: 0.7401 - val_mae: 0.4970\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7540 - mae: 0.5746 - val_loss: 0.7445 - val_mae: 0.4900\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7833 - mae: 0.5760 - val_loss: 0.7470 - val_mae: 0.4904\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6960 - mae: 0.5483 - val_loss: 0.7496 - val_mae: 0.4908\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7958 - mae: 0.5885 - val_loss: 0.7421 - val_mae: 0.4903\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6538 - mae: 0.5351 - val_loss: 0.7416 - val_mae: 0.4842\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6776 - mae: 0.5642 - val_loss: 0.7326 - val_mae: 0.4850\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6189 - mae: 0.5243 - val_loss: 0.7330 - val_mae: 0.4850\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7667 - mae: 0.5443 - val_loss: 0.7311 - val_mae: 0.4868\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8507 - mae: 0.6159 - val_loss: 0.7324 - val_mae: 0.4968\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8188 - mae: 0.5660 - val_loss: 0.7393 - val_mae: 0.5074\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6481 - mae: 0.5096 - val_loss: 0.7453 - val_mae: 0.5151\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9317 - mae: 0.5803 - val_loss: 0.7487 - val_mae: 0.5140\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5499 - mae: 0.4894 - val_loss: 0.7505 - val_mae: 0.5144\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6916 - mae: 0.5437 - val_loss: 0.7502 - val_mae: 0.5143\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5841 - mae: 0.5058 - val_loss: 0.7490 - val_mae: 0.5088\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5416 - mae: 0.5169 - val_loss: 0.7479 - val_mae: 0.4927\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5405 - mae: 0.4492 - val_loss: 0.7463 - val_mae: 0.4766\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5166 - mae: 0.4370 - val_loss: 0.7505 - val_mae: 0.4712\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6081 - mae: 0.4966 - val_loss: 0.7491 - val_mae: 0.4654\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5132 - mae: 0.4448 - val_loss: 0.7421 - val_mae: 0.4623\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5213 - mae: 0.4611 - val_loss: 0.7428 - val_mae: 0.4603\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4179 - mae: 0.4010 - val_loss: 0.7381 - val_mae: 0.4635\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6096 - mae: 0.4690 - val_loss: 0.7369 - val_mae: 0.4668\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6740 - mae: 0.5030 - val_loss: 0.7375 - val_mae: 0.4702\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4795 - mae: 0.4171 - val_loss: 0.7327 - val_mae: 0.4811\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5178 - mae: 0.4283 - val_loss: 0.7277 - val_mae: 0.4949\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5644 - mae: 0.4850 - val_loss: 0.7280 - val_mae: 0.5027\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5411 - mae: 0.4969 - val_loss: 0.7269 - val_mae: 0.5067\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5439 - mae: 0.4770 - val_loss: 0.7247 - val_mae: 0.5064\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6574 - mae: 0.5079 - val_loss: 0.7240 - val_mae: 0.5006\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3919 - mae: 0.4165 - val_loss: 0.7220 - val_mae: 0.4951\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5378 - mae: 0.4738 - val_loss: 0.7209 - val_mae: 0.4948\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6489 - mae: 0.4967 - val_loss: 0.7269 - val_mae: 0.4925\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4261 - mae: 0.4095 - val_loss: 0.7249 - val_mae: 0.4933\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4748 - mae: 0.4374 - val_loss: 0.7218 - val_mae: 0.4954\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5722 - mae: 0.4694 - val_loss: 0.7192 - val_mae: 0.4946\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5489 - mae: 0.4604 - val_loss: 0.7176 - val_mae: 0.4960\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3964 - mae: 0.4182 - val_loss: 0.7164 - val_mae: 0.4949\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5251 - mae: 0.4615 - val_loss: 0.7127 - val_mae: 0.4950\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5446 - mae: 0.4667 - val_loss: 0.7134 - val_mae: 0.4894\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4277 - mae: 0.4037 - val_loss: 0.7111 - val_mae: 0.4879\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4462 - mae: 0.4086 - val_loss: 0.7143 - val_mae: 0.4835\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4104 - mae: 0.4093 - val_loss: 0.7153 - val_mae: 0.4831\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5125 - mae: 0.4438 - val_loss: 0.7152 - val_mae: 0.4849\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4333 - mae: 0.4086 - val_loss: 0.7166 - val_mae: 0.4841\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5208 - mae: 0.4326 - val_loss: 0.7179 - val_mae: 0.4866\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4395 - mae: 0.4128 - val_loss: 0.7198 - val_mae: 0.4890\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4359 - mae: 0.3999 - val_loss: 0.7212 - val_mae: 0.4920\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4609 - mae: 0.4321 - val_loss: 0.7189 - val_mae: 0.4954\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3539 - mae: 0.3684 - val_loss: 0.7193 - val_mae: 0.4965\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4377 - mae: 0.3983 - val_loss: 0.7199 - val_mae: 0.4903\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6304 - mae: 0.4764 - val_loss: 0.7187 - val_mae: 0.4838\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4006 - mae: 0.4142 - val_loss: 0.7133 - val_mae: 0.4751\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4868 - mae: 0.4078 - val_loss: 0.7143 - val_mae: 0.4593\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4379 - mae: 0.3865 - val_loss: 0.7279 - val_mae: 0.4473\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4710 - mae: 0.4081 - val_loss: 0.7277 - val_mae: 0.4497\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5030 - mae: 0.4038 - val_loss: 0.7265 - val_mae: 0.4520\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5150 - mae: 0.4144 - val_loss: 0.7278 - val_mae: 0.4530\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5070 - mae: 0.4434 - val_loss: 0.7324 - val_mae: 0.4512\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3953 - mae: 0.3566 - val_loss: 0.7287 - val_mae: 0.4492\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4768 - mae: 0.4214 - val_loss: 0.7252 - val_mae: 0.4556\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4511 - mae: 0.4185 - val_loss: 0.7221 - val_mae: 0.4607\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4860 - mae: 0.4187 - val_loss: 0.7245 - val_mae: 0.4589\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3212 - mae: 0.3447 - val_loss: 0.7207 - val_mae: 0.4579\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3607 - mae: 0.3534 - val_loss: 0.7168 - val_mae: 0.4602\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3555 - mae: 0.3611 - val_loss: 0.7140 - val_mae: 0.4656\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4564 - mae: 0.4029 - val_loss: 0.7141 - val_mae: 0.4675\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4908 - mae: 0.4258 - val_loss: 0.7179 - val_mae: 0.4686\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3249 - mae: 0.3426 - val_loss: 0.7239 - val_mae: 0.4689\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3275 - mae: 0.3602 - val_loss: 0.7257 - val_mae: 0.4707\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4956 - mae: 0.4049 - val_loss: 0.7231 - val_mae: 0.4769\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5467 - mae: 0.3782\n",
      "Test Loss: 0.5467\n",
      "Test MAE: 0.3782\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.1282\n",
      "MSE: 0.5467\n",
      "MAE: 0.3782\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 30.9933 - mae: 3.3098 - val_loss: 2.6143 - val_mae: 1.4133\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.7247 - mae: 2.3279 - val_loss: 4.1431 - val_mae: 1.5855\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1340 - mae: 2.4908 - val_loss: 1.2172 - val_mae: 0.8182\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.6017 - mae: 2.1356 - val_loss: 0.6333 - val_mae: 0.5533\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.5187 - mae: 1.8527 - val_loss: 0.5572 - val_mae: 0.5211\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8989 - mae: 1.4769 - val_loss: 0.4162 - val_mae: 0.5329\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.0865 - mae: 1.2807 - val_loss: 0.3767 - val_mae: 0.5526\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8467 - mae: 0.9945 - val_loss: 0.5015 - val_mae: 0.6035\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1775 - mae: 1.2343 - val_loss: 0.5585 - val_mae: 0.6149\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.6272 - mae: 1.1878 - val_loss: 0.4916 - val_mae: 0.5787\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3953 - mae: 1.1070 - val_loss: 0.4492 - val_mae: 0.5432\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0696 - mae: 0.9932 - val_loss: 0.5105 - val_mae: 0.5429\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0384 - mae: 0.9152 - val_loss: 0.5234 - val_mae: 0.5648\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7456 - mae: 0.9113 - val_loss: 0.4406 - val_mae: 0.5183\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4463 - mae: 0.8315 - val_loss: 0.3772 - val_mae: 0.4818\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8458 - mae: 0.8788 - val_loss: 0.3659 - val_mae: 0.4707\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2498 - mae: 0.7917 - val_loss: 0.3745 - val_mae: 0.4545\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1609 - mae: 0.7410 - val_loss: 0.3600 - val_mae: 0.4373\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0281 - mae: 0.6993 - val_loss: 0.3432 - val_mae: 0.4294\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7534 - mae: 0.6098 - val_loss: 0.3347 - val_mae: 0.4281\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7732 - mae: 0.6348 - val_loss: 0.3246 - val_mae: 0.4273\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8121 - mae: 0.6237 - val_loss: 0.3147 - val_mae: 0.4204\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7041 - mae: 0.6034 - val_loss: 0.3239 - val_mae: 0.4158\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6988 - mae: 0.6071 - val_loss: 0.3384 - val_mae: 0.4054\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6860 - mae: 0.5685 - val_loss: 0.3626 - val_mae: 0.4008\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5374 - mae: 0.5080 - val_loss: 0.3693 - val_mae: 0.3983\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6024 - mae: 0.5223 - val_loss: 0.3635 - val_mae: 0.3945\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6879 - mae: 0.5139 - val_loss: 0.3589 - val_mae: 0.3898\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6800 - mae: 0.5366 - val_loss: 0.3572 - val_mae: 0.3886\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6528 - mae: 0.5496 - val_loss: 0.3579 - val_mae: 0.3870\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6031 - mae: 0.5317 - val_loss: 0.3591 - val_mae: 0.3881\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5335 - mae: 0.4892 - val_loss: 0.3560 - val_mae: 0.3890\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4861 - mae: 0.4411 - val_loss: 0.3531 - val_mae: 0.3871\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4517 - mae: 0.4740 - val_loss: 0.3473 - val_mae: 0.3825\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5119 - mae: 0.4871 - val_loss: 0.3355 - val_mae: 0.3769\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3893 - mae: 0.4525 - val_loss: 0.3289 - val_mae: 0.3735\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6361 - mae: 0.5253 - val_loss: 0.3228 - val_mae: 0.3700\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4983 - mae: 0.4760 - val_loss: 0.3106 - val_mae: 0.3634\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4721 - mae: 0.4480 - val_loss: 0.2984 - val_mae: 0.3550\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4515 - mae: 0.4373 - val_loss: 0.2944 - val_mae: 0.3503\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3996 - mae: 0.4336 - val_loss: 0.2938 - val_mae: 0.3481\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4458 - mae: 0.4425 - val_loss: 0.2829 - val_mae: 0.3460\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3846 - mae: 0.4131 - val_loss: 0.2712 - val_mae: 0.3447\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5258 - mae: 0.4736 - val_loss: 0.2692 - val_mae: 0.3461\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5596 - mae: 0.4340 - val_loss: 0.2698 - val_mae: 0.3471\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3958 - mae: 0.3914 - val_loss: 0.2699 - val_mae: 0.3482\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4687 - mae: 0.4490 - val_loss: 0.2735 - val_mae: 0.3475\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4761 - mae: 0.4350 - val_loss: 0.2810 - val_mae: 0.3487\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3509 - mae: 0.3863 - val_loss: 0.2847 - val_mae: 0.3536\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4425 - mae: 0.4350 - val_loss: 0.2933 - val_mae: 0.3578\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3697 - mae: 0.4037 - val_loss: 0.2937 - val_mae: 0.3600\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3466 - mae: 0.3826 - val_loss: 0.2893 - val_mae: 0.3599\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3489 - mae: 0.4126 - val_loss: 0.2814 - val_mae: 0.3562\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4527 - mae: 0.4462 - val_loss: 0.2714 - val_mae: 0.3515\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3963 - mae: 0.4226 - val_loss: 0.2683 - val_mae: 0.3490\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4003 - mae: 0.4366 - val_loss: 0.2673 - val_mae: 0.3473\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4076 - mae: 0.4323 - val_loss: 0.2697 - val_mae: 0.3470\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4414 - mae: 0.4314 - val_loss: 0.2740 - val_mae: 0.3483\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3704 - mae: 0.4091 - val_loss: 0.2758 - val_mae: 0.3478\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3083 - mae: 0.3847 - val_loss: 0.2760 - val_mae: 0.3443\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3865 - mae: 0.3953 - val_loss: 0.2781 - val_mae: 0.3424\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3401 - mae: 0.3763 - val_loss: 0.2742 - val_mae: 0.3414\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4193 - mae: 0.4159 - val_loss: 0.2709 - val_mae: 0.3401\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3636 - mae: 0.4073 - val_loss: 0.2655 - val_mae: 0.3385\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3510 - mae: 0.3858 - val_loss: 0.2618 - val_mae: 0.3381\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3304 - mae: 0.3670 - val_loss: 0.2584 - val_mae: 0.3381\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3178 - mae: 0.3730 - val_loss: 0.2576 - val_mae: 0.3394\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3922 - mae: 0.4030 - val_loss: 0.2567 - val_mae: 0.3410\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2925 - mae: 0.3567 - val_loss: 0.2592 - val_mae: 0.3411\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2871 - mae: 0.3582 - val_loss: 0.2635 - val_mae: 0.3428\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3312 - mae: 0.3625 - val_loss: 0.2632 - val_mae: 0.3424\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3571 - mae: 0.3847 - val_loss: 0.2661 - val_mae: 0.3431\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3213 - mae: 0.3650 - val_loss: 0.2737 - val_mae: 0.3461\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3073 - mae: 0.3739 - val_loss: 0.2790 - val_mae: 0.3454\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4041 - mae: 0.4010 - val_loss: 0.2780 - val_mae: 0.3423\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3160 - mae: 0.3768 - val_loss: 0.2741 - val_mae: 0.3401\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3082 - mae: 0.3635 - val_loss: 0.2724 - val_mae: 0.3397\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3168 - mae: 0.3646 - val_loss: 0.2682 - val_mae: 0.3414\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3407 - mae: 0.3586 - val_loss: 0.2698 - val_mae: 0.3470\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3328 - mae: 0.3774 - val_loss: 0.2722 - val_mae: 0.3509\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3236 - mae: 0.3706 - val_loss: 0.2723 - val_mae: 0.3520\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2837 - mae: 0.3546 - val_loss: 0.2696 - val_mae: 0.3517\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3684 - mae: 0.3860 - val_loss: 0.2710 - val_mae: 0.3504\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2876 - mae: 0.3582 - val_loss: 0.2773 - val_mae: 0.3487\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3000 - mae: 0.3473 - val_loss: 0.2827 - val_mae: 0.3458\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3393 - mae: 0.3891 - val_loss: 0.2851 - val_mae: 0.3431\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3320 - mae: 0.3719 - val_loss: 0.2894 - val_mae: 0.3418\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2822 - mae: 0.3447 - val_loss: 0.2907 - val_mae: 0.3394\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3407 - mae: 0.3831 - val_loss: 0.2862 - val_mae: 0.3373\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3083 - mae: 0.3460 - val_loss: 0.2777 - val_mae: 0.3353\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3573 - mae: 0.3760 - val_loss: 0.2713 - val_mae: 0.3330\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2927 - mae: 0.3354 - val_loss: 0.2691 - val_mae: 0.3326\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3173 - mae: 0.3298 - val_loss: 0.2669 - val_mae: 0.3311\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2653 - mae: 0.3137 - val_loss: 0.2620 - val_mae: 0.3303\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3492 - mae: 0.3608 - val_loss: 0.2613 - val_mae: 0.3309\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2923 - mae: 0.3359 - val_loss: 0.2581 - val_mae: 0.3317\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3250 - mae: 0.3525 - val_loss: 0.2577 - val_mae: 0.3343\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3575 - mae: 0.4007 - val_loss: 0.2636 - val_mae: 0.3367\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2197 - mae: 0.2900 - val_loss: 0.2708 - val_mae: 0.3380\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3290 - mae: 0.3649 - val_loss: 0.2724 - val_mae: 0.3385\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3458 - mae: 0.3378\n",
      "Test Loss: 0.3458\n",
      "Test MAE: 0.3378\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.1651\n",
      "MSE: 0.3458\n",
      "MAE: 0.3378\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 21.2950 - mae: 2.7246 - val_loss: 3.9338 - val_mae: 1.3560\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0774 - mae: 2.3731 - val_loss: 0.2917 - val_mae: 0.3680\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.2575 - mae: 2.0828 - val_loss: 0.9455 - val_mae: 0.6962\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.2920 - mae: 1.5306 - val_loss: 0.9745 - val_mae: 0.7266\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.6941 - mae: 1.5823 - val_loss: 0.6794 - val_mae: 0.6066\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7501 - mae: 1.1298 - val_loss: 0.4387 - val_mae: 0.4763\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8258 - mae: 0.9782 - val_loss: 0.4197 - val_mae: 0.4431\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8581 - mae: 1.0602 - val_loss: 0.2688 - val_mae: 0.3345\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.6136 - mae: 0.9527 - val_loss: 0.2211 - val_mae: 0.3111\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2268 - mae: 0.7395 - val_loss: 0.2309 - val_mae: 0.3316\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7005 - mae: 0.8127 - val_loss: 0.1775 - val_mae: 0.2863\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7186 - mae: 0.8277 - val_loss: 0.1468 - val_mae: 0.2559\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6497 - mae: 0.7914 - val_loss: 0.1744 - val_mae: 0.2918\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0644 - mae: 0.6581 - val_loss: 0.2652 - val_mae: 0.3689\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0968 - mae: 0.8360 - val_loss: 0.4082 - val_mae: 0.4561\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1630 - mae: 0.6564 - val_loss: 0.4711 - val_mae: 0.4831\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0211 - mae: 0.6411 - val_loss: 0.4682 - val_mae: 0.4789\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8653 - mae: 0.6157 - val_loss: 0.4760 - val_mae: 0.4786\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5498 - mae: 0.6994 - val_loss: 0.4119 - val_mae: 0.4443\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7913 - mae: 0.5171 - val_loss: 0.3340 - val_mae: 0.4003\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9131 - mae: 0.5931 - val_loss: 0.2957 - val_mae: 0.3752\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8895 - mae: 0.7797 - val_loss: 0.2846 - val_mae: 0.3659\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0011 - mae: 0.6038 - val_loss: 0.2992 - val_mae: 0.3691\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6689 - mae: 0.6852 - val_loss: 0.2902 - val_mae: 0.3667\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2084 - mae: 0.6674 - val_loss: 0.3128 - val_mae: 0.3782\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7002 - mae: 0.4974 - val_loss: 0.3907 - val_mae: 0.4139\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1176 - mae: 0.6346 - val_loss: 0.4143 - val_mae: 0.4237\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3322 - mae: 0.6740 - val_loss: 0.3770 - val_mae: 0.4128\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5997 - mae: 0.4677 - val_loss: 0.3110 - val_mae: 0.3798\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5486 - mae: 0.4797 - val_loss: 0.2300 - val_mae: 0.3325\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7098 - mae: 0.5492 - val_loss: 0.1771 - val_mae: 0.2920\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7379 - mae: 0.5468 - val_loss: 0.1581 - val_mae: 0.2754\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1202 - mae: 0.5602 - val_loss: 0.1591 - val_mae: 0.2665\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6964 - mae: 0.4988 - val_loss: 0.1713 - val_mae: 0.2642\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5795 - mae: 0.4461 - val_loss: 0.2106 - val_mae: 0.2928\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7962 - mae: 0.5261 - val_loss: 0.2808 - val_mae: 0.3388\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7364 - mae: 0.4842 - val_loss: 0.3080 - val_mae: 0.3709\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5801 - mae: 0.4593 - val_loss: 0.3412 - val_mae: 0.3969\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3085 - mae: 0.3599 - val_loss: 0.3381 - val_mae: 0.3991\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6140 - mae: 0.4292 - val_loss: 0.2943 - val_mae: 0.3768\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4329 - mae: 0.3823 - val_loss: 0.2329 - val_mae: 0.3411\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5771 - mae: 0.4421 - val_loss: 0.2273 - val_mae: 0.3402\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4674 - mae: 0.4094 - val_loss: 0.2404 - val_mae: 0.3467\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5102 - mae: 0.4089 - val_loss: 0.2685 - val_mae: 0.3554\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5340 - mae: 0.4236 - val_loss: 0.2897 - val_mae: 0.3606\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4759 - mae: 0.3776 - val_loss: 0.2731 - val_mae: 0.3469\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5440 - mae: 0.4273 - val_loss: 0.2668 - val_mae: 0.3411\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4213 - mae: 0.3852 - val_loss: 0.2579 - val_mae: 0.3332\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5385 - mae: 0.4179 - val_loss: 0.2573 - val_mae: 0.3351\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3595 - mae: 0.3725 - val_loss: 0.2453 - val_mae: 0.3291\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7173 - mae: 0.4888 - val_loss: 0.2658 - val_mae: 0.3461\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5392 - mae: 0.4197 - val_loss: 0.2752 - val_mae: 0.3533\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5970 - mae: 0.4041 - val_loss: 0.2566 - val_mae: 0.3440\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6192 - mae: 0.4204 - val_loss: 0.2399 - val_mae: 0.3331\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2985 - mae: 0.3318 - val_loss: 0.2467 - val_mae: 0.3402\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4713 - mae: 0.4257 - val_loss: 0.2405 - val_mae: 0.3372\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4636 - mae: 0.3823 - val_loss: 0.2389 - val_mae: 0.3388\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4081 - mae: 0.3715 - val_loss: 0.2813 - val_mae: 0.3641\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4950 - mae: 0.4088 - val_loss: 0.3365 - val_mae: 0.3948\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3822 - mae: 0.3436 - val_loss: 0.4037 - val_mae: 0.4323\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5542 - mae: 0.4348 - val_loss: 0.4454 - val_mae: 0.4565\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3545 - mae: 0.3569 - val_loss: 0.4465 - val_mae: 0.4610\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3047 - mae: 0.3389 - val_loss: 0.4403 - val_mae: 0.4614\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4506 - mae: 0.3752 - val_loss: 0.4317 - val_mae: 0.4588\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2389 - mae: 0.3035 - val_loss: 0.4046 - val_mae: 0.4426\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4498 - mae: 0.3515 - val_loss: 0.3673 - val_mae: 0.4159\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3216 - mae: 0.3483 - val_loss: 0.3297 - val_mae: 0.3871\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2091 - mae: 0.2943 - val_loss: 0.2768 - val_mae: 0.3387\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6380 - mae: 0.4338 - val_loss: 0.2765 - val_mae: 0.3393\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4704 - mae: 0.3853 - val_loss: 0.3273 - val_mae: 0.3832\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4370 - mae: 0.3556 - val_loss: 0.4353 - val_mae: 0.4413\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4115 - mae: 0.3732 - val_loss: 0.4698 - val_mae: 0.4558\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5131 - mae: 0.3763 - val_loss: 0.4404 - val_mae: 0.4407\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4376 - mae: 0.3630 - val_loss: 0.3666 - val_mae: 0.4028\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4426 - mae: 0.3898 - val_loss: 0.2826 - val_mae: 0.3541\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2690 - mae: 0.3100 - val_loss: 0.2363 - val_mae: 0.3299\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5960 - mae: 0.4248 - val_loss: 0.2386 - val_mae: 0.3391\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4003 - mae: 0.3424 - val_loss: 0.2275 - val_mae: 0.3292\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5048 - mae: 0.4088 - val_loss: 0.2371 - val_mae: 0.3323\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3226 - mae: 0.3419 - val_loss: 0.2793 - val_mae: 0.3537\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2864 - mae: 0.3119 - val_loss: 0.3159 - val_mae: 0.3783\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2443 - mae: 0.2900 - val_loss: 0.3152 - val_mae: 0.3791\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3577 - mae: 0.3372 - val_loss: 0.2961 - val_mae: 0.3715\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3982 - mae: 0.3694 - val_loss: 0.3104 - val_mae: 0.3840\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3292 - mae: 0.3251 - val_loss: 0.3428 - val_mae: 0.4068\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1843 - mae: 0.2831 - val_loss: 0.3467 - val_mae: 0.4106\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3696 - mae: 0.3570 - val_loss: 0.3231 - val_mae: 0.3975\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3289 - mae: 0.3042 - val_loss: 0.3054 - val_mae: 0.3877\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3724 - mae: 0.3328 - val_loss: 0.2619 - val_mae: 0.3551\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3325 - mae: 0.3239 - val_loss: 0.2594 - val_mae: 0.3470\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2424 - mae: 0.2852 - val_loss: 0.2764 - val_mae: 0.3538\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2684 - mae: 0.3242 - val_loss: 0.2988 - val_mae: 0.3671\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2645 - mae: 0.3174 - val_loss: 0.3217 - val_mae: 0.3816\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - mae: 0.3288 - val_loss: 0.3094 - val_mae: 0.3759\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4379 - mae: 0.3745 - val_loss: 0.2491 - val_mae: 0.3372\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2125 - mae: 0.2881 - val_loss: 0.1910 - val_mae: 0.2892\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2940 - mae: 0.3232 - val_loss: 0.1707 - val_mae: 0.2641\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2390 - mae: 0.2731 - val_loss: 0.1965 - val_mae: 0.2914\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5109 - mae: 0.3333 - val_loss: 0.2550 - val_mae: 0.3442\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3551 - mae: 0.3359 - val_loss: 0.3539 - val_mae: 0.4114\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1550 - mae: 0.2323\n",
      "Test Loss: 0.1550\n",
      "Test MAE: 0.2323\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.8849\n",
      "MSE: 0.1550\n",
      "MAE: 0.2323\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 32ms/step - loss: 22.7841 - mae: 3.1105 - val_loss: 1.7926 - val_mae: 0.9307\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.3340 - mae: 2.6670 - val_loss: 1.7802 - val_mae: 1.0109\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.0382 - mae: 1.9374 - val_loss: 1.7319 - val_mae: 1.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.6147 - mae: 1.8792 - val_loss: 1.3270 - val_mae: 0.8292\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1334 - mae: 1.4225 - val_loss: 1.5989 - val_mae: 0.9040\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1912 - mae: 1.5286 - val_loss: 1.3176 - val_mae: 0.8344\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9531 - mae: 1.4559 - val_loss: 0.9385 - val_mae: 0.5932\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2446 - mae: 1.2366 - val_loss: 1.1564 - val_mae: 0.7407\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.6440 - mae: 1.0666 - val_loss: 1.3326 - val_mae: 0.8381\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1957 - mae: 0.9639 - val_loss: 1.2745 - val_mae: 0.8206\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7245 - mae: 0.9335 - val_loss: 1.0820 - val_mae: 0.7133\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9074 - mae: 0.9860 - val_loss: 0.9747 - val_mae: 0.6306\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.6762 - mae: 0.8803 - val_loss: 0.9097 - val_mae: 0.5620\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3428 - mae: 1.0222 - val_loss: 0.9074 - val_mae: 0.5440\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3632 - mae: 0.8316 - val_loss: 0.9296 - val_mae: 0.5473\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1601 - mae: 0.7140 - val_loss: 0.9349 - val_mae: 0.5417\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0903 - mae: 0.7041 - val_loss: 0.9373 - val_mae: 0.5460\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1775 - mae: 0.7650 - val_loss: 0.9275 - val_mae: 0.5413\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2669 - mae: 0.7360 - val_loss: 0.8993 - val_mae: 0.5270\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1746 - mae: 0.7652 - val_loss: 0.8790 - val_mae: 0.5193\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.2317 - mae: 0.7305 - val_loss: 0.8580 - val_mae: 0.5103\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.2254 - mae: 0.7077 - val_loss: 0.8362 - val_mae: 0.5009\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2401 - mae: 0.7450 - val_loss: 0.8236 - val_mae: 0.4917\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8514 - mae: 0.6344 - val_loss: 0.8163 - val_mae: 0.4922\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1766 - mae: 0.7123 - val_loss: 0.8101 - val_mae: 0.4880\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7303 - mae: 0.5922 - val_loss: 0.8150 - val_mae: 0.4865\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0739 - mae: 0.6617 - val_loss: 0.8250 - val_mae: 0.4900\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8394 - mae: 0.5934 - val_loss: 0.8342 - val_mae: 0.4958\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6713 - mae: 0.5580 - val_loss: 0.8357 - val_mae: 0.4954\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8480 - mae: 0.5957 - val_loss: 0.8207 - val_mae: 0.4880\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0069 - mae: 0.6694 - val_loss: 0.7947 - val_mae: 0.4842\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6158 - mae: 0.5130 - val_loss: 0.7824 - val_mae: 0.4860\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6787 - mae: 0.5514 - val_loss: 0.7812 - val_mae: 0.4857\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7971 - mae: 0.5621 - val_loss: 0.7835 - val_mae: 0.4880\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6479 - mae: 0.5370 - val_loss: 0.7979 - val_mae: 0.4940\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6696 - mae: 0.5084 - val_loss: 0.8026 - val_mae: 0.4886\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6996 - mae: 0.5580 - val_loss: 0.8042 - val_mae: 0.4783\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6161 - mae: 0.5269 - val_loss: 0.8050 - val_mae: 0.4783\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6480 - mae: 0.5127 - val_loss: 0.8115 - val_mae: 0.4839\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6287 - mae: 0.5441 - val_loss: 0.8491 - val_mae: 0.5153\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5780 - mae: 0.4887 - val_loss: 0.8875 - val_mae: 0.5487\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5929 - mae: 0.5254 - val_loss: 0.8577 - val_mae: 0.5340\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9199 - mae: 0.6178 - val_loss: 0.8106 - val_mae: 0.4873\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6368 - mae: 0.5187 - val_loss: 0.7852 - val_mae: 0.4619\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7725 - mae: 0.5278 - val_loss: 0.7684 - val_mae: 0.4522\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6148 - mae: 0.4886 - val_loss: 0.7644 - val_mae: 0.4420\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5849 - mae: 0.4640 - val_loss: 0.7624 - val_mae: 0.4433\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6523 - mae: 0.5033 - val_loss: 0.7707 - val_mae: 0.4524\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7439 - mae: 0.5361 - val_loss: 0.7744 - val_mae: 0.4575\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4910 - mae: 0.4611 - val_loss: 0.7871 - val_mae: 0.4639\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4796 - mae: 0.4583 - val_loss: 0.7915 - val_mae: 0.4660\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5568 - mae: 0.4945 - val_loss: 0.7992 - val_mae: 0.4699\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5393 - mae: 0.4908 - val_loss: 0.7736 - val_mae: 0.4496\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5232 - mae: 0.4279 - val_loss: 0.7507 - val_mae: 0.4461\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5168 - mae: 0.4493 - val_loss: 0.7507 - val_mae: 0.4563\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6293 - mae: 0.4956 - val_loss: 0.7769 - val_mae: 0.4805\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5730 - mae: 0.4814 - val_loss: 0.7842 - val_mae: 0.4862\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5605 - mae: 0.4966 - val_loss: 0.8031 - val_mae: 0.4831\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4890 - mae: 0.4515 - val_loss: 0.8219 - val_mae: 0.4894\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6064 - mae: 0.4693 - val_loss: 0.8047 - val_mae: 0.4721\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5976 - mae: 0.4921 - val_loss: 0.7702 - val_mae: 0.4476\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5466 - mae: 0.4578 - val_loss: 0.7402 - val_mae: 0.4418\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4522 - mae: 0.4073 - val_loss: 0.7326 - val_mae: 0.4476\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5192 - mae: 0.4370 - val_loss: 0.7276 - val_mae: 0.4481\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5524 - mae: 0.4491 - val_loss: 0.7106 - val_mae: 0.4408\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5290 - mae: 0.4331 - val_loss: 0.7014 - val_mae: 0.4359\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4196 - mae: 0.4208 - val_loss: 0.7024 - val_mae: 0.4325\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4526 - mae: 0.4152 - val_loss: 0.7461 - val_mae: 0.4660\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5134 - mae: 0.4374 - val_loss: 0.7979 - val_mae: 0.4981\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4456 - mae: 0.4101 - val_loss: 0.8288 - val_mae: 0.5125\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4943 - mae: 0.4739 - val_loss: 0.8106 - val_mae: 0.4949\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4408 - mae: 0.4084 - val_loss: 0.7572 - val_mae: 0.4568\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5000 - mae: 0.4373 - val_loss: 0.7362 - val_mae: 0.4462\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4818 - mae: 0.4371 - val_loss: 0.7201 - val_mae: 0.4511\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5567 - mae: 0.4661 - val_loss: 0.7090 - val_mae: 0.4518\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4381 - mae: 0.3893 - val_loss: 0.7088 - val_mae: 0.4513\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4194 - mae: 0.4124 - val_loss: 0.7237 - val_mae: 0.4547\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4254 - mae: 0.3996 - val_loss: 0.7310 - val_mae: 0.4486\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4875 - mae: 0.4132 - val_loss: 0.7513 - val_mae: 0.4652\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4532 - mae: 0.4155 - val_loss: 0.7313 - val_mae: 0.4572\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4657 - mae: 0.4371 - val_loss: 0.7162 - val_mae: 0.4462\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4772 - mae: 0.4159 - val_loss: 0.7143 - val_mae: 0.4329\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4142 - mae: 0.4058 - val_loss: 0.7363 - val_mae: 0.4328\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5425 - mae: 0.4127 - val_loss: 0.7486 - val_mae: 0.4365\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4987 - mae: 0.4148 - val_loss: 0.7421 - val_mae: 0.4278\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3654 - mae: 0.3453 - val_loss: 0.7293 - val_mae: 0.4262\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4751 - mae: 0.3766 - val_loss: 0.7308 - val_mae: 0.4392\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3766 - mae: 0.3368 - val_loss: 0.7325 - val_mae: 0.4489\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4578 - mae: 0.3974 - val_loss: 0.7395 - val_mae: 0.4555\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4414 - mae: 0.3734 - val_loss: 0.7555 - val_mae: 0.4671\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4388 - mae: 0.4169 - val_loss: 0.7506 - val_mae: 0.4558\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4335 - mae: 0.3950 - val_loss: 0.7682 - val_mae: 0.4732\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4543 - mae: 0.3951 - val_loss: 0.7770 - val_mae: 0.4907\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4270 - mae: 0.3866 - val_loss: 0.7576 - val_mae: 0.4805\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4044 - mae: 0.3845 - val_loss: 0.7581 - val_mae: 0.4813\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4459 - mae: 0.3911 - val_loss: 0.7575 - val_mae: 0.4762\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3922 - mae: 0.3565 - val_loss: 0.7736 - val_mae: 0.4842\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5162 - mae: 0.4289 - val_loss: 0.7775 - val_mae: 0.4862\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3556 - mae: 0.3720 - val_loss: 0.7778 - val_mae: 0.4805\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4164 - mae: 0.3831 - val_loss: 0.7652 - val_mae: 0.4781\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5588 - mae: 0.3663\n",
      "Test Loss: 0.5588\n",
      "Test MAE: 0.3663\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.3083\n",
      "MSE: 0.5588\n",
      "MAE: 0.3663\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "for col in target.columns:\n",
    "    y = target[col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # convert back to a dataframe\n",
    "    X_train_pca = pd.DataFrame(X_train_pca)\n",
    "    X_test_pca = pd.DataFrame(X_test_pca)\n",
    "\n",
    "    # split training data into training and validation data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_pca, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = NN_model(X_train, y_train, X_val, y_val, X_test_pca, y_test)\n",
    "\n",
    "    y_predicted[col] = model.predict(X_test_pca).flatten()\n",
    "    y_truth[col] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.823990</td>\n",
       "      <td>3.329969</td>\n",
       "      <td>0.414321</td>\n",
       "      <td>0.308510</td>\n",
       "      <td>0.066362</td>\n",
       "      <td>0.216090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.614796</td>\n",
       "      <td>-0.002380</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>0.093849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.313177</td>\n",
       "      <td>0.181588</td>\n",
       "      <td>0.114306</td>\n",
       "      <td>0.090248</td>\n",
       "      <td>0.062036</td>\n",
       "      <td>0.109636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.379244</td>\n",
       "      <td>31.750568</td>\n",
       "      <td>0.108698</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>2.765123</td>\n",
       "      <td>0.156546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.483399</td>\n",
       "      <td>0.295539</td>\n",
       "      <td>0.143515</td>\n",
       "      <td>0.050766</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.075028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      16.823990       3.329969       0.414321       0.308510       0.066362   \n",
       "1       6.614796      -0.002380       0.108477       0.093146       0.051840   \n",
       "2       2.313177       0.181588       0.114306       0.090248       0.062036   \n",
       "3      22.379244      31.750568       0.108698       0.034434       2.765123   \n",
       "4       5.483399       0.295539       0.143515       0.050766       0.284747   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0       0.216090  \n",
       "1       0.093849  \n",
       "2       0.109636  \n",
       "3       0.156546  \n",
       "4       0.075028  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.739658</td>\n",
       "      <td>40.735563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.91524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.660000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      30.000000      25.000000            0.5            2.0        0.00000   \n",
       "1      50.000000       0.000000            0.0            0.0        0.00000   \n",
       "2       0.000000       0.000000            0.0            1.5        0.00000   \n",
       "3      34.739658      40.735563            0.0            0.0        3.91524   \n",
       "4       8.660000       2.180000            0.0            0.0        0.72000   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0            1.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35816286323129254"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for all target variables\n",
    "r2 = r2_score(y_truth, y_predicted)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <td>0.057638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <td>0.604816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <td>0.128175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <td>0.165103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <td>0.884916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formate (g/L)</th>\n",
       "      <td>0.308329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R^2 Score\n",
       "Glucose (g/L)   0.057638\n",
       "Lactate (g/L)   0.604816\n",
       "Ethanol (g/L)   0.128175\n",
       "Acetate (g/L)   0.165103\n",
       "Biomass (g/L)   0.884916\n",
       "Formate (g/L)   0.308329"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for each target variable\n",
    "r2 = r2_score(y_truth, y_predicted, multioutput='raw_values')\n",
    "\n",
    "# convert to a dataframe\n",
    "r2 = pd.DataFrame(r2, index=target.columns, columns=['R^2 Score'])\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined r2 score is: **0.42913293043177275** [1]\n",
    "\n",
    "### The combined r2 score is: **0.35816286323129254** [curr]\n",
    "\n",
    "The combined r2 score is: **0.2843934946185081** [3]\n",
    "\n",
    "The combined r2 score is: **0.33809704738378416** [4]\n",
    "\n",
    "\n",
    "Which is an average score.\n",
    "\n",
    "Individually for each target variable, the r2 score has high variability. With Biomass being predicted most accurately with a score of 0.884916 (higher than before) and Glucose being predicted most poorly with a score of 0.057638."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. With the selected features dataset for each target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = pd.DataFrame(columns=target.columns)\n",
    "y_truth = pd.DataFrame(columns=target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose = pd.read_csv('modified_data/data_glucose2.csv')\n",
    "lactate = pd.read_csv('modified_data/data_lactate.csv')\n",
    "ethanol = pd.read_csv('modified_data/data_ethanol.csv')\n",
    "acetate = pd.read_csv('modified_data/data_acetate.csv')\n",
    "biomass = pd.read_csv('modified_data/data_biomass.csv')\n",
    "formate = pd.read_csv('modified_data/data_formate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [glucose, lactate, ethanol, acetate, biomass, formate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 408.7224 - mae: 13.1298 - val_loss: 442.9629 - val_mae: 14.7049\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 404.9343 - mae: 13.0881 - val_loss: 438.7206 - val_mae: 14.6806\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 401.1028 - mae: 13.0240 - val_loss: 433.7328 - val_mae: 14.6608\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 397.4810 - mae: 13.0408 - val_loss: 427.7477 - val_mae: 14.6414\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 389.8109 - mae: 13.0172 - val_loss: 420.2066 - val_mae: 14.6186\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 380.6319 - mae: 12.9170 - val_loss: 410.9977 - val_mae: 14.5888\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 376.1442 - mae: 12.8747 - val_loss: 399.6980 - val_mae: 14.5521\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 369.7792 - mae: 12.8291 - val_loss: 386.1407 - val_mae: 14.5089\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 347.9042 - mae: 12.7471 - val_loss: 369.4389 - val_mae: 14.4519\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 340.1248 - mae: 12.7729 - val_loss: 349.9674 - val_mae: 14.3807\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 322.7548 - mae: 12.6220 - val_loss: 327.3975 - val_mae: 14.2889\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 298.6776 - mae: 12.4004 - val_loss: 302.3180 - val_mae: 14.1685\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 286.7459 - mae: 12.3857 - val_loss: 275.4507 - val_mae: 14.0132\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 268.6611 - mae: 12.6181 - val_loss: 249.1814 - val_mae: 13.8209\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 263.6836 - mae: 12.4635 - val_loss: 227.4202 - val_mae: 13.7076\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.6498 - mae: 12.5134 - val_loss: 212.4607 - val_mae: 13.5731\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.3492 - mae: 12.6912 - val_loss: 202.4156 - val_mae: 13.4685\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 223.0169 - mae: 12.5444 - val_loss: 195.3000 - val_mae: 13.3640\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 235.4882 - mae: 13.3480 - val_loss: 190.8132 - val_mae: 13.2303\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.1004 - mae: 12.6147 - val_loss: 187.6791 - val_mae: 13.0931\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 211.6564 - mae: 12.6160 - val_loss: 185.6401 - val_mae: 12.9473\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 211.5154 - mae: 12.2770 - val_loss: 183.6924 - val_mae: 12.8002\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 208.0693 - mae: 12.0403 - val_loss: 181.1654 - val_mae: 12.6553\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 214.0709 - mae: 12.4100 - val_loss: 178.1125 - val_mae: 12.5151\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 218.2419 - mae: 12.2634 - val_loss: 173.8557 - val_mae: 12.3615\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 174.1856 - mae: 11.0416 - val_loss: 168.3557 - val_mae: 12.2003\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 222.8271 - mae: 12.2922 - val_loss: 164.5575 - val_mae: 12.0449\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.1444 - mae: 11.9077 - val_loss: 162.3020 - val_mae: 11.8992\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 192.4669 - mae: 11.7969 - val_loss: 161.0646 - val_mae: 11.7635\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 198.8203 - mae: 11.6875 - val_loss: 157.8992 - val_mae: 11.6043\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.9560 - mae: 12.1393 - val_loss: 154.5813 - val_mae: 11.4355\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 209.5977 - mae: 12.1576 - val_loss: 152.0705 - val_mae: 11.2706\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 189.3499 - mae: 11.6518 - val_loss: 149.2594 - val_mae: 11.1038\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.1454 - mae: 11.4589 - val_loss: 145.0602 - val_mae: 10.9023\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 177.6760 - mae: 11.1547 - val_loss: 141.5797 - val_mae: 10.7023\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 193.9893 - mae: 11.6920 - val_loss: 138.7042 - val_mae: 10.4993\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.3671 - mae: 11.2320 - val_loss: 137.0217 - val_mae: 10.3348\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 172.1452 - mae: 11.2492 - val_loss: 134.6998 - val_mae: 10.1464\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 196.6203 - mae: 11.6717 - val_loss: 133.1134 - val_mae: 9.9898\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 169.5650 - mae: 11.0395 - val_loss: 131.8018 - val_mae: 9.8412\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.7028 - mae: 10.8317 - val_loss: 131.5814 - val_mae: 9.7573\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 180.5880 - mae: 11.2586 - val_loss: 131.0399 - val_mae: 9.6702\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 189.2289 - mae: 11.3190 - val_loss: 129.9258 - val_mae: 9.5527\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 155.7219 - mae: 10.5513 - val_loss: 128.1591 - val_mae: 9.3908\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 173.3571 - mae: 10.8087 - val_loss: 126.2874 - val_mae: 9.1974\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.7103 - mae: 10.3973 - val_loss: 125.2477 - val_mae: 9.0462\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 169.7897 - mae: 10.6720 - val_loss: 124.5656 - val_mae: 8.9273\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 170.5690 - mae: 10.7746 - val_loss: 123.9814 - val_mae: 8.8118\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.4021 - mae: 10.2968 - val_loss: 123.4826 - val_mae: 8.7043\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 150.5041 - mae: 10.1965 - val_loss: 123.0119 - val_mae: 8.6406\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.3052 - mae: 10.7736 - val_loss: 123.1408 - val_mae: 8.5964\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 149.6123 - mae: 10.5186 - val_loss: 122.7989 - val_mae: 8.5258\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.9942 - mae: 10.4456 - val_loss: 122.2291 - val_mae: 8.4525\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 180.1371 - mae: 10.8149 - val_loss: 122.5384 - val_mae: 8.3965\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 165.1121 - mae: 10.3454 - val_loss: 123.1988 - val_mae: 8.3865\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 165.5193 - mae: 10.2024 - val_loss: 123.8142 - val_mae: 8.4080\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 147.8371 - mae: 9.7641 - val_loss: 122.8353 - val_mae: 8.3243\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.0742 - mae: 10.0920 - val_loss: 122.0099 - val_mae: 8.3016\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.6269 - mae: 10.5678 - val_loss: 121.8030 - val_mae: 8.2972\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 188.3183 - mae: 10.9564 - val_loss: 121.8883 - val_mae: 8.2828\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 169.6707 - mae: 10.3538 - val_loss: 122.2559 - val_mae: 8.2493\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 171.3634 - mae: 10.5832 - val_loss: 122.6710 - val_mae: 8.2183\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 169.2238 - mae: 10.2888 - val_loss: 122.3309 - val_mae: 8.1945\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 146.1402 - mae: 9.5951 - val_loss: 121.8398 - val_mae: 8.1868\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 166.2492 - mae: 10.2417 - val_loss: 121.6585 - val_mae: 8.1798\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 155.9676 - mae: 9.7745 - val_loss: 121.7128 - val_mae: 8.1775\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.6875 - mae: 10.5241 - val_loss: 121.7426 - val_mae: 8.1815\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 165.3883 - mae: 10.2753 - val_loss: 121.8021 - val_mae: 8.1783\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 172.8023 - mae: 10.5974 - val_loss: 121.8229 - val_mae: 8.1665\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 149.7718 - mae: 9.7459 - val_loss: 122.5546 - val_mae: 8.1674\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 180.9637 - mae: 10.4493 - val_loss: 123.8406 - val_mae: 8.1834\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 148.4155 - mae: 9.5271 - val_loss: 123.2988 - val_mae: 8.1628\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 174.4300 - mae: 10.6254 - val_loss: 122.5189 - val_mae: 8.1707\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 172.5869 - mae: 10.3899 - val_loss: 121.9796 - val_mae: 8.1877\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 165.9987 - mae: 10.3329 - val_loss: 121.7046 - val_mae: 8.2191\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.5340 - mae: 10.3638 - val_loss: 121.6775 - val_mae: 8.2142\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 160.7836 - mae: 9.9195 - val_loss: 121.6903 - val_mae: 8.2012\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.1689 - mae: 9.8763 - val_loss: 121.8348 - val_mae: 8.1932\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 154.1835 - mae: 10.1552 - val_loss: 121.9192 - val_mae: 8.1846\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 188.0956 - mae: 10.6962 - val_loss: 121.8910 - val_mae: 8.1514\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 149.8907 - mae: 9.8997 - val_loss: 121.9041 - val_mae: 8.1189\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.0557 - mae: 9.9743 - val_loss: 121.9225 - val_mae: 8.1021\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 188.0784 - mae: 10.9035 - val_loss: 122.1498 - val_mae: 8.0972\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 157.3874 - mae: 9.9932 - val_loss: 122.5927 - val_mae: 8.0970\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.6087 - mae: 9.7937 - val_loss: 122.0474 - val_mae: 8.0923\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.0157 - mae: 9.9741 - val_loss: 121.9921 - val_mae: 8.0949\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.0084 - mae: 10.0019 - val_loss: 122.2619 - val_mae: 8.0997\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 155.0911 - mae: 10.0884 - val_loss: 122.3007 - val_mae: 8.0975\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 189.2885 - mae: 10.8231 - val_loss: 122.0580 - val_mae: 8.0822\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 167.5470 - mae: 10.1753 - val_loss: 122.1351 - val_mae: 8.0709\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.8032 - mae: 10.0135 - val_loss: 122.2022 - val_mae: 8.0572\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.3900 - mae: 10.0108 - val_loss: 122.1833 - val_mae: 8.0384\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 141.7202 - mae: 9.3718 - val_loss: 122.2859 - val_mae: 8.0238\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 161.1540 - mae: 9.9933 - val_loss: 122.7821 - val_mae: 8.1299\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 181.6746 - mae: 10.9656 - val_loss: 122.5718 - val_mae: 8.0710\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 164.7466 - mae: 10.0919 - val_loss: 122.4269 - val_mae: 8.0150\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.8455 - mae: 9.8973 - val_loss: 122.9439 - val_mae: 8.0295\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.3609 - mae: 9.8462 - val_loss: 122.4035 - val_mae: 8.0332\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.6633 - mae: 9.7514 - val_loss: 122.2044 - val_mae: 8.0362\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 146.0469 - mae: 9.7407 - val_loss: 122.1645 - val_mae: 8.0379\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 316.6708 - mae: 14.1993\n",
      "Test Loss: 316.6708\n",
      "Test MAE: 14.1993\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.0524\n",
      "MSE: 316.6708\n",
      "MAE: 14.1993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 339.3779 - mae: 8.8387 - val_loss: 403.3616 - val_mae: 11.0919\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 328.5306 - mae: 8.6665 - val_loss: 390.1450 - val_mae: 11.0231\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 317.2617 - mae: 8.8103 - val_loss: 373.4736 - val_mae: 10.9425\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 301.3329 - mae: 8.9086 - val_loss: 352.4316 - val_mae: 11.0681\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 307.7095 - mae: 9.4314 - val_loss: 331.0471 - val_mae: 11.4469\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 280.8466 - mae: 9.8400 - val_loss: 312.8296 - val_mae: 11.9682\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 273.4690 - mae: 10.5439 - val_loss: 300.7741 - val_mae: 12.5190\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 295.1480 - mae: 11.4946 - val_loss: 296.7900 - val_mae: 12.7581\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 280.4429 - mae: 11.5516 - val_loss: 297.4200 - val_mae: 12.6194\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 255.2240 - mae: 10.5837 - val_loss: 299.9523 - val_mae: 12.3773\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 280.3741 - mae: 10.6601 - val_loss: 304.7146 - val_mae: 12.0575\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 265.6359 - mae: 10.0388 - val_loss: 303.6573 - val_mae: 12.0627\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 280.2676 - mae: 10.7464 - val_loss: 302.4909 - val_mae: 12.0708\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 257.3831 - mae: 9.8860 - val_loss: 299.0640 - val_mae: 12.1929\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 276.8449 - mae: 10.7058 - val_loss: 296.3243 - val_mae: 12.2977\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 266.6781 - mae: 10.7251 - val_loss: 295.1425 - val_mae: 12.3058\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 248.2145 - mae: 10.2895 - val_loss: 292.3317 - val_mae: 12.3995\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 251.3728 - mae: 10.4325 - val_loss: 291.2393 - val_mae: 12.3897\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 266.7650 - mae: 11.1316 - val_loss: 290.6507 - val_mae: 12.3424\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.6958 - mae: 10.1539 - val_loss: 290.0153 - val_mae: 12.3001\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 258.3886 - mae: 10.5148 - val_loss: 289.1882 - val_mae: 12.2959\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 252.6560 - mae: 10.5447 - val_loss: 290.8867 - val_mae: 12.1027\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 265.9689 - mae: 10.2924 - val_loss: 290.2917 - val_mae: 12.0840\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 274.3776 - mae: 10.3395 - val_loss: 292.7262 - val_mae: 11.8673\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.0135 - mae: 9.3324 - val_loss: 293.4164 - val_mae: 11.7785\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.4895 - mae: 9.4849 - val_loss: 288.8454 - val_mae: 12.0432\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 254.8551 - mae: 9.9100 - val_loss: 287.9236 - val_mae: 12.0740\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 259.2780 - mae: 9.8151 - val_loss: 287.7300 - val_mae: 12.0804\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.3060 - mae: 10.2721 - val_loss: 288.6256 - val_mae: 11.9760\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.4377 - mae: 9.8358 - val_loss: 290.5031 - val_mae: 11.7932\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.5742 - mae: 9.5620 - val_loss: 288.5779 - val_mae: 11.9578\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.1521 - mae: 9.8533 - val_loss: 286.6862 - val_mae: 12.2157\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.2067 - mae: 9.7924 - val_loss: 288.2556 - val_mae: 12.0231\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.6286 - mae: 9.1912 - val_loss: 289.8700 - val_mae: 11.8546\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.5606 - mae: 9.5148 - val_loss: 293.9075 - val_mae: 11.5402\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 255.3951 - mae: 9.2555 - val_loss: 292.8569 - val_mae: 11.6123\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 254.4413 - mae: 9.3779 - val_loss: 292.1369 - val_mae: 11.6664\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 261.4330 - mae: 9.7939 - val_loss: 293.0394 - val_mae: 11.6060\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.2950 - mae: 9.0883 - val_loss: 290.9412 - val_mae: 11.7690\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 247.7203 - mae: 9.5281 - val_loss: 290.1325 - val_mae: 11.8269\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 238.9561 - mae: 9.9196 - val_loss: 287.2909 - val_mae: 12.1943\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.1428 - mae: 9.6485 - val_loss: 288.3574 - val_mae: 12.0363\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 243.0251 - mae: 9.6791 - val_loss: 291.6968 - val_mae: 11.7052\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.3570 - mae: 9.2464 - val_loss: 294.4051 - val_mae: 11.5027\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 257.7951 - mae: 9.3296 - val_loss: 292.1281 - val_mae: 11.6693\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 239.7974 - mae: 8.9948 - val_loss: 288.4564 - val_mae: 12.0243\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.5836 - mae: 9.7703 - val_loss: 287.0452 - val_mae: 12.2893\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 232.4180 - mae: 9.4567 - val_loss: 287.5380 - val_mae: 12.1862\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.8994 - mae: 9.6980 - val_loss: 289.0668 - val_mae: 11.9460\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.8843 - mae: 9.3297 - val_loss: 290.6956 - val_mae: 11.7828\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.3583 - mae: 9.4909 - val_loss: 292.8070 - val_mae: 11.6238\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.2327 - mae: 9.5778 - val_loss: 292.4490 - val_mae: 11.6452\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 249.7295 - mae: 9.4036 - val_loss: 292.4122 - val_mae: 11.6458\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 240.7450 - mae: 9.3812 - val_loss: 288.7540 - val_mae: 12.0080\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 250.7965 - mae: 9.7935 - val_loss: 288.7240 - val_mae: 11.9977\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 245.9464 - mae: 9.7577 - val_loss: 289.1602 - val_mae: 11.9144\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 229.3251 - mae: 9.3741 - val_loss: 290.1734 - val_mae: 11.8130\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 252.2131 - mae: 9.5280 - val_loss: 292.3889 - val_mae: 11.6330\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 255.3291 - mae: 9.1665 - val_loss: 293.1862 - val_mae: 11.5670\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 236.1222 - mae: 8.8425 - val_loss: 293.5421 - val_mae: 11.5359\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 244.1301 - mae: 9.3253 - val_loss: 290.1548 - val_mae: 11.7842\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 232.5001 - mae: 9.0930 - val_loss: 288.7242 - val_mae: 11.9193\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 253.9367 - mae: 9.7881 - val_loss: 287.5266 - val_mae: 12.0717\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 252.3494 - mae: 9.9053 - val_loss: 289.2721 - val_mae: 11.8525\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 250.3686 - mae: 9.4809 - val_loss: 288.1621 - val_mae: 11.9647\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 246.7505 - mae: 9.6833 - val_loss: 286.9339 - val_mae: 12.1112\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.8715 - mae: 9.6699 - val_loss: 287.6512 - val_mae: 12.0009\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 260.1919 - mae: 9.9168 - val_loss: 290.0693 - val_mae: 11.7543\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 251.4787 - mae: 9.4832 - val_loss: 290.5899 - val_mae: 11.7168\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.9056 - mae: 9.1841 - val_loss: 290.6981 - val_mae: 11.7196\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 238.9397 - mae: 9.4348 - val_loss: 289.2263 - val_mae: 11.8259\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.1603 - mae: 9.6150 - val_loss: 285.8746 - val_mae: 12.1521\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.1487 - mae: 9.6724 - val_loss: 286.3810 - val_mae: 12.0854\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.1211 - mae: 9.3462 - val_loss: 285.7628 - val_mae: 12.1916\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.4891 - mae: 9.9414 - val_loss: 286.0102 - val_mae: 12.1676\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.9234 - mae: 9.5645 - val_loss: 288.1128 - val_mae: 11.9251\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 240.0318 - mae: 9.3920 - val_loss: 288.4670 - val_mae: 11.8809\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.3535 - mae: 9.4909 - val_loss: 287.0987 - val_mae: 12.0234\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.9659 - mae: 9.3746 - val_loss: 285.9021 - val_mae: 12.2046\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 228.0025 - mae: 9.5690 - val_loss: 285.8903 - val_mae: 12.2683\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 245.0063 - mae: 10.2978 - val_loss: 285.5539 - val_mae: 12.4912\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 254.8242 - mae: 10.0966 - val_loss: 286.5624 - val_mae: 12.1506\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 253.5084 - mae: 9.8023 - val_loss: 292.9353 - val_mae: 11.5466\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 244.8808 - mae: 8.9426 - val_loss: 292.4924 - val_mae: 11.5577\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 229.8412 - mae: 8.9727 - val_loss: 289.2356 - val_mae: 11.8293\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.5165 - mae: 9.4138 - val_loss: 286.2738 - val_mae: 12.3872\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.9519 - mae: 9.7017 - val_loss: 286.3981 - val_mae: 12.4663\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 238.6592 - mae: 10.0605 - val_loss: 286.9343 - val_mae: 12.1552\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.8893 - mae: 9.8647 - val_loss: 287.9201 - val_mae: 11.9536\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.2182 - mae: 9.1867 - val_loss: 289.3372 - val_mae: 11.8005\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 226.1565 - mae: 8.8952 - val_loss: 290.2861 - val_mae: 11.7216\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 247.7500 - mae: 9.6252 - val_loss: 289.4503 - val_mae: 11.8660\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 254.8239 - mae: 9.7667 - val_loss: 289.8162 - val_mae: 11.8310\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 233.6886 - mae: 9.1765 - val_loss: 294.4394 - val_mae: 11.4418\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 238.3950 - mae: 9.0377 - val_loss: 291.8535 - val_mae: 11.5706\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 236.6630 - mae: 8.9978 - val_loss: 288.0785 - val_mae: 11.8987\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.4001 - mae: 9.6839 - val_loss: 285.6979 - val_mae: 12.2476\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 242.7538 - mae: 9.8685 - val_loss: 286.1012 - val_mae: 12.0853\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 238.7372 - mae: 9.5287 - val_loss: 287.5916 - val_mae: 11.8996\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 250.3420 - mae: 9.6229 - val_loss: 287.5817 - val_mae: 11.8917\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 110.1694 - mae: 7.1749\n",
      "Test Loss: 110.1694\n",
      "Test MAE: 7.1749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.1615\n",
      "MSE: 110.1694\n",
      "MAE: 7.1749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.8460 - mae: 0.4952 - val_loss: 0.9277 - val_mae: 0.5249\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7078 - mae: 0.5143 - val_loss: 0.8940 - val_mae: 0.5842\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7365 - mae: 0.5817 - val_loss: 0.8869 - val_mae: 0.5763\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6756 - mae: 0.5011 - val_loss: 0.8872 - val_mae: 0.5547\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6800 - mae: 0.5321 - val_loss: 0.8763 - val_mae: 0.5796\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6439 - mae: 0.5216 - val_loss: 0.8607 - val_mae: 0.6256\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6442 - mae: 0.5672 - val_loss: 0.8595 - val_mae: 0.6547\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.5636 - val_loss: 0.8514 - val_mae: 0.6020\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6601 - mae: 0.5277 - val_loss: 0.8490 - val_mae: 0.5713\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6409 - mae: 0.5292 - val_loss: 0.8428 - val_mae: 0.6093\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6132 - mae: 0.5016 - val_loss: 0.8384 - val_mae: 0.5987\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5307 - mae: 0.4755 - val_loss: 0.8254 - val_mae: 0.6208\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5635 - mae: 0.4986 - val_loss: 0.8126 - val_mae: 0.6038\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5920 - mae: 0.4560 - val_loss: 0.8069 - val_mae: 0.5657\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5321 - mae: 0.4790 - val_loss: 0.8072 - val_mae: 0.6362\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5989 - mae: 0.5203 - val_loss: 0.7967 - val_mae: 0.5927\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6128 - mae: 0.4726 - val_loss: 0.8069 - val_mae: 0.4927\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5348 - mae: 0.4191 - val_loss: 0.7941 - val_mae: 0.5518\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5504 - mae: 0.4737 - val_loss: 0.7934 - val_mae: 0.5598\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5483 - mae: 0.4502 - val_loss: 0.7871 - val_mae: 0.5326\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5225 - mae: 0.4424 - val_loss: 0.7937 - val_mae: 0.5962\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5374 - mae: 0.4937 - val_loss: 0.8005 - val_mae: 0.6141\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5457 - mae: 0.4793 - val_loss: 0.7893 - val_mae: 0.5359\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5035 - mae: 0.4439 - val_loss: 0.7903 - val_mae: 0.5333\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4973 - mae: 0.4289 - val_loss: 0.8064 - val_mae: 0.6095\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5094 - mae: 0.4861 - val_loss: 0.8273 - val_mae: 0.6577\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4694 - mae: 0.4519 - val_loss: 0.7864 - val_mae: 0.5465\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5045 - mae: 0.4291 - val_loss: 0.7808 - val_mae: 0.5246\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4745 - mae: 0.4343 - val_loss: 0.8115 - val_mae: 0.6042\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4446 - mae: 0.4340 - val_loss: 0.8252 - val_mae: 0.6118\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4364 - mae: 0.4456 - val_loss: 0.8057 - val_mae: 0.5538\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4419 - mae: 0.4042 - val_loss: 0.7950 - val_mae: 0.5258\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4875 - mae: 0.4218 - val_loss: 0.7860 - val_mae: 0.5186\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4706 - mae: 0.4097 - val_loss: 0.7935 - val_mae: 0.5752\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5088 - mae: 0.4756 - val_loss: 0.7937 - val_mae: 0.5755\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4528 - mae: 0.4122 - val_loss: 0.7969 - val_mae: 0.5676\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5096 - mae: 0.4634 - val_loss: 0.8001 - val_mae: 0.5668\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4954 - mae: 0.4274 - val_loss: 0.7772 - val_mae: 0.5296\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4950 - mae: 0.4240 - val_loss: 0.7836 - val_mae: 0.5448\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4754 - mae: 0.4306 - val_loss: 0.8129 - val_mae: 0.5916\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5142 - mae: 0.4545 - val_loss: 0.7943 - val_mae: 0.5665\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4757 - mae: 0.4159 - val_loss: 0.7818 - val_mae: 0.5536\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4393 - mae: 0.4112 - val_loss: 0.7832 - val_mae: 0.5692\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4793 - mae: 0.4475 - val_loss: 0.8000 - val_mae: 0.5864\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5085 - mae: 0.4845 - val_loss: 0.8457 - val_mae: 0.6262\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4625 - mae: 0.4299 - val_loss: 0.7889 - val_mae: 0.5380\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4924 - mae: 0.4230 - val_loss: 0.7849 - val_mae: 0.5348\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4556 - mae: 0.4094 - val_loss: 0.7962 - val_mae: 0.5753\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5102 - mae: 0.4466 - val_loss: 0.7960 - val_mae: 0.5554\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5141 - mae: 0.4289 - val_loss: 0.7892 - val_mae: 0.5277\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4466 - mae: 0.4116 - val_loss: 0.7961 - val_mae: 0.5451\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5259 - mae: 0.4440 - val_loss: 0.7894 - val_mae: 0.5360\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4755 - mae: 0.4013 - val_loss: 0.7809 - val_mae: 0.5346\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5405 - mae: 0.4599 - val_loss: 0.7992 - val_mae: 0.5790\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4817 - mae: 0.4312 - val_loss: 0.7822 - val_mae: 0.5406\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4027 - mae: 0.4152 - val_loss: 0.8070 - val_mae: 0.5768\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4275 - mae: 0.4074 - val_loss: 0.8000 - val_mae: 0.5542\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5116 - mae: 0.4469 - val_loss: 0.8002 - val_mae: 0.5506\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5433 - mae: 0.4390 - val_loss: 0.7807 - val_mae: 0.5152\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4989 - mae: 0.4064 - val_loss: 0.7840 - val_mae: 0.5385\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5284 - mae: 0.4297 - val_loss: 0.7709 - val_mae: 0.5205\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4488 - mae: 0.3954 - val_loss: 0.7733 - val_mae: 0.5397\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4768 - mae: 0.4506 - val_loss: 0.8137 - val_mae: 0.6099\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4855 - mae: 0.4696 - val_loss: 0.7833 - val_mae: 0.5567\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4566 - mae: 0.4290 - val_loss: 0.7716 - val_mae: 0.5018\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4847 - mae: 0.4015 - val_loss: 0.7816 - val_mae: 0.5327\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4460 - mae: 0.4072 - val_loss: 0.8042 - val_mae: 0.5559\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4569 - mae: 0.3984 - val_loss: 0.7852 - val_mae: 0.5279\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4677 - mae: 0.4098 - val_loss: 0.8035 - val_mae: 0.5623\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4306 - mae: 0.4307 - val_loss: 0.8059 - val_mae: 0.5690\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4865 - mae: 0.4277 - val_loss: 0.7786 - val_mae: 0.5289\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4782 - mae: 0.3771 - val_loss: 0.7686 - val_mae: 0.5050\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4538 - mae: 0.3900 - val_loss: 0.8323 - val_mae: 0.5978\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5073 - mae: 0.4641 - val_loss: 0.7890 - val_mae: 0.5537\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3924 - mae: 0.4041 - val_loss: 0.7770 - val_mae: 0.5351\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4850 - mae: 0.4129 - val_loss: 0.7714 - val_mae: 0.5219\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4171 - mae: 0.3868 - val_loss: 0.8170 - val_mae: 0.5820\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4548 - mae: 0.4512 - val_loss: 0.8138 - val_mae: 0.5719\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4567 - mae: 0.4289 - val_loss: 0.7906 - val_mae: 0.5284\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4491 - mae: 0.4013 - val_loss: 0.7779 - val_mae: 0.4876\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4911 - mae: 0.4017 - val_loss: 0.7885 - val_mae: 0.5293\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4537 - mae: 0.3981 - val_loss: 0.7921 - val_mae: 0.5514\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4167 - mae: 0.4321 - val_loss: 0.8460 - val_mae: 0.6282\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4732 - mae: 0.4583 - val_loss: 0.7780 - val_mae: 0.5200\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4379 - mae: 0.3704 - val_loss: 0.7662 - val_mae: 0.4824\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4703 - mae: 0.3806 - val_loss: 0.7731 - val_mae: 0.5240\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5013 - mae: 0.4417 - val_loss: 0.8601 - val_mae: 0.6326\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4227 - mae: 0.4395 - val_loss: 0.8055 - val_mae: 0.5707\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4400 - mae: 0.4220 - val_loss: 0.7646 - val_mae: 0.5159\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4581 - mae: 0.4011 - val_loss: 0.7651 - val_mae: 0.5027\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4415 - mae: 0.3987 - val_loss: 0.7823 - val_mae: 0.5559\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4283 - mae: 0.4304 - val_loss: 0.8043 - val_mae: 0.5787\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4312 - mae: 0.4179 - val_loss: 0.7956 - val_mae: 0.5645\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4203 - mae: 0.4062 - val_loss: 0.7881 - val_mae: 0.5449\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4239 - mae: 0.3851 - val_loss: 0.7926 - val_mae: 0.5432\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4176 - mae: 0.4055 - val_loss: 0.8225 - val_mae: 0.5762\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4514 - mae: 0.4246 - val_loss: 0.8184 - val_mae: 0.5676\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4379 - mae: 0.4064 - val_loss: 0.7980 - val_mae: 0.5395\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4667 - mae: 0.3972 - val_loss: 0.7691 - val_mae: 0.4975\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4011 - mae: 0.3846 - val_loss: 0.8097 - val_mae: 0.5743\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5775 - mae: 0.4223\n",
      "Test Loss: 0.5775\n",
      "Test MAE: 0.4223\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.0791\n",
      "MSE: 0.5775\n",
      "MAE: 0.4223\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4479 - mae: 0.4871 - val_loss: 0.4519 - val_mae: 0.4941\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4067 - mae: 0.4318 - val_loss: 0.4632 - val_mae: 0.4583\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3924 - mae: 0.4137 - val_loss: 0.4493 - val_mae: 0.4703\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4010 - mae: 0.4344 - val_loss: 0.4310 - val_mae: 0.4816\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3932 - mae: 0.4513 - val_loss: 0.4341 - val_mae: 0.4707\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3869 - mae: 0.4480 - val_loss: 0.4273 - val_mae: 0.4672\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3999 - mae: 0.4516 - val_loss: 0.4054 - val_mae: 0.4932\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3868 - mae: 0.4632 - val_loss: 0.4102 - val_mae: 0.4579\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3706 - mae: 0.4304 - val_loss: 0.3979 - val_mae: 0.4544\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3521 - mae: 0.4310 - val_loss: 0.3920 - val_mae: 0.4377\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3752 - mae: 0.4265 - val_loss: 0.3748 - val_mae: 0.4406\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3409 - mae: 0.4007 - val_loss: 0.3661 - val_mae: 0.4402\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3200 - mae: 0.3880 - val_loss: 0.3546 - val_mae: 0.4471\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3362 - mae: 0.3953 - val_loss: 0.3474 - val_mae: 0.4153\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3158 - mae: 0.3725 - val_loss: 0.3340 - val_mae: 0.4152\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3173 - mae: 0.3895 - val_loss: 0.3323 - val_mae: 0.4520\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3655 - mae: 0.4124 - val_loss: 0.3170 - val_mae: 0.4041\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3685 - mae: 0.3915 - val_loss: 0.3236 - val_mae: 0.3714\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3196 - mae: 0.3489 - val_loss: 0.3171 - val_mae: 0.4097\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3110 - mae: 0.4024 - val_loss: 0.3028 - val_mae: 0.4504\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2968 - mae: 0.3925 - val_loss: 0.2839 - val_mae: 0.3830\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3079 - mae: 0.3664 - val_loss: 0.2774 - val_mae: 0.3744\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2927 - mae: 0.3820 - val_loss: 0.2777 - val_mae: 0.4025\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3296 - mae: 0.3810 - val_loss: 0.3121 - val_mae: 0.3674\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3171 - mae: 0.3597 - val_loss: 0.2976 - val_mae: 0.4177\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3327 - mae: 0.3996 - val_loss: 0.2876 - val_mae: 0.4252\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3042 - mae: 0.3854 - val_loss: 0.2794 - val_mae: 0.3907\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3172 - mae: 0.3838 - val_loss: 0.2742 - val_mae: 0.3826\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2684 - mae: 0.3390 - val_loss: 0.2757 - val_mae: 0.3638\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2886 - mae: 0.3482 - val_loss: 0.2733 - val_mae: 0.3867\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3008 - mae: 0.3546 - val_loss: 0.2699 - val_mae: 0.3904\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3740 - mae: 0.3957 - val_loss: 0.2711 - val_mae: 0.3513\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3134 - mae: 0.3489 - val_loss: 0.2964 - val_mae: 0.3432\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3016 - mae: 0.3468 - val_loss: 0.2750 - val_mae: 0.4002\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3171 - mae: 0.4008 - val_loss: 0.2717 - val_mae: 0.4092\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3085 - mae: 0.3776 - val_loss: 0.2813 - val_mae: 0.3436\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2930 - mae: 0.3303 - val_loss: 0.2661 - val_mae: 0.3536\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2615 - mae: 0.3310 - val_loss: 0.2622 - val_mae: 0.3839\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3031 - mae: 0.3639 - val_loss: 0.2612 - val_mae: 0.3774\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2948 - mae: 0.3735 - val_loss: 0.2627 - val_mae: 0.3732\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2750 - mae: 0.3339 - val_loss: 0.2704 - val_mae: 0.3691\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2673 - mae: 0.3302 - val_loss: 0.2670 - val_mae: 0.3726\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3119 - mae: 0.3514 - val_loss: 0.2638 - val_mae: 0.3761\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2866 - mae: 0.3436 - val_loss: 0.2628 - val_mae: 0.3601\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3142 - mae: 0.3557 - val_loss: 0.2614 - val_mae: 0.3624\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2703 - mae: 0.3367 - val_loss: 0.2613 - val_mae: 0.3483\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2766 - mae: 0.3309 - val_loss: 0.2597 - val_mae: 0.3351\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2978 - mae: 0.3331 - val_loss: 0.2577 - val_mae: 0.3348\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3050 - mae: 0.3370 - val_loss: 0.2536 - val_mae: 0.3646\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2756 - mae: 0.3574 - val_loss: 0.2590 - val_mae: 0.3971\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2685 - mae: 0.3788 - val_loss: 0.2548 - val_mae: 0.3823\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3274 - mae: 0.3625 - val_loss: 0.2620 - val_mae: 0.3400\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3149 - mae: 0.3394 - val_loss: 0.2546 - val_mae: 0.3485\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2671 - mae: 0.3336 - val_loss: 0.2543 - val_mae: 0.3749\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3051 - mae: 0.3857 - val_loss: 0.2481 - val_mae: 0.3600\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2752 - mae: 0.3362 - val_loss: 0.2602 - val_mae: 0.3452\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2858 - mae: 0.3234 - val_loss: 0.2580 - val_mae: 0.3556\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2908 - mae: 0.3477 - val_loss: 0.2610 - val_mae: 0.3749\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2870 - mae: 0.3521 - val_loss: 0.2600 - val_mae: 0.3652\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3027 - mae: 0.3558 - val_loss: 0.2597 - val_mae: 0.3473\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3020 - mae: 0.3479 - val_loss: 0.2604 - val_mae: 0.3551\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2735 - mae: 0.3307 - val_loss: 0.2578 - val_mae: 0.3617\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3074 - mae: 0.3512 - val_loss: 0.2562 - val_mae: 0.3668\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3113 - mae: 0.3570 - val_loss: 0.2548 - val_mae: 0.3678\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2570 - mae: 0.3299 - val_loss: 0.2541 - val_mae: 0.3715\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2829 - mae: 0.3368 - val_loss: 0.2536 - val_mae: 0.3503\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2586 - mae: 0.3311 - val_loss: 0.2518 - val_mae: 0.3694\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2652 - mae: 0.3394 - val_loss: 0.2508 - val_mae: 0.3559\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2953 - mae: 0.3454 - val_loss: 0.2466 - val_mae: 0.3471\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2603 - mae: 0.3162 - val_loss: 0.2433 - val_mae: 0.3373\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3002 - mae: 0.3386 - val_loss: 0.2461 - val_mae: 0.3423\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2925 - mae: 0.3343 - val_loss: 0.2535 - val_mae: 0.3440\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2509 - mae: 0.3204 - val_loss: 0.2564 - val_mae: 0.3527\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2601 - mae: 0.3301 - val_loss: 0.2567 - val_mae: 0.3606\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2891 - mae: 0.3606 - val_loss: 0.2497 - val_mae: 0.3537\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2913 - mae: 0.3401 - val_loss: 0.2634 - val_mae: 0.3327\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2998 - mae: 0.3241 - val_loss: 0.2580 - val_mae: 0.3431\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3113 - mae: 0.3518 - val_loss: 0.2607 - val_mae: 0.3889\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2925 - mae: 0.3597 - val_loss: 0.2635 - val_mae: 0.3936\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2549 - mae: 0.3465 - val_loss: 0.2633 - val_mae: 0.3945\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3144 - mae: 0.3852 - val_loss: 0.2602 - val_mae: 0.3693\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2928 - mae: 0.3440 - val_loss: 0.2586 - val_mae: 0.3512\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2635 - mae: 0.3218 - val_loss: 0.2587 - val_mae: 0.3465\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2873 - mae: 0.3191 - val_loss: 0.2604 - val_mae: 0.3458\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3120 - mae: 0.3429 - val_loss: 0.2606 - val_mae: 0.3517\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3243 - mae: 0.3504 - val_loss: 0.2589 - val_mae: 0.3528\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3108 - mae: 0.3402 - val_loss: 0.2598 - val_mae: 0.3563\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3137 - mae: 0.3493 - val_loss: 0.2578 - val_mae: 0.3774\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2432 - mae: 0.3303 - val_loss: 0.2533 - val_mae: 0.3772\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2811 - mae: 0.3609 - val_loss: 0.2488 - val_mae: 0.3608\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2797 - mae: 0.3461 - val_loss: 0.2460 - val_mae: 0.3627\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2913 - mae: 0.3443 - val_loss: 0.2458 - val_mae: 0.3509\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2841 - mae: 0.3380 - val_loss: 0.2473 - val_mae: 0.3575\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2718 - mae: 0.3392 - val_loss: 0.2476 - val_mae: 0.3586\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2908 - mae: 0.3436 - val_loss: 0.2450 - val_mae: 0.3566\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2637 - mae: 0.3248 - val_loss: 0.2430 - val_mae: 0.3568\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2751 - mae: 0.3480 - val_loss: 0.2416 - val_mae: 0.3596\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2859 - mae: 0.3473 - val_loss: 0.2372 - val_mae: 0.3473\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2827 - mae: 0.3248 - val_loss: 0.2464 - val_mae: 0.3426\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2873 - mae: 0.3345 - val_loss: 0.2432 - val_mae: 0.3512\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3657 - mae: 0.3588\n",
      "Test Loss: 0.3657\n",
      "Test MAE: 0.3588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.1171\n",
      "MSE: 0.3657\n",
      "MAE: 0.3588\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.2057 - mae: 1.1307 - val_loss: 1.7257 - val_mae: 1.1653\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9862 - mae: 1.1217 - val_loss: 1.8415 - val_mae: 1.0871\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9281 - mae: 1.0752 - val_loss: 1.9991 - val_mae: 1.0525\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7327 - mae: 0.9722 - val_loss: 1.7927 - val_mae: 1.0879\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8668 - mae: 1.0964 - val_loss: 1.7297 - val_mae: 1.1304\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9637 - mae: 1.1295 - val_loss: 1.7020 - val_mae: 1.1093\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0125 - mae: 1.1351 - val_loss: 1.7856 - val_mae: 1.0675\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7289 - mae: 0.9817 - val_loss: 1.7808 - val_mae: 1.0513\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7747 - mae: 1.0598 - val_loss: 1.5727 - val_mae: 1.0583\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6276 - mae: 1.0243 - val_loss: 1.7156 - val_mae: 1.0002\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8347 - mae: 0.9698 - val_loss: 1.6554 - val_mae: 0.9956\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5998 - mae: 0.9784 - val_loss: 1.5539 - val_mae: 1.0219\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5416 - mae: 0.9901 - val_loss: 1.4556 - val_mae: 1.0057\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6248 - mae: 1.0228 - val_loss: 1.5128 - val_mae: 0.9421\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3348 - mae: 0.9013 - val_loss: 1.3128 - val_mae: 0.9948\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4443 - mae: 0.9501 - val_loss: 1.2467 - val_mae: 0.8537\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2817 - mae: 0.8622 - val_loss: 1.1126 - val_mae: 0.8036\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2096 - mae: 0.8510 - val_loss: 0.9141 - val_mae: 0.7972\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9250 - mae: 0.7691 - val_loss: 0.8568 - val_mae: 0.7602\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9817 - mae: 0.7234 - val_loss: 0.7319 - val_mae: 0.7073\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7544 - mae: 0.6780 - val_loss: 0.6658 - val_mae: 0.6114\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7267 - mae: 0.5433 - val_loss: 0.4831 - val_mae: 0.5574\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5914 - mae: 0.5529 - val_loss: 0.4082 - val_mae: 0.4793\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7111 - mae: 0.5324 - val_loss: 0.3543 - val_mae: 0.4487\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4745 - mae: 0.4579 - val_loss: 0.2364 - val_mae: 0.3997\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6231 - mae: 0.5564 - val_loss: 0.3446 - val_mae: 0.3929\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4902 - mae: 0.5163 - val_loss: 0.2797 - val_mae: 0.3535\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6443 - mae: 0.5188 - val_loss: 0.1805 - val_mae: 0.3645\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5779 - mae: 0.5365 - val_loss: 0.2343 - val_mae: 0.3632\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3871 - mae: 0.4474 - val_loss: 0.0832 - val_mae: 0.2309\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3818 - mae: 0.4331 - val_loss: 0.1292 - val_mae: 0.2355\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4187 - mae: 0.4242 - val_loss: 0.0577 - val_mae: 0.1803\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3659 - mae: 0.3952 - val_loss: 0.0813 - val_mae: 0.2173\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3566 - mae: 0.4221 - val_loss: 0.1527 - val_mae: 0.2782\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5107 - mae: 0.4420 - val_loss: 0.1379 - val_mae: 0.3364\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3659 - mae: 0.4047 - val_loss: 0.1536 - val_mae: 0.2520\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4220 - mae: 0.3685 - val_loss: 0.0717 - val_mae: 0.2175\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2676 - mae: 0.3808 - val_loss: 0.1713 - val_mae: 0.2732\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4247 - mae: 0.4195 - val_loss: 0.1496 - val_mae: 0.2949\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2558 - mae: 0.3662 - val_loss: 0.1151 - val_mae: 0.2821\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4129 - mae: 0.4269 - val_loss: 0.2555 - val_mae: 0.3677\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3498 - mae: 0.3677 - val_loss: 0.1050 - val_mae: 0.2495\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5336 - mae: 0.4836 - val_loss: 0.1243 - val_mae: 0.2283\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3643 - mae: 0.3729 - val_loss: 0.0667 - val_mae: 0.1750\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1777 - mae: 0.2762 - val_loss: 0.1928 - val_mae: 0.3132\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2558 - mae: 0.3542 - val_loss: 0.0773 - val_mae: 0.1971\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3493 - mae: 0.3932 - val_loss: 0.2282 - val_mae: 0.3283\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.3968 - val_loss: 0.0676 - val_mae: 0.2249\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5288 - mae: 0.4512 - val_loss: 0.4698 - val_mae: 0.4755\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3544 - mae: 0.3781 - val_loss: 0.1616 - val_mae: 0.3461\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4733 - mae: 0.4866 - val_loss: 0.2474 - val_mae: 0.3637\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3172 - mae: 0.3539 - val_loss: 0.0656 - val_mae: 0.2087\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3128 - mae: 0.3955 - val_loss: 0.0661 - val_mae: 0.2077\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1992 - mae: 0.2906 - val_loss: 0.0668 - val_mae: 0.1927\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3764 - mae: 0.3881 - val_loss: 0.0983 - val_mae: 0.2226\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2423 - mae: 0.3555 - val_loss: 0.0729 - val_mae: 0.2246\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2813 - mae: 0.3474 - val_loss: 0.1782 - val_mae: 0.2919\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4340 - mae: 0.4154 - val_loss: 0.0640 - val_mae: 0.2039\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4258 - mae: 0.3979 - val_loss: 0.1420 - val_mae: 0.2673\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3470 - mae: 0.3651 - val_loss: 0.0737 - val_mae: 0.2038\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3364 - mae: 0.3988 - val_loss: 0.1440 - val_mae: 0.2577\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2132 - mae: 0.2893 - val_loss: 0.0677 - val_mae: 0.1992\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2087 - mae: 0.3263 - val_loss: 0.1312 - val_mae: 0.2500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3635 - mae: 0.3614 - val_loss: 0.0779 - val_mae: 0.2353\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3416 - mae: 0.3972 - val_loss: 0.0626 - val_mae: 0.1837\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3953 - mae: 0.3743 - val_loss: 0.2526 - val_mae: 0.3271\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3921 - mae: 0.4007 - val_loss: 0.0591 - val_mae: 0.1927\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2240 - mae: 0.3162 - val_loss: 0.2889 - val_mae: 0.3820\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3778 - mae: 0.3924 - val_loss: 0.1215 - val_mae: 0.2845\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5671 - mae: 0.5288 - val_loss: 0.2446 - val_mae: 0.3689\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2676 - mae: 0.3509 - val_loss: 0.0726 - val_mae: 0.2228\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3404 - mae: 0.3876 - val_loss: 0.2018 - val_mae: 0.3261\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4002 - mae: 0.3916 - val_loss: 0.1173 - val_mae: 0.2683\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3802 - mae: 0.4046 - val_loss: 0.0821 - val_mae: 0.2351\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3008 - mae: 0.3631 - val_loss: 0.0727 - val_mae: 0.2063\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3533 - mae: 0.3887 - val_loss: 0.0649 - val_mae: 0.1851\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3412 - mae: 0.3363 - val_loss: 0.0698 - val_mae: 0.1919\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3158 - mae: 0.3761 - val_loss: 0.1102 - val_mae: 0.2253\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4033 - mae: 0.3872 - val_loss: 0.1107 - val_mae: 0.2891\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3319 - mae: 0.3667 - val_loss: 0.1025 - val_mae: 0.2129\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2515 - mae: 0.3114 - val_loss: 0.0690 - val_mae: 0.2141\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2744 - mae: 0.3344 - val_loss: 0.1010 - val_mae: 0.2189\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3063 - mae: 0.3507 - val_loss: 0.1043 - val_mae: 0.2802\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2648 - mae: 0.3625 - val_loss: 0.0876 - val_mae: 0.2090\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3325 - mae: 0.3535 - val_loss: 0.0849 - val_mae: 0.2087\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4157 - mae: 0.3758 - val_loss: 0.1659 - val_mae: 0.2850\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5820 - mae: 0.4914 - val_loss: 0.2384 - val_mae: 0.3844\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4121 - mae: 0.4825 - val_loss: 0.0982 - val_mae: 0.2454\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4832 - mae: 0.4574 - val_loss: 0.1958 - val_mae: 0.3087\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2526 - mae: 0.3711 - val_loss: 0.1029 - val_mae: 0.2835\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2709 - mae: 0.3560 - val_loss: 0.1177 - val_mae: 0.2345\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3130 - mae: 0.3559 - val_loss: 0.1271 - val_mae: 0.3024\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3305 - mae: 0.3639 - val_loss: 0.4189 - val_mae: 0.4624\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4107 - mae: 0.4046 - val_loss: 0.0621 - val_mae: 0.1906\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3475 - mae: 0.3949 - val_loss: 0.0990 - val_mae: 0.2291\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2618 - mae: 0.3398 - val_loss: 0.1143 - val_mae: 0.2485\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2196 - mae: 0.3677 - val_loss: 0.1142 - val_mae: 0.3082\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3756 - mae: 0.3781 - val_loss: 0.2266 - val_mae: 0.3397\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2918 - mae: 0.3359 - val_loss: 0.0675 - val_mae: 0.1989\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2418 - mae: 0.3039 - val_loss: 0.0635 - val_mae: 0.2150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0399 - mae: 0.1746\n",
      "Test Loss: 0.0399\n",
      "Test MAE: 0.1746\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.9704\n",
      "MSE: 0.0399\n",
      "MAE: 0.1746\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6329 - mae: 0.5013 - val_loss: 0.8829 - val_mae: 0.6500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5969 - mae: 0.5132 - val_loss: 0.8984 - val_mae: 0.6047\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5876 - mae: 0.5090 - val_loss: 0.8744 - val_mae: 0.6147\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5745 - mae: 0.5006 - val_loss: 0.8587 - val_mae: 0.6302\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5636 - mae: 0.5108 - val_loss: 0.8545 - val_mae: 0.6330\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5851 - mae: 0.4772 - val_loss: 0.8711 - val_mae: 0.5877\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5249 - mae: 0.4677 - val_loss: 0.8411 - val_mae: 0.6401\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5278 - mae: 0.4984 - val_loss: 0.8361 - val_mae: 0.6254\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5529 - mae: 0.4650 - val_loss: 0.8739 - val_mae: 0.5535\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5294 - mae: 0.4177 - val_loss: 0.8630 - val_mae: 0.5619\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5511 - mae: 0.4917 - val_loss: 0.8276 - val_mae: 0.6457\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5264 - mae: 0.4944 - val_loss: 0.8456 - val_mae: 0.5823\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5055 - mae: 0.4239 - val_loss: 0.8619 - val_mae: 0.5512\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5361 - mae: 0.4230 - val_loss: 0.8391 - val_mae: 0.5838\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4715 - mae: 0.4552 - val_loss: 0.8327 - val_mae: 0.5987\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5014 - mae: 0.4417 - val_loss: 0.8306 - val_mae: 0.5938\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4290 - mae: 0.4250 - val_loss: 0.8284 - val_mae: 0.6062\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5006 - mae: 0.4499 - val_loss: 0.8361 - val_mae: 0.5452\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4848 - mae: 0.3887 - val_loss: 0.8461 - val_mae: 0.5267\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4806 - mae: 0.3799 - val_loss: 0.8416 - val_mae: 0.5537\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4973 - mae: 0.4392 - val_loss: 0.8375 - val_mae: 0.5863\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4999 - mae: 0.4469 - val_loss: 0.8426 - val_mae: 0.5404\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4792 - mae: 0.3910 - val_loss: 0.8455 - val_mae: 0.5274\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4421 - mae: 0.3771 - val_loss: 0.8381 - val_mae: 0.5400\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4890 - mae: 0.4147 - val_loss: 0.8377 - val_mae: 0.5507\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4768 - mae: 0.4141 - val_loss: 0.8400 - val_mae: 0.5477\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4470 - mae: 0.4108 - val_loss: 0.8463 - val_mae: 0.5721\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5120 - mae: 0.4231 - val_loss: 0.8456 - val_mae: 0.5565\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4556 - mae: 0.4185 - val_loss: 0.8441 - val_mae: 0.5493\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4504 - mae: 0.4229 - val_loss: 0.8436 - val_mae: 0.5464\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4452 - mae: 0.3818 - val_loss: 0.8443 - val_mae: 0.5702\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4635 - mae: 0.4401 - val_loss: 0.8483 - val_mae: 0.6072\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4419 - mae: 0.4510 - val_loss: 0.8573 - val_mae: 0.5622\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4577 - mae: 0.3927 - val_loss: 0.8653 - val_mae: 0.5250\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4937 - mae: 0.3928 - val_loss: 0.8660 - val_mae: 0.5335\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4441 - mae: 0.3780 - val_loss: 0.8663 - val_mae: 0.5363\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4782 - mae: 0.4000 - val_loss: 0.8700 - val_mae: 0.5107\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4468 - mae: 0.3693 - val_loss: 0.8647 - val_mae: 0.5421\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4289 - mae: 0.3868 - val_loss: 0.8647 - val_mae: 0.5360\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4448 - mae: 0.3899 - val_loss: 0.8689 - val_mae: 0.5381\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4437 - mae: 0.3677 - val_loss: 0.8766 - val_mae: 0.5339\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4091 - mae: 0.3679 - val_loss: 0.8679 - val_mae: 0.5342\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4632 - mae: 0.3661 - val_loss: 0.8620 - val_mae: 0.5262\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4635 - mae: 0.3726 - val_loss: 0.8629 - val_mae: 0.5319\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4732 - mae: 0.3866 - val_loss: 0.8638 - val_mae: 0.5406\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4239 - mae: 0.3661 - val_loss: 0.8633 - val_mae: 0.5628\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4416 - mae: 0.4149 - val_loss: 0.8700 - val_mae: 0.5810\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4539 - mae: 0.4237 - val_loss: 0.8678 - val_mae: 0.5658\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4527 - mae: 0.3942 - val_loss: 0.8690 - val_mae: 0.5589\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4555 - mae: 0.3821 - val_loss: 0.8681 - val_mae: 0.5509\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4494 - mae: 0.3830 - val_loss: 0.8663 - val_mae: 0.5468\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4824 - mae: 0.3970 - val_loss: 0.8647 - val_mae: 0.5547\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4780 - mae: 0.3859 - val_loss: 0.8732 - val_mae: 0.5453\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4752 - mae: 0.3872 - val_loss: 0.8789 - val_mae: 0.5866\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4579 - mae: 0.4249 - val_loss: 0.8899 - val_mae: 0.5991\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4731 - mae: 0.4060 - val_loss: 0.8909 - val_mae: 0.5388\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4936 - mae: 0.3459 - val_loss: 0.8981 - val_mae: 0.5270\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4291 - mae: 0.3580 - val_loss: 0.8888 - val_mae: 0.5863\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4680 - mae: 0.4202 - val_loss: 0.8936 - val_mae: 0.6093\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4626 - mae: 0.4284 - val_loss: 0.8762 - val_mae: 0.5669\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4446 - mae: 0.3710 - val_loss: 0.8788 - val_mae: 0.5551\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4402 - mae: 0.3730 - val_loss: 0.8749 - val_mae: 0.5815\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4248 - mae: 0.3988 - val_loss: 0.8852 - val_mae: 0.6136\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4238 - mae: 0.4172 - val_loss: 0.8903 - val_mae: 0.6033\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4137 - mae: 0.4090 - val_loss: 0.8894 - val_mae: 0.5780\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4483 - mae: 0.3919 - val_loss: 0.8961 - val_mae: 0.5520\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4233 - mae: 0.3535 - val_loss: 0.8857 - val_mae: 0.5565\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4667 - mae: 0.3811 - val_loss: 0.8776 - val_mae: 0.5779\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4308 - mae: 0.4002 - val_loss: 0.8986 - val_mae: 0.6108\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4451 - mae: 0.4233 - val_loss: 0.8814 - val_mae: 0.5862\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4194 - mae: 0.3946 - val_loss: 0.8812 - val_mae: 0.5628\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4615 - mae: 0.3973 - val_loss: 0.8828 - val_mae: 0.5480\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4438 - mae: 0.3615 - val_loss: 0.8843 - val_mae: 0.5432\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4757 - mae: 0.3804 - val_loss: 0.8791 - val_mae: 0.5448\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4377 - mae: 0.3788 - val_loss: 0.8788 - val_mae: 0.5728\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4851 - mae: 0.4231 - val_loss: 0.8847 - val_mae: 0.5842\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4215 - mae: 0.3957 - val_loss: 0.8768 - val_mae: 0.5642\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4108 - mae: 0.3670 - val_loss: 0.8916 - val_mae: 0.5502\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4645 - mae: 0.3748 - val_loss: 0.8991 - val_mae: 0.5500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4235 - mae: 0.3723 - val_loss: 0.8978 - val_mae: 0.5596\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4661 - mae: 0.3852 - val_loss: 0.8956 - val_mae: 0.5648\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4668 - mae: 0.3971 - val_loss: 0.8900 - val_mae: 0.5871\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4451 - mae: 0.4045 - val_loss: 0.8824 - val_mae: 0.5696\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4243 - mae: 0.3879 - val_loss: 0.8878 - val_mae: 0.5666\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4424 - mae: 0.4014 - val_loss: 0.8903 - val_mae: 0.5700\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4444 - mae: 0.3738 - val_loss: 0.8929 - val_mae: 0.5535\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4451 - mae: 0.3612 - val_loss: 0.8955 - val_mae: 0.5449\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4682 - mae: 0.3802 - val_loss: 0.8852 - val_mae: 0.5521\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4205 - mae: 0.3621 - val_loss: 0.8762 - val_mae: 0.5662\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4405 - mae: 0.3831 - val_loss: 0.8978 - val_mae: 0.6043\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4131 - mae: 0.3959 - val_loss: 0.8814 - val_mae: 0.5625\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4215 - mae: 0.3601 - val_loss: 0.8942 - val_mae: 0.5522\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4363 - mae: 0.3647 - val_loss: 0.8907 - val_mae: 0.5686\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4488 - mae: 0.3944 - val_loss: 0.8815 - val_mae: 0.5836\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4424 - mae: 0.3865 - val_loss: 0.8811 - val_mae: 0.5776\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4170 - mae: 0.3847 - val_loss: 0.8832 - val_mae: 0.6007\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4678 - mae: 0.4036 - val_loss: 0.8813 - val_mae: 0.5907\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4497 - mae: 0.3994 - val_loss: 0.8822 - val_mae: 0.5621\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4079 - mae: 0.3597 - val_loss: 0.8938 - val_mae: 0.5524\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4274 - mae: 0.3770 - val_loss: 0.8802 - val_mae: 0.5810\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5446 - mae: 0.4151\n",
      "Test Loss: 0.5446\n",
      "Test MAE: 0.4151\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.3259\n",
      "MSE: 0.5446\n",
      "MAE: 0.4151\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # y is the last column in the dataset\n",
    "    y = dataset.iloc[:, -1]\n",
    "    X = dataset.iloc[:, :-1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # split training data into training and validation data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = NN_model(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    y_predicted[dataset.columns[-1]] = model.predict(X_test).flatten()\n",
    "    y_truth[dataset.columns[-1]] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.044641</td>\n",
       "      <td>5.814450</td>\n",
       "      <td>0.337607</td>\n",
       "      <td>0.181046</td>\n",
       "      <td>0.139045</td>\n",
       "      <td>0.216647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300912</td>\n",
       "      <td>5.204381</td>\n",
       "      <td>0.208007</td>\n",
       "      <td>0.117998</td>\n",
       "      <td>0.127974</td>\n",
       "      <td>0.154979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.568072</td>\n",
       "      <td>5.015829</td>\n",
       "      <td>0.127050</td>\n",
       "      <td>0.089438</td>\n",
       "      <td>0.165664</td>\n",
       "      <td>0.138042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.185236</td>\n",
       "      <td>15.855120</td>\n",
       "      <td>0.501427</td>\n",
       "      <td>0.325027</td>\n",
       "      <td>3.737548</td>\n",
       "      <td>0.416546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.817746</td>\n",
       "      <td>3.584099</td>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.037689</td>\n",
       "      <td>0.362659</td>\n",
       "      <td>0.129893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      12.044641       5.814450       0.337607       0.181046       0.139045   \n",
       "1       8.300912       5.204381       0.208007       0.117998       0.127974   \n",
       "2       4.568072       5.015829       0.127050       0.089438       0.165664   \n",
       "3      19.185236      15.855120       0.501427       0.325027       3.737548   \n",
       "4       3.817746       3.584099       0.064924       0.037689       0.362659   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0       0.216647  \n",
       "1       0.154979  \n",
       "2       0.138042  \n",
       "3       0.416546  \n",
       "4       0.129893  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.739658</td>\n",
       "      <td>40.735563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.91524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.660000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      30.000000      25.000000            0.5            2.0        0.00000   \n",
       "1      50.000000       0.000000            0.0            0.0        0.00000   \n",
       "2       0.000000       0.000000            0.0            1.5        0.00000   \n",
       "3      34.739658      40.735563            0.0            0.0        3.91524   \n",
       "4       8.660000       2.180000            0.0            0.0        0.72000   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0            1.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2843934946185081"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for all target variables\n",
    "r2 = r2_score(y_truth, y_predicted)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <td>0.052366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <td>0.161480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <td>0.079092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <td>0.117112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <td>0.970402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formate (g/L)</th>\n",
       "      <td>0.325907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R^2 Score\n",
       "Glucose (g/L)   0.052366\n",
       "Lactate (g/L)   0.161480\n",
       "Ethanol (g/L)   0.079092\n",
       "Acetate (g/L)   0.117112\n",
       "Biomass (g/L)   0.970402\n",
       "Formate (g/L)   0.325907"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for each target variable\n",
    "r2 = r2_score(y_truth, y_predicted, multioutput='raw_values')\n",
    "\n",
    "# convert to a dataframe\n",
    "r2 = pd.DataFrame(r2, index=target.columns, columns=['R^2 Score'])\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined r2 score is: **0.42913293043177275** [1]\n",
    "\n",
    "The combined r2 score is: **0.35816286323129254** [2]\n",
    "\n",
    "### The combined r2 score is: **0.2843934946185081** [curr] THE WORST\n",
    "\n",
    "The combined r2 score is: **0.33809704738378416** [4]\n",
    "\n",
    "Which is a below average score. :(\n",
    "\n",
    "BUT\n",
    "\n",
    "Individually for each target variable, the r2 score has high variability. With Biomass being predicted most accurately with a score of ***0.970402***, and acetate being predicted most poorly with a score of 0.052366."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. With the selected features dataset (after dimensionality reduction by PCA) for each target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = pd.DataFrame(columns=target.columns)\n",
    "y_truth = pd.DataFrame(columns=target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose = pd.read_csv('modified_data/data_glucose2.csv')\n",
    "lactate = pd.read_csv('modified_data/data_lactate.csv')\n",
    "ethanol = pd.read_csv('modified_data/data_ethanol.csv')\n",
    "acetate = pd.read_csv('modified_data/data_acetate.csv')\n",
    "biomass = pd.read_csv('modified_data/data_biomass.csv')\n",
    "formate = pd.read_csv('modified_data/data_formate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [glucose, lactate, ethanol, acetate, biomass, formate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 409.5983 - mae: 13.1372 - val_loss: 446.0562 - val_mae: 14.7243\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 407.7460 - mae: 13.1158 - val_loss: 443.8323 - val_mae: 14.7134\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 405.9049 - mae: 13.0955 - val_loss: 441.0459 - val_mae: 14.7002\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 403.3758 - mae: 13.0840 - val_loss: 437.7345 - val_mae: 14.6847\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 400.2840 - mae: 13.0742 - val_loss: 433.5514 - val_mae: 14.6682\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 396.8241 - mae: 13.0302 - val_loss: 428.2809 - val_mae: 14.6517\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 392.4183 - mae: 12.9936 - val_loss: 421.6544 - val_mae: 14.6307\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 385.5867 - mae: 12.9725 - val_loss: 413.2322 - val_mae: 14.6026\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 379.4183 - mae: 12.9548 - val_loss: 402.6709 - val_mae: 14.5645\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 369.1093 - mae: 12.8581 - val_loss: 389.4541 - val_mae: 14.5170\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 356.0261 - mae: 12.7316 - val_loss: 373.1368 - val_mae: 14.4518\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 341.1780 - mae: 12.6911 - val_loss: 353.1768 - val_mae: 14.3641\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 319.7270 - mae: 12.5207 - val_loss: 329.4894 - val_mae: 14.2449\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 303.8282 - mae: 12.4440 - val_loss: 303.4540 - val_mae: 14.0844\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 289.6076 - mae: 12.2921 - val_loss: 274.8401 - val_mae: 13.8765\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 259.6124 - mae: 12.3129 - val_loss: 245.6824 - val_mae: 13.6081\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 248.6585 - mae: 12.2646 - val_loss: 218.9357 - val_mae: 13.3041\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.8007 - mae: 12.0837 - val_loss: 196.6044 - val_mae: 12.9700\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.9433 - mae: 12.4871 - val_loss: 180.0091 - val_mae: 12.6118\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 192.4223 - mae: 11.7405 - val_loss: 169.1585 - val_mae: 12.2888\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 184.7713 - mae: 11.7727 - val_loss: 160.8242 - val_mae: 11.9532\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 182.0905 - mae: 11.5668 - val_loss: 154.2451 - val_mae: 11.5931\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.3167 - mae: 11.4342 - val_loss: 148.5670 - val_mae: 11.2438\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 180.9819 - mae: 11.5718 - val_loss: 143.5402 - val_mae: 10.8994\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 171.1286 - mae: 11.3508 - val_loss: 139.0412 - val_mae: 10.5603\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 159.2353 - mae: 10.7820 - val_loss: 135.2155 - val_mae: 10.2293\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.2425 - mae: 10.8177 - val_loss: 132.2144 - val_mae: 9.9398\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 180.8580 - mae: 11.4146 - val_loss: 129.8838 - val_mae: 9.6784\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 146.0438 - mae: 10.1823 - val_loss: 128.0823 - val_mae: 9.4550\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.7851 - mae: 10.2760 - val_loss: 126.5605 - val_mae: 9.2576\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 169.9457 - mae: 10.7938 - val_loss: 125.3501 - val_mae: 9.0779\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 153.9896 - mae: 10.3114 - val_loss: 124.3608 - val_mae: 8.9112\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.2712 - mae: 10.5094 - val_loss: 123.4495 - val_mae: 8.7199\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.3006 - mae: 10.5605 - val_loss: 122.8919 - val_mae: 8.6225\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 166.1661 - mae: 10.5762 - val_loss: 122.5664 - val_mae: 8.5498\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.4192 - mae: 10.2634 - val_loss: 122.3870 - val_mae: 8.4858\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 152.9532 - mae: 10.0052 - val_loss: 122.2127 - val_mae: 8.4436\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.3814 - mae: 10.2161 - val_loss: 122.1006 - val_mae: 8.3924\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 173.7615 - mae: 10.5235 - val_loss: 122.0203 - val_mae: 8.3486\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 174.3663 - mae: 10.4649 - val_loss: 121.9591 - val_mae: 8.3289\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.8491 - mae: 10.1557 - val_loss: 121.9067 - val_mae: 8.3072\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 169.3167 - mae: 10.3126 - val_loss: 121.9413 - val_mae: 8.2928\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 166.6135 - mae: 10.1658 - val_loss: 121.9061 - val_mae: 8.2604\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.2072 - mae: 10.1059 - val_loss: 121.8399 - val_mae: 8.2400\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.7983 - mae: 10.3465 - val_loss: 121.8544 - val_mae: 8.2120\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.5876 - mae: 10.2169 - val_loss: 121.8559 - val_mae: 8.1916\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 173.6190 - mae: 10.4780 - val_loss: 121.8218 - val_mae: 8.1884\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.0697 - mae: 10.3023 - val_loss: 121.7913 - val_mae: 8.1914\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 156.1977 - mae: 10.1503 - val_loss: 121.7845 - val_mae: 8.1819\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 150.6351 - mae: 9.9258 - val_loss: 121.8028 - val_mae: 8.1747\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 152.9463 - mae: 9.8445 - val_loss: 121.8340 - val_mae: 8.1475\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 162.2169 - mae: 10.1812 - val_loss: 121.8475 - val_mae: 8.1283\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 160.8130 - mae: 10.1596 - val_loss: 121.8652 - val_mae: 8.1277\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.3024 - mae: 10.1009 - val_loss: 121.9975 - val_mae: 8.1162\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 141.6929 - mae: 9.2659 - val_loss: 121.9977 - val_mae: 8.1206\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 160.4317 - mae: 9.9829 - val_loss: 121.9145 - val_mae: 8.1085\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 145.7786 - mae: 9.6427 - val_loss: 121.9158 - val_mae: 8.1237\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 168.7455 - mae: 10.1616 - val_loss: 122.2010 - val_mae: 8.1506\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.0981 - mae: 10.4208 - val_loss: 122.3552 - val_mae: 8.1452\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.2656 - mae: 10.1730 - val_loss: 122.1688 - val_mae: 8.1222\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.6747 - mae: 10.0344 - val_loss: 121.9595 - val_mae: 8.0995\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 148.6311 - mae: 9.8695 - val_loss: 121.9224 - val_mae: 8.1119\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 148.3393 - mae: 9.6963 - val_loss: 121.9018 - val_mae: 8.1234\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 168.2228 - mae: 10.3171 - val_loss: 121.9209 - val_mae: 8.1365\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.3190 - mae: 9.8843 - val_loss: 121.9313 - val_mae: 8.1501\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 153.4450 - mae: 9.9040 - val_loss: 121.8871 - val_mae: 8.1570\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 148.1012 - mae: 9.6253 - val_loss: 121.8170 - val_mae: 8.1501\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 140.1442 - mae: 9.3767 - val_loss: 121.8821 - val_mae: 8.1340\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 136.6598 - mae: 9.5074 - val_loss: 122.0383 - val_mae: 8.1345\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 156.2269 - mae: 10.1811 - val_loss: 122.1421 - val_mae: 8.1338\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.6627 - mae: 9.9984 - val_loss: 122.1869 - val_mae: 8.1456\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 162.1510 - mae: 10.3704 - val_loss: 121.9309 - val_mae: 8.1573\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 150.3045 - mae: 9.8449 - val_loss: 121.9586 - val_mae: 8.1598\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 164.0107 - mae: 10.2865 - val_loss: 121.9067 - val_mae: 8.1450\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 144.9611 - mae: 9.7718 - val_loss: 121.8972 - val_mae: 8.1441\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.7644 - mae: 10.0579 - val_loss: 121.9775 - val_mae: 8.1380\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.9016 - mae: 10.0562 - val_loss: 121.9565 - val_mae: 8.1121\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 144.8712 - mae: 9.7393 - val_loss: 121.9834 - val_mae: 8.1076\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 155.5768 - mae: 9.8477 - val_loss: 122.0541 - val_mae: 8.0972\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 152.2113 - mae: 9.6870 - val_loss: 122.1970 - val_mae: 8.0851\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 144.3816 - mae: 9.8394 - val_loss: 122.2417 - val_mae: 8.0771\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 144.9329 - mae: 9.6296 - val_loss: 122.2405 - val_mae: 8.0741\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.4273 - mae: 10.1800 - val_loss: 122.2349 - val_mae: 8.0701\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 160.4156 - mae: 9.9456 - val_loss: 122.1183 - val_mae: 8.0726\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.3594 - mae: 10.3545 - val_loss: 122.0746 - val_mae: 8.0695\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.4860 - mae: 10.0667 - val_loss: 122.0649 - val_mae: 8.0634\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 140.8137 - mae: 9.5965 - val_loss: 122.1070 - val_mae: 8.0719\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.2219 - mae: 9.9660 - val_loss: 122.0083 - val_mae: 8.0852\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 167.8184 - mae: 10.0343 - val_loss: 121.9419 - val_mae: 8.1064\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.7996 - mae: 9.8908 - val_loss: 121.9734 - val_mae: 8.1083\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.0500 - mae: 9.9571 - val_loss: 121.8526 - val_mae: 8.1223\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 152.0267 - mae: 9.6381 - val_loss: 121.8090 - val_mae: 8.1265\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.4359 - mae: 10.0619 - val_loss: 121.8148 - val_mae: 8.1309\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.9894 - mae: 10.0076 - val_loss: 122.0498 - val_mae: 8.1269\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 153.3477 - mae: 9.6900 - val_loss: 122.4804 - val_mae: 8.1310\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 166.1097 - mae: 10.2626 - val_loss: 122.6524 - val_mae: 8.1214\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 137.9175 - mae: 9.4433 - val_loss: 123.0272 - val_mae: 8.1791\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 140.6741 - mae: 9.6480 - val_loss: 122.7718 - val_mae: 8.1014\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.2019 - mae: 10.0441 - val_loss: 122.3332 - val_mae: 8.0382\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 153.0280 - mae: 9.9786 - val_loss: 122.1864 - val_mae: 8.0235\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 310.8366 - mae: 13.9479\n",
      "Test Loss: 310.8366\n",
      "Test MAE: 13.9479\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.0698\n",
      "MSE: 310.8366\n",
      "MAE: 13.9479\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 344.5920 - mae: 8.9025 - val_loss: 417.5975 - val_mae: 11.2024\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 341.4549 - mae: 8.8175 - val_loss: 415.6716 - val_mae: 11.1790\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 340.2535 - mae: 8.7795 - val_loss: 413.7159 - val_mae: 11.1565\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 338.7444 - mae: 8.7679 - val_loss: 411.6044 - val_mae: 11.1322\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 337.0049 - mae: 8.7519 - val_loss: 409.4685 - val_mae: 11.1086\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 335.4774 - mae: 8.7332 - val_loss: 406.8116 - val_mae: 11.0858\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 332.9297 - mae: 8.6997 - val_loss: 403.6654 - val_mae: 11.0617\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 329.6910 - mae: 8.6708 - val_loss: 399.7578 - val_mae: 11.0292\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 327.0579 - mae: 8.6629 - val_loss: 395.1219 - val_mae: 10.9908\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 321.9950 - mae: 8.6445 - val_loss: 389.4500 - val_mae: 10.9411\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 321.0274 - mae: 8.6719 - val_loss: 382.6881 - val_mae: 10.9147\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 312.3452 - mae: 8.6810 - val_loss: 374.5158 - val_mae: 10.8836\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 310.4802 - mae: 8.7779 - val_loss: 364.4032 - val_mae: 10.8377\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 299.7966 - mae: 8.7067 - val_loss: 353.0764 - val_mae: 10.8316\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 296.3612 - mae: 8.7027 - val_loss: 340.8082 - val_mae: 10.8882\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 292.7766 - mae: 8.9637 - val_loss: 328.7881 - val_mae: 10.9620\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 271.9010 - mae: 8.9737 - val_loss: 316.1766 - val_mae: 11.0464\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 263.4088 - mae: 8.9925 - val_loss: 304.8624 - val_mae: 11.1228\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 254.4276 - mae: 9.0492 - val_loss: 294.6023 - val_mae: 11.2638\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 251.2591 - mae: 9.2757 - val_loss: 286.7068 - val_mae: 11.4156\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 249.1107 - mae: 9.7552 - val_loss: 282.0079 - val_mae: 11.5785\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 251.3536 - mae: 9.8866 - val_loss: 281.6621 - val_mae: 11.6497\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 246.0780 - mae: 9.9757 - val_loss: 283.3333 - val_mae: 11.6482\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 252.5438 - mae: 9.9256 - val_loss: 284.1391 - val_mae: 11.6101\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.3660 - mae: 10.0291 - val_loss: 284.4204 - val_mae: 11.5840\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 256.7056 - mae: 10.1282 - val_loss: 284.3831 - val_mae: 11.5628\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 263.1277 - mae: 10.3262 - val_loss: 284.7022 - val_mae: 11.5032\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 252.7346 - mae: 9.9878 - val_loss: 284.4343 - val_mae: 11.4825\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 249.4384 - mae: 9.8703 - val_loss: 284.6109 - val_mae: 11.4561\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 232.9174 - mae: 9.4545 - val_loss: 284.8082 - val_mae: 11.4406\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 234.1943 - mae: 9.3253 - val_loss: 284.7260 - val_mae: 11.4371\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 241.5376 - mae: 9.2316 - val_loss: 284.6321 - val_mae: 11.4352\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.7656 - mae: 9.5220 - val_loss: 284.2211 - val_mae: 11.4495\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.7023 - mae: 9.2450 - val_loss: 283.8779 - val_mae: 11.4682\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.0591 - mae: 9.8607 - val_loss: 283.6678 - val_mae: 11.4939\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 238.8012 - mae: 9.4119 - val_loss: 284.2216 - val_mae: 11.4807\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.6520 - mae: 9.1368 - val_loss: 284.1965 - val_mae: 11.4761\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.0058 - mae: 9.1721 - val_loss: 284.2552 - val_mae: 11.4786\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.8922 - mae: 9.6105 - val_loss: 284.0034 - val_mae: 11.4929\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.9011 - mae: 9.6385 - val_loss: 283.6011 - val_mae: 11.5114\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 232.9507 - mae: 9.3099 - val_loss: 282.9803 - val_mae: 11.5484\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.0509 - mae: 9.6716 - val_loss: 282.3571 - val_mae: 11.6058\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 255.4965 - mae: 10.0043 - val_loss: 281.9019 - val_mae: 11.6252\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 246.5794 - mae: 9.8399 - val_loss: 281.4045 - val_mae: 11.6299\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 241.9553 - mae: 9.4529 - val_loss: 281.2519 - val_mae: 11.5875\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.1425 - mae: 9.7117 - val_loss: 281.4876 - val_mae: 11.5497\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.4309 - mae: 9.6390 - val_loss: 281.8739 - val_mae: 11.5037\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.6666 - mae: 9.4641 - val_loss: 281.2337 - val_mae: 11.5276\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 244.4479 - mae: 9.5532 - val_loss: 281.2685 - val_mae: 11.5192\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.4624 - mae: 9.3018 - val_loss: 281.4116 - val_mae: 11.5047\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 229.3754 - mae: 9.1849 - val_loss: 281.2245 - val_mae: 11.5113\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 244.7791 - mae: 9.5891 - val_loss: 281.3542 - val_mae: 11.5047\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.6462 - mae: 9.3656 - val_loss: 281.4608 - val_mae: 11.4945\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 226.4628 - mae: 9.1638 - val_loss: 280.8446 - val_mae: 11.5231\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.0387 - mae: 9.4915 - val_loss: 280.4587 - val_mae: 11.5538\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 262.4765 - mae: 9.9114 - val_loss: 280.5672 - val_mae: 11.5331\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 247.4820 - mae: 9.6234 - val_loss: 280.7123 - val_mae: 11.5162\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.6672 - mae: 9.4255 - val_loss: 280.5456 - val_mae: 11.5120\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 244.7968 - mae: 9.3884 - val_loss: 279.7038 - val_mae: 11.5468\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.9325 - mae: 9.5891 - val_loss: 279.3217 - val_mae: 11.5557\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.1957 - mae: 9.4263 - val_loss: 278.4860 - val_mae: 11.5998\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.8568 - mae: 9.6350 - val_loss: 278.1797 - val_mae: 11.6314\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.3899 - mae: 9.4946 - val_loss: 278.6311 - val_mae: 11.6394\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.0995 - mae: 9.8963 - val_loss: 279.0923 - val_mae: 11.6357\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.3073 - mae: 9.6943 - val_loss: 278.9291 - val_mae: 11.6092\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.1199 - mae: 9.4643 - val_loss: 278.4318 - val_mae: 11.6009\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 246.8113 - mae: 10.1171 - val_loss: 277.7227 - val_mae: 11.6162\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 248.4263 - mae: 9.7628 - val_loss: 277.5848 - val_mae: 11.5772\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 241.6474 - mae: 9.7140 - val_loss: 278.0321 - val_mae: 11.5313\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.1358 - mae: 9.4910 - val_loss: 277.9589 - val_mae: 11.5292\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 235.8982 - mae: 9.3996 - val_loss: 277.6277 - val_mae: 11.5385\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 228.8829 - mae: 9.4248 - val_loss: 277.2242 - val_mae: 11.5419\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 220.8232 - mae: 9.2702 - val_loss: 277.4588 - val_mae: 11.5145\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 231.8843 - mae: 9.4201 - val_loss: 277.3119 - val_mae: 11.5022\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.6871 - mae: 9.6979 - val_loss: 276.8776 - val_mae: 11.5072\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 229.2357 - mae: 9.1653 - val_loss: 276.7050 - val_mae: 11.5042\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.5502 - mae: 9.3728 - val_loss: 276.1514 - val_mae: 11.5545\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 242.0058 - mae: 9.6227 - val_loss: 276.0681 - val_mae: 11.5870\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.9849 - mae: 9.4035 - val_loss: 275.4131 - val_mae: 11.6261\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.3804 - mae: 9.6067 - val_loss: 274.9030 - val_mae: 11.6530\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 247.9991 - mae: 10.1247 - val_loss: 274.7548 - val_mae: 11.6369\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.0332 - mae: 9.4849 - val_loss: 275.0657 - val_mae: 11.5894\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 230.9247 - mae: 9.7335 - val_loss: 274.4515 - val_mae: 11.6044\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 235.9082 - mae: 9.6396 - val_loss: 273.7868 - val_mae: 11.6204\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.1830 - mae: 9.5537 - val_loss: 273.6744 - val_mae: 11.6085\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.1692 - mae: 9.5367 - val_loss: 274.2390 - val_mae: 11.5439\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 224.2946 - mae: 9.3457 - val_loss: 274.7929 - val_mae: 11.4962\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 229.5046 - mae: 9.0846 - val_loss: 274.9776 - val_mae: 11.4757\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 220.8073 - mae: 9.0001 - val_loss: 275.1408 - val_mae: 11.4679\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.3699 - mae: 9.4431 - val_loss: 274.9146 - val_mae: 11.4800\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.0110 - mae: 9.0257 - val_loss: 274.9146 - val_mae: 11.4716\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.3883 - mae: 9.3336 - val_loss: 275.0914 - val_mae: 11.4429\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 232.7111 - mae: 9.3764 - val_loss: 274.2471 - val_mae: 11.4860\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.4395 - mae: 9.6040 - val_loss: 273.7909 - val_mae: 11.4914\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 228.1802 - mae: 9.3933 - val_loss: 273.2224 - val_mae: 11.5119\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 223.3160 - mae: 9.1369 - val_loss: 272.6052 - val_mae: 11.5172\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.9173 - mae: 9.7851 - val_loss: 271.9626 - val_mae: 11.5358\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 228.9567 - mae: 9.4642 - val_loss: 271.7403 - val_mae: 11.5629\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 236.2692 - mae: 9.5244 - val_loss: 271.5616 - val_mae: 11.5718\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 224.4717 - mae: 9.4351 - val_loss: 271.1759 - val_mae: 11.5608\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 107.4193 - mae: 7.3897\n",
      "Test Loss: 107.4193\n",
      "Test MAE: 7.3897\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.1824\n",
      "MSE: 107.4193\n",
      "MAE: 7.3897\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7561 - mae: 0.4239 - val_loss: 0.9513 - val_mae: 0.4486\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7001 - mae: 0.4143 - val_loss: 0.8946 - val_mae: 0.4669\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6350 - mae: 0.4065 - val_loss: 0.8454 - val_mae: 0.4899\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5646 - mae: 0.4114 - val_loss: 0.8089 - val_mae: 0.5112\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5254 - mae: 0.4103 - val_loss: 0.7874 - val_mae: 0.5381\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4836 - mae: 0.4075 - val_loss: 0.7835 - val_mae: 0.5687\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4598 - mae: 0.4257 - val_loss: 0.7989 - val_mae: 0.5970\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4774 - mae: 0.4478 - val_loss: 0.8212 - val_mae: 0.6110\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4853 - mae: 0.4601 - val_loss: 0.8361 - val_mae: 0.6077\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4607 - mae: 0.4347 - val_loss: 0.8445 - val_mae: 0.5963\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4327 - mae: 0.4143 - val_loss: 0.8433 - val_mae: 0.5849\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4392 - mae: 0.4308 - val_loss: 0.8366 - val_mae: 0.5722\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4579 - mae: 0.4098 - val_loss: 0.8246 - val_mae: 0.5604\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4576 - mae: 0.3989 - val_loss: 0.8089 - val_mae: 0.5468\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4504 - mae: 0.3841 - val_loss: 0.8051 - val_mae: 0.5439\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4735 - mae: 0.4012 - val_loss: 0.8060 - val_mae: 0.5440\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4509 - mae: 0.3960 - val_loss: 0.8085 - val_mae: 0.5452\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5144 - mae: 0.4109 - val_loss: 0.8103 - val_mae: 0.5446\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4546 - mae: 0.3825 - val_loss: 0.8079 - val_mae: 0.5424\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4300 - mae: 0.3780 - val_loss: 0.8054 - val_mae: 0.5396\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4510 - mae: 0.3864 - val_loss: 0.8067 - val_mae: 0.5412\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4482 - mae: 0.3851 - val_loss: 0.8126 - val_mae: 0.5456\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4578 - mae: 0.3958 - val_loss: 0.8170 - val_mae: 0.5511\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4727 - mae: 0.3843 - val_loss: 0.8213 - val_mae: 0.5555\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4772 - mae: 0.4076 - val_loss: 0.8161 - val_mae: 0.5536\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4152 - mae: 0.3759 - val_loss: 0.8188 - val_mae: 0.5555\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4344 - mae: 0.3850 - val_loss: 0.8171 - val_mae: 0.5535\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4451 - mae: 0.3823 - val_loss: 0.8135 - val_mae: 0.5493\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4364 - mae: 0.3926 - val_loss: 0.8126 - val_mae: 0.5466\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4528 - mae: 0.3837 - val_loss: 0.8066 - val_mae: 0.5388\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4054 - mae: 0.3744 - val_loss: 0.8033 - val_mae: 0.5327\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4552 - mae: 0.3760 - val_loss: 0.8027 - val_mae: 0.5315\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3992 - mae: 0.3594 - val_loss: 0.8039 - val_mae: 0.5348\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4381 - mae: 0.3802 - val_loss: 0.8028 - val_mae: 0.5355\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4725 - mae: 0.3872 - val_loss: 0.8026 - val_mae: 0.5374\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4723 - mae: 0.3855 - val_loss: 0.8025 - val_mae: 0.5374\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4388 - mae: 0.3876 - val_loss: 0.8032 - val_mae: 0.5366\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4347 - mae: 0.3811 - val_loss: 0.8017 - val_mae: 0.5335\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4026 - mae: 0.3738 - val_loss: 0.8048 - val_mae: 0.5358\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4135 - mae: 0.3627 - val_loss: 0.8074 - val_mae: 0.5395\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3753 - mae: 0.3631 - val_loss: 0.8153 - val_mae: 0.5467\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3994 - mae: 0.3717 - val_loss: 0.8312 - val_mae: 0.5554\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4444 - mae: 0.3945 - val_loss: 0.8213 - val_mae: 0.5466\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4359 - mae: 0.3940 - val_loss: 0.8064 - val_mae: 0.5352\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4171 - mae: 0.3771 - val_loss: 0.8051 - val_mae: 0.5330\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4434 - mae: 0.3835 - val_loss: 0.8077 - val_mae: 0.5336\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3963 - mae: 0.3583 - val_loss: 0.8092 - val_mae: 0.5345\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4090 - mae: 0.3732 - val_loss: 0.8198 - val_mae: 0.5406\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3644 - mae: 0.3590 - val_loss: 0.8260 - val_mae: 0.5446\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4215 - mae: 0.3802 - val_loss: 0.8246 - val_mae: 0.5416\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4354 - mae: 0.3792 - val_loss: 0.8276 - val_mae: 0.5447\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4358 - mae: 0.3827 - val_loss: 0.8202 - val_mae: 0.5376\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3962 - mae: 0.3637 - val_loss: 0.8143 - val_mae: 0.5328\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4465 - mae: 0.3824 - val_loss: 0.8095 - val_mae: 0.5295\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4036 - mae: 0.3673 - val_loss: 0.8121 - val_mae: 0.5330\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4057 - mae: 0.3651 - val_loss: 0.8157 - val_mae: 0.5346\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4006 - mae: 0.3595 - val_loss: 0.8187 - val_mae: 0.5356\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3467 - mae: 0.3455 - val_loss: 0.8315 - val_mae: 0.5424\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4138 - mae: 0.3745 - val_loss: 0.8397 - val_mae: 0.5463\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3999 - mae: 0.3681 - val_loss: 0.8484 - val_mae: 0.5511\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3889 - mae: 0.3711 - val_loss: 0.8344 - val_mae: 0.5419\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4131 - mae: 0.3637 - val_loss: 0.8221 - val_mae: 0.5346\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4404 - mae: 0.3848 - val_loss: 0.8095 - val_mae: 0.5263\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4459 - mae: 0.3904 - val_loss: 0.7956 - val_mae: 0.5166\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4340 - mae: 0.3665 - val_loss: 0.7908 - val_mae: 0.5159\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4149 - mae: 0.3682 - val_loss: 0.7892 - val_mae: 0.5170\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4300 - mae: 0.3736 - val_loss: 0.7921 - val_mae: 0.5209\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3751 - mae: 0.3599 - val_loss: 0.7925 - val_mae: 0.5206\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3651 - mae: 0.3436 - val_loss: 0.8052 - val_mae: 0.5317\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4535 - mae: 0.3863 - val_loss: 0.8130 - val_mae: 0.5384\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4458 - mae: 0.3856 - val_loss: 0.8076 - val_mae: 0.5305\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4251 - mae: 0.3707 - val_loss: 0.7930 - val_mae: 0.5144\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4090 - mae: 0.3620 - val_loss: 0.7903 - val_mae: 0.5102\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4000 - mae: 0.3603 - val_loss: 0.7933 - val_mae: 0.5137\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3875 - mae: 0.3522 - val_loss: 0.7950 - val_mae: 0.5190\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3984 - mae: 0.3439 - val_loss: 0.8019 - val_mae: 0.5263\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3983 - mae: 0.3674 - val_loss: 0.8185 - val_mae: 0.5420\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3694 - mae: 0.3588 - val_loss: 0.8247 - val_mae: 0.5451\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4095 - mae: 0.3715 - val_loss: 0.8275 - val_mae: 0.5443\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3751 - mae: 0.3638 - val_loss: 0.8172 - val_mae: 0.5340\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4019 - mae: 0.3569 - val_loss: 0.8054 - val_mae: 0.5221\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3654 - mae: 0.3505 - val_loss: 0.8001 - val_mae: 0.5169\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3882 - mae: 0.3530 - val_loss: 0.7969 - val_mae: 0.5137\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3845 - mae: 0.3443 - val_loss: 0.7998 - val_mae: 0.5140\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4027 - mae: 0.3644 - val_loss: 0.8062 - val_mae: 0.5188\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3700 - mae: 0.3504 - val_loss: 0.8095 - val_mae: 0.5210\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3667 - mae: 0.3490 - val_loss: 0.8154 - val_mae: 0.5242\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3743 - mae: 0.3441 - val_loss: 0.8218 - val_mae: 0.5274\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3763 - mae: 0.3551 - val_loss: 0.8217 - val_mae: 0.5250\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3860 - mae: 0.3571 - val_loss: 0.8294 - val_mae: 0.5295\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4220 - mae: 0.3678 - val_loss: 0.8230 - val_mae: 0.5242\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3718 - mae: 0.3418 - val_loss: 0.8170 - val_mae: 0.5169\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3937 - mae: 0.3512 - val_loss: 0.8102 - val_mae: 0.5094\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3684 - mae: 0.3440 - val_loss: 0.8107 - val_mae: 0.5106\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3726 - mae: 0.3365 - val_loss: 0.8165 - val_mae: 0.5163\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3964 - mae: 0.3538 - val_loss: 0.8261 - val_mae: 0.5209\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3438 - mae: 0.3373 - val_loss: 0.8324 - val_mae: 0.5229\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3608 - mae: 0.3445 - val_loss: 0.8384 - val_mae: 0.5254\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4120 - mae: 0.3667 - val_loss: 0.8248 - val_mae: 0.5148\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4010 - mae: 0.3450 - val_loss: 0.8136 - val_mae: 0.5066\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5286 - mae: 0.3735\n",
      "Test Loss: 0.5286\n",
      "Test MAE: 0.3735\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.1570\n",
      "MSE: 0.5286\n",
      "MAE: 0.3735\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4372 - mae: 0.3328 - val_loss: 0.4890 - val_mae: 0.3914\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4011 - mae: 0.3301 - val_loss: 0.4367 - val_mae: 0.3901\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3790 - mae: 0.3386 - val_loss: 0.3916 - val_mae: 0.3914\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3180 - mae: 0.3229 - val_loss: 0.3521 - val_mae: 0.3923\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3050 - mae: 0.3321 - val_loss: 0.3179 - val_mae: 0.3950\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3081 - mae: 0.3544 - val_loss: 0.2938 - val_mae: 0.3973\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2957 - mae: 0.3485 - val_loss: 0.2791 - val_mae: 0.3975\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2935 - mae: 0.3549 - val_loss: 0.2701 - val_mae: 0.3917\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2558 - mae: 0.3387 - val_loss: 0.2657 - val_mae: 0.3834\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2746 - mae: 0.3393 - val_loss: 0.2635 - val_mae: 0.3720\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2661 - mae: 0.3195 - val_loss: 0.2621 - val_mae: 0.3656\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2812 - mae: 0.3327 - val_loss: 0.2608 - val_mae: 0.3608\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2793 - mae: 0.3248 - val_loss: 0.2600 - val_mae: 0.3584\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2857 - mae: 0.3266 - val_loss: 0.2593 - val_mae: 0.3558\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2629 - mae: 0.3148 - val_loss: 0.2590 - val_mae: 0.3548\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2439 - mae: 0.3055 - val_loss: 0.2575 - val_mae: 0.3530\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2456 - mae: 0.3041 - val_loss: 0.2553 - val_mae: 0.3508\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2567 - mae: 0.3090 - val_loss: 0.2541 - val_mae: 0.3496\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2765 - mae: 0.3202 - val_loss: 0.2543 - val_mae: 0.3473\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2538 - mae: 0.3118 - val_loss: 0.2536 - val_mae: 0.3474\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2549 - mae: 0.3106 - val_loss: 0.2522 - val_mae: 0.3448\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2649 - mae: 0.3072 - val_loss: 0.2521 - val_mae: 0.3425\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2607 - mae: 0.3070 - val_loss: 0.2514 - val_mae: 0.3414\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2445 - mae: 0.3018 - val_loss: 0.2509 - val_mae: 0.3417\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2623 - mae: 0.2988 - val_loss: 0.2505 - val_mae: 0.3408\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2596 - mae: 0.3076 - val_loss: 0.2502 - val_mae: 0.3410\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2437 - mae: 0.3079 - val_loss: 0.2501 - val_mae: 0.3411\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2551 - mae: 0.3047 - val_loss: 0.2507 - val_mae: 0.3416\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2654 - mae: 0.3055 - val_loss: 0.2502 - val_mae: 0.3425\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2481 - mae: 0.2983 - val_loss: 0.2491 - val_mae: 0.3415\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2355 - mae: 0.2961 - val_loss: 0.2472 - val_mae: 0.3423\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2427 - mae: 0.3084 - val_loss: 0.2462 - val_mae: 0.3400\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2751 - mae: 0.3166 - val_loss: 0.2455 - val_mae: 0.3376\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2535 - mae: 0.3053 - val_loss: 0.2454 - val_mae: 0.3380\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2484 - mae: 0.2970 - val_loss: 0.2450 - val_mae: 0.3377\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2575 - mae: 0.3094 - val_loss: 0.2449 - val_mae: 0.3387\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2349 - mae: 0.3049 - val_loss: 0.2449 - val_mae: 0.3396\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2369 - mae: 0.2991 - val_loss: 0.2447 - val_mae: 0.3400\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2348 - mae: 0.3017 - val_loss: 0.2449 - val_mae: 0.3395\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2439 - mae: 0.3047 - val_loss: 0.2447 - val_mae: 0.3387\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2429 - mae: 0.2974 - val_loss: 0.2461 - val_mae: 0.3391\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2217 - mae: 0.2922 - val_loss: 0.2463 - val_mae: 0.3422\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2264 - mae: 0.2855 - val_loss: 0.2458 - val_mae: 0.3423\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2566 - mae: 0.3062 - val_loss: 0.2459 - val_mae: 0.3434\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2362 - mae: 0.2975 - val_loss: 0.2452 - val_mae: 0.3433\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2376 - mae: 0.3142 - val_loss: 0.2447 - val_mae: 0.3426\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2601 - mae: 0.3217 - val_loss: 0.2442 - val_mae: 0.3405\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2180 - mae: 0.2909 - val_loss: 0.2426 - val_mae: 0.3341\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2799 - mae: 0.3295 - val_loss: 0.2420 - val_mae: 0.3287\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2285 - mae: 0.2905 - val_loss: 0.2420 - val_mae: 0.3245\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2206 - mae: 0.2833 - val_loss: 0.2416 - val_mae: 0.3216\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2283 - mae: 0.2799 - val_loss: 0.2411 - val_mae: 0.3252\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2318 - mae: 0.2899 - val_loss: 0.2400 - val_mae: 0.3262\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2269 - mae: 0.2953 - val_loss: 0.2402 - val_mae: 0.3298\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2864 - mae: 0.3260 - val_loss: 0.2386 - val_mae: 0.3258\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2245 - mae: 0.2825 - val_loss: 0.2386 - val_mae: 0.3240\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2295 - mae: 0.2917 - val_loss: 0.2389 - val_mae: 0.3245\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2318 - mae: 0.2966 - val_loss: 0.2388 - val_mae: 0.3225\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2495 - mae: 0.3054 - val_loss: 0.2399 - val_mae: 0.3203\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2179 - mae: 0.2855 - val_loss: 0.2396 - val_mae: 0.3198\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2397 - mae: 0.2923 - val_loss: 0.2394 - val_mae: 0.3204\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2300 - mae: 0.2963 - val_loss: 0.2398 - val_mae: 0.3228\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2260 - mae: 0.2957 - val_loss: 0.2399 - val_mae: 0.3211\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2323 - mae: 0.2912 - val_loss: 0.2393 - val_mae: 0.3172\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2273 - mae: 0.2910 - val_loss: 0.2394 - val_mae: 0.3150\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2296 - mae: 0.2841 - val_loss: 0.2399 - val_mae: 0.3131\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2325 - mae: 0.2931 - val_loss: 0.2402 - val_mae: 0.3124\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2311 - mae: 0.2878 - val_loss: 0.2399 - val_mae: 0.3139\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2357 - mae: 0.2885 - val_loss: 0.2422 - val_mae: 0.3202\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2296 - mae: 0.2943 - val_loss: 0.2447 - val_mae: 0.3212\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2182 - mae: 0.2733 - val_loss: 0.2463 - val_mae: 0.3246\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2234 - mae: 0.2927 - val_loss: 0.2484 - val_mae: 0.3268\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2207 - mae: 0.2850 - val_loss: 0.2500 - val_mae: 0.3243\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2132 - mae: 0.2693 - val_loss: 0.2487 - val_mae: 0.3253\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2433 - mae: 0.2987 - val_loss: 0.2490 - val_mae: 0.3246\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2067 - mae: 0.2775 - val_loss: 0.2472 - val_mae: 0.3234\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2585 - mae: 0.3086 - val_loss: 0.2474 - val_mae: 0.3234\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2214 - mae: 0.2819 - val_loss: 0.2469 - val_mae: 0.3232\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2436 - mae: 0.2916 - val_loss: 0.2477 - val_mae: 0.3221\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2311 - mae: 0.2872 - val_loss: 0.2487 - val_mae: 0.3220\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2469 - mae: 0.2962 - val_loss: 0.2472 - val_mae: 0.3236\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2458 - mae: 0.2966 - val_loss: 0.2476 - val_mae: 0.3237\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2369 - mae: 0.2947 - val_loss: 0.2488 - val_mae: 0.3220\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2148 - mae: 0.2774 - val_loss: 0.2531 - val_mae: 0.3212\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2316 - mae: 0.2827 - val_loss: 0.2534 - val_mae: 0.3192\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2154 - mae: 0.2679 - val_loss: 0.2490 - val_mae: 0.3167\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2287 - mae: 0.2824 - val_loss: 0.2473 - val_mae: 0.3171\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2015 - mae: 0.2736 - val_loss: 0.2450 - val_mae: 0.3162\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2226 - mae: 0.2851 - val_loss: 0.2445 - val_mae: 0.3186\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2182 - mae: 0.2928 - val_loss: 0.2442 - val_mae: 0.3167\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1986 - mae: 0.2746 - val_loss: 0.2438 - val_mae: 0.3143\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2114 - mae: 0.2832 - val_loss: 0.2435 - val_mae: 0.3100\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2359 - mae: 0.2937 - val_loss: 0.2437 - val_mae: 0.3089\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2077 - mae: 0.2670 - val_loss: 0.2475 - val_mae: 0.3081\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2085 - mae: 0.2628 - val_loss: 0.2496 - val_mae: 0.3103\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2446 - mae: 0.2867 - val_loss: 0.2468 - val_mae: 0.3108\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2102 - mae: 0.2676 - val_loss: 0.2444 - val_mae: 0.3151\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2249 - mae: 0.2949 - val_loss: 0.2465 - val_mae: 0.3182\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1997 - mae: 0.2795 - val_loss: 0.2465 - val_mae: 0.3210\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2268 - mae: 0.2904 - val_loss: 0.2488 - val_mae: 0.3224\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3090 - mae: 0.3091\n",
      "Test Loss: 0.3090\n",
      "Test MAE: 0.3091\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.2540\n",
      "MSE: 0.3090\n",
      "MAE: 0.3091\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.4071 - mae: 0.9163 - val_loss: 2.3077 - val_mae: 0.9795\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.9834 - mae: 0.8478 - val_loss: 1.9777 - val_mae: 0.9246\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7700 - mae: 0.8317 - val_loss: 1.6882 - val_mae: 0.8557\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4582 - mae: 0.7396 - val_loss: 1.3937 - val_mae: 0.7734\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1946 - mae: 0.6629 - val_loss: 1.0800 - val_mae: 0.6777\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9373 - mae: 0.5794 - val_loss: 0.7738 - val_mae: 0.5666\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8237 - mae: 0.5300 - val_loss: 0.5146 - val_mae: 0.4501\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5379 - mae: 0.4256 - val_loss: 0.3146 - val_mae: 0.3230\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4169 - mae: 0.3820 - val_loss: 0.1981 - val_mae: 0.2081\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3512 - mae: 0.3391 - val_loss: 0.1642 - val_mae: 0.2181\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2857 - mae: 0.3126 - val_loss: 0.1597 - val_mae: 0.2330\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3611 - mae: 0.3279 - val_loss: 0.1556 - val_mae: 0.2356\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3659 - mae: 0.3357 - val_loss: 0.1426 - val_mae: 0.2176\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - mae: 0.3503 - val_loss: 0.1376 - val_mae: 0.1972\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3093 - mae: 0.3021 - val_loss: 0.1434 - val_mae: 0.1977\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2540 - mae: 0.2899 - val_loss: 0.1452 - val_mae: 0.2054\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2677 - mae: 0.2980 - val_loss: 0.1287 - val_mae: 0.1970\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2709 - mae: 0.2787 - val_loss: 0.1098 - val_mae: 0.1910\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2871 - mae: 0.2909 - val_loss: 0.0970 - val_mae: 0.1914\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3139 - mae: 0.3076 - val_loss: 0.0943 - val_mae: 0.1764\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3146 - mae: 0.2929 - val_loss: 0.1043 - val_mae: 0.1781\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2311 - mae: 0.2755 - val_loss: 0.1074 - val_mae: 0.1828\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2764 - mae: 0.2877 - val_loss: 0.1014 - val_mae: 0.1871\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2419 - mae: 0.2752 - val_loss: 0.0815 - val_mae: 0.1729\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2294 - mae: 0.2595 - val_loss: 0.0691 - val_mae: 0.1563\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2785 - mae: 0.2614 - val_loss: 0.0746 - val_mae: 0.1589\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2295 - mae: 0.2665 - val_loss: 0.1161 - val_mae: 0.2052\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2784 - mae: 0.2982 - val_loss: 0.1234 - val_mae: 0.2204\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2614 - mae: 0.2773 - val_loss: 0.0766 - val_mae: 0.1858\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2564 - mae: 0.2733 - val_loss: 0.0453 - val_mae: 0.1497\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2406 - mae: 0.2800 - val_loss: 0.0381 - val_mae: 0.1318\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2235 - mae: 0.2570 - val_loss: 0.0510 - val_mae: 0.1499\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1489 - mae: 0.2152 - val_loss: 0.0468 - val_mae: 0.1377\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1376 - mae: 0.1958 - val_loss: 0.0399 - val_mae: 0.1271\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1635 - mae: 0.2160 - val_loss: 0.0313 - val_mae: 0.1179\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1964 - mae: 0.2424 - val_loss: 0.0415 - val_mae: 0.1481\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1659 - mae: 0.2175 - val_loss: 0.0560 - val_mae: 0.1660\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1558 - mae: 0.2144 - val_loss: 0.0506 - val_mae: 0.1525\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1760 - mae: 0.2332 - val_loss: 0.0380 - val_mae: 0.1318\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1351 - mae: 0.2075 - val_loss: 0.0360 - val_mae: 0.1253\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1324 - mae: 0.2032 - val_loss: 0.0493 - val_mae: 0.1432\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0973 - mae: 0.1603 - val_loss: 0.0638 - val_mae: 0.1624\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1673 - mae: 0.2244 - val_loss: 0.0776 - val_mae: 0.1781\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1872 - mae: 0.2243 - val_loss: 0.0712 - val_mae: 0.1738\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1660 - mae: 0.2225 - val_loss: 0.0401 - val_mae: 0.1363\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1373 - mae: 0.2064 - val_loss: 0.0265 - val_mae: 0.1104\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1956 - mae: 0.2484 - val_loss: 0.0251 - val_mae: 0.1069\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1299 - mae: 0.1954 - val_loss: 0.0256 - val_mae: 0.1037\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1554 - mae: 0.2052 - val_loss: 0.0301 - val_mae: 0.1161\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1042 - mae: 0.1760 - val_loss: 0.0424 - val_mae: 0.1385\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0819 - mae: 0.1647 - val_loss: 0.0426 - val_mae: 0.1406\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1868 - mae: 0.2110 - val_loss: 0.0512 - val_mae: 0.1516\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1496 - mae: 0.2006 - val_loss: 0.0574 - val_mae: 0.1571\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2242 - mae: 0.2289 - val_loss: 0.0533 - val_mae: 0.1494\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1550 - mae: 0.2018 - val_loss: 0.0396 - val_mae: 0.1268\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1726 - mae: 0.2037 - val_loss: 0.0335 - val_mae: 0.1129\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1371 - mae: 0.2072 - val_loss: 0.0353 - val_mae: 0.1207\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2032 - mae: 0.2342 - val_loss: 0.0332 - val_mae: 0.1205\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1134 - mae: 0.1835 - val_loss: 0.0349 - val_mae: 0.1257\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0698 - mae: 0.1391 - val_loss: 0.0423 - val_mae: 0.1362\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1194 - mae: 0.1939 - val_loss: 0.0548 - val_mae: 0.1512\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1472 - mae: 0.1854 - val_loss: 0.0580 - val_mae: 0.1561\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1784 - mae: 0.2153 - val_loss: 0.0493 - val_mae: 0.1480\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2024 - mae: 0.2350 - val_loss: 0.0366 - val_mae: 0.1313\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1414 - mae: 0.1943 - val_loss: 0.0351 - val_mae: 0.1174\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1549 - mae: 0.2148 - val_loss: 0.0424 - val_mae: 0.1278\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2183 - mae: 0.2228 - val_loss: 0.0373 - val_mae: 0.1176\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1356 - mae: 0.2061 - val_loss: 0.0562 - val_mae: 0.1523\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1104 - mae: 0.1834 - val_loss: 0.0656 - val_mae: 0.1689\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1212 - mae: 0.1951 - val_loss: 0.0507 - val_mae: 0.1534\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1042 - mae: 0.1597 - val_loss: 0.0313 - val_mae: 0.1218\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1555 - mae: 0.2179 - val_loss: 0.0283 - val_mae: 0.1071\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1331 - mae: 0.1914 - val_loss: 0.0295 - val_mae: 0.1107\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1587 - mae: 0.2167 - val_loss: 0.0320 - val_mae: 0.1170\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1634 - mae: 0.2115 - val_loss: 0.0318 - val_mae: 0.1194\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1112 - mae: 0.1876 - val_loss: 0.0284 - val_mae: 0.1083\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1170 - mae: 0.1794 - val_loss: 0.0271 - val_mae: 0.1092\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1123 - mae: 0.1795 - val_loss: 0.0266 - val_mae: 0.1105\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1440 - mae: 0.1968 - val_loss: 0.0274 - val_mae: 0.1120\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1266 - mae: 0.1898 - val_loss: 0.0284 - val_mae: 0.1096\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1441 - mae: 0.1718 - val_loss: 0.0290 - val_mae: 0.1026\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1138 - mae: 0.1750 - val_loss: 0.0295 - val_mae: 0.0978\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0992 - mae: 0.1602 - val_loss: 0.0290 - val_mae: 0.1022\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1652 - mae: 0.2149 - val_loss: 0.0287 - val_mae: 0.1060\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1254 - mae: 0.1898 - val_loss: 0.0289 - val_mae: 0.1051\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1118 - mae: 0.1803 - val_loss: 0.0288 - val_mae: 0.1093\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1086 - mae: 0.1797 - val_loss: 0.0332 - val_mae: 0.1293\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0834 - mae: 0.1721 - val_loss: 0.0367 - val_mae: 0.1338\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1734 - mae: 0.1970 - val_loss: 0.0308 - val_mae: 0.1166\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1347 - mae: 0.1813 - val_loss: 0.0311 - val_mae: 0.1011\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1022 - mae: 0.1756 - val_loss: 0.0338 - val_mae: 0.1007\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1001 - mae: 0.1751 - val_loss: 0.0323 - val_mae: 0.1097\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1470 - mae: 0.1952 - val_loss: 0.0360 - val_mae: 0.1268\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1904 - mae: 0.2235 - val_loss: 0.0439 - val_mae: 0.1474\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1165 - mae: 0.1752 - val_loss: 0.0458 - val_mae: 0.1517\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1803 - mae: 0.2044 - val_loss: 0.0343 - val_mae: 0.1276\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1094 - mae: 0.1705 - val_loss: 0.0330 - val_mae: 0.1178\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1034 - mae: 0.1690 - val_loss: 0.0417 - val_mae: 0.1353\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0822 - mae: 0.1602 - val_loss: 0.0445 - val_mae: 0.1386\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1119 - mae: 0.1742 - val_loss: 0.0376 - val_mae: 0.1267\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0084 - mae: 0.0628\n",
      "Test Loss: 0.0084\n",
      "Test MAE: 0.0628\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Score: 0.9937\n",
      "MSE: 0.0084\n",
      "MAE: 0.0628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6770 - mae: 0.3658 - val_loss: 1.0156 - val_mae: 0.4950\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6119 - mae: 0.3687 - val_loss: 0.9492 - val_mae: 0.5079\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5705 - mae: 0.3747 - val_loss: 0.8939 - val_mae: 0.5221\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5313 - mae: 0.3850 - val_loss: 0.8501 - val_mae: 0.5333\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4894 - mae: 0.3898 - val_loss: 0.8199 - val_mae: 0.5434\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4637 - mae: 0.3833 - val_loss: 0.8063 - val_mae: 0.5504\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4318 - mae: 0.4037 - val_loss: 0.8056 - val_mae: 0.5536\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4368 - mae: 0.4012 - val_loss: 0.8116 - val_mae: 0.5616\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4112 - mae: 0.3882 - val_loss: 0.8196 - val_mae: 0.5696\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4474 - mae: 0.4209 - val_loss: 0.8237 - val_mae: 0.5675\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4564 - mae: 0.4022 - val_loss: 0.8251 - val_mae: 0.5598\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4140 - mae: 0.3779 - val_loss: 0.8205 - val_mae: 0.5476\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4264 - mae: 0.3775 - val_loss: 0.8210 - val_mae: 0.5426\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4242 - mae: 0.3692 - val_loss: 0.8232 - val_mae: 0.5402\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4265 - mae: 0.3676 - val_loss: 0.8221 - val_mae: 0.5348\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4522 - mae: 0.3729 - val_loss: 0.8212 - val_mae: 0.5331\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4577 - mae: 0.3866 - val_loss: 0.8216 - val_mae: 0.5328\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3900 - mae: 0.3433 - val_loss: 0.8236 - val_mae: 0.5328\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4665 - mae: 0.3801 - val_loss: 0.8239 - val_mae: 0.5296\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4206 - mae: 0.3500 - val_loss: 0.8251 - val_mae: 0.5262\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4564 - mae: 0.3734 - val_loss: 0.8257 - val_mae: 0.5216\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4263 - mae: 0.3662 - val_loss: 0.8296 - val_mae: 0.5241\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3991 - mae: 0.3564 - val_loss: 0.8337 - val_mae: 0.5302\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3814 - mae: 0.3445 - val_loss: 0.8379 - val_mae: 0.5436\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4260 - mae: 0.3832 - val_loss: 0.8402 - val_mae: 0.5499\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5031 - mae: 0.4014 - val_loss: 0.8388 - val_mae: 0.5451\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3935 - mae: 0.3527 - val_loss: 0.8390 - val_mae: 0.5468\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3843 - mae: 0.3599 - val_loss: 0.8417 - val_mae: 0.5496\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4473 - mae: 0.3763 - val_loss: 0.8428 - val_mae: 0.5480\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3861 - mae: 0.3597 - val_loss: 0.8452 - val_mae: 0.5488\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4028 - mae: 0.3682 - val_loss: 0.8465 - val_mae: 0.5496\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4081 - mae: 0.3825 - val_loss: 0.8498 - val_mae: 0.5539\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4268 - mae: 0.3794 - val_loss: 0.8507 - val_mae: 0.5548\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4248 - mae: 0.3652 - val_loss: 0.8503 - val_mae: 0.5499\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4006 - mae: 0.3673 - val_loss: 0.8475 - val_mae: 0.5511\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4057 - mae: 0.3578 - val_loss: 0.8529 - val_mae: 0.5586\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4179 - mae: 0.3764 - val_loss: 0.8539 - val_mae: 0.5565\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4142 - mae: 0.3653 - val_loss: 0.8500 - val_mae: 0.5473\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4318 - mae: 0.3699 - val_loss: 0.8489 - val_mae: 0.5409\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4416 - mae: 0.3589 - val_loss: 0.8497 - val_mae: 0.5363\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3801 - mae: 0.3428 - val_loss: 0.8490 - val_mae: 0.5406\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4085 - mae: 0.3517 - val_loss: 0.8470 - val_mae: 0.5445\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4420 - mae: 0.3659 - val_loss: 0.8488 - val_mae: 0.5524\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3971 - mae: 0.3579 - val_loss: 0.8502 - val_mae: 0.5554\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4314 - mae: 0.3946 - val_loss: 0.8511 - val_mae: 0.5565\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3820 - mae: 0.3572 - val_loss: 0.8518 - val_mae: 0.5544\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4786 - mae: 0.3948 - val_loss: 0.8521 - val_mae: 0.5550\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4681 - mae: 0.3806 - val_loss: 0.8476 - val_mae: 0.5500\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3998 - mae: 0.3535 - val_loss: 0.8423 - val_mae: 0.5438\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4655 - mae: 0.3849 - val_loss: 0.8406 - val_mae: 0.5435\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4021 - mae: 0.3684 - val_loss: 0.8429 - val_mae: 0.5456\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3690 - mae: 0.3566 - val_loss: 0.8465 - val_mae: 0.5473\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3834 - mae: 0.3616 - val_loss: 0.8517 - val_mae: 0.5541\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3946 - mae: 0.3624 - val_loss: 0.8566 - val_mae: 0.5530\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4589 - mae: 0.3853 - val_loss: 0.8583 - val_mae: 0.5536\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3912 - mae: 0.3619 - val_loss: 0.8610 - val_mae: 0.5534\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3818 - mae: 0.3539 - val_loss: 0.8546 - val_mae: 0.5491\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3870 - mae: 0.3655 - val_loss: 0.8533 - val_mae: 0.5558\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4478 - mae: 0.3871 - val_loss: 0.8462 - val_mae: 0.5507\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3595 - mae: 0.3519 - val_loss: 0.8410 - val_mae: 0.5405\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3729 - mae: 0.3496 - val_loss: 0.8418 - val_mae: 0.5388\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4382 - mae: 0.3846 - val_loss: 0.8466 - val_mae: 0.5446\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4130 - mae: 0.3688 - val_loss: 0.8503 - val_mae: 0.5401\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3805 - mae: 0.3424 - val_loss: 0.8596 - val_mae: 0.5389\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3780 - mae: 0.3339 - val_loss: 0.8703 - val_mae: 0.5434\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4446 - mae: 0.3690 - val_loss: 0.8714 - val_mae: 0.5479\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4010 - mae: 0.3630 - val_loss: 0.8631 - val_mae: 0.5450\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3848 - mae: 0.3422 - val_loss: 0.8543 - val_mae: 0.5409\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4122 - mae: 0.3588 - val_loss: 0.8496 - val_mae: 0.5472\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4014 - mae: 0.3632 - val_loss: 0.8442 - val_mae: 0.5618\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3749 - mae: 0.3690 - val_loss: 0.8468 - val_mae: 0.5618\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3880 - mae: 0.3625 - val_loss: 0.8545 - val_mae: 0.5492\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3667 - mae: 0.3409 - val_loss: 0.8657 - val_mae: 0.5348\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3928 - mae: 0.3510 - val_loss: 0.8732 - val_mae: 0.5356\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4157 - mae: 0.3488 - val_loss: 0.8626 - val_mae: 0.5393\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4112 - mae: 0.3522 - val_loss: 0.8546 - val_mae: 0.5549\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4273 - mae: 0.3814 - val_loss: 0.8435 - val_mae: 0.5427\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3963 - mae: 0.3606 - val_loss: 0.8426 - val_mae: 0.5396\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4136 - mae: 0.3596 - val_loss: 0.8439 - val_mae: 0.5291\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3993 - mae: 0.3453 - val_loss: 0.8385 - val_mae: 0.5437\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3896 - mae: 0.3581 - val_loss: 0.8392 - val_mae: 0.5497\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3991 - mae: 0.3695 - val_loss: 0.8401 - val_mae: 0.5505\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3823 - mae: 0.3670 - val_loss: 0.8444 - val_mae: 0.5526\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3775 - mae: 0.3501 - val_loss: 0.8457 - val_mae: 0.5485\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3395 - mae: 0.3248 - val_loss: 0.8449 - val_mae: 0.5458\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3992 - mae: 0.3639 - val_loss: 0.8375 - val_mae: 0.5489\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3619 - mae: 0.3374 - val_loss: 0.8310 - val_mae: 0.5397\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4137 - mae: 0.3778 - val_loss: 0.8288 - val_mae: 0.5406\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4276 - mae: 0.3752 - val_loss: 0.8307 - val_mae: 0.5434\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4259 - mae: 0.3811 - val_loss: 0.8320 - val_mae: 0.5286\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3962 - mae: 0.3411 - val_loss: 0.8345 - val_mae: 0.5260\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3286 - mae: 0.3087 - val_loss: 0.8368 - val_mae: 0.5320\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3614 - mae: 0.3403 - val_loss: 0.8364 - val_mae: 0.5523\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3769 - mae: 0.3713 - val_loss: 0.8391 - val_mae: 0.5547\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4295 - mae: 0.3912 - val_loss: 0.8373 - val_mae: 0.5474\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3560 - mae: 0.3439 - val_loss: 0.8289 - val_mae: 0.5303\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4367 - mae: 0.3546 - val_loss: 0.8254 - val_mae: 0.5198\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4171 - mae: 0.3485 - val_loss: 0.8281 - val_mae: 0.5161\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4011 - mae: 0.3390 - val_loss: 0.8278 - val_mae: 0.5177\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3431 - mae: 0.3312 - val_loss: 0.8277 - val_mae: 0.5277\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5077 - mae: 0.3681\n",
      "Test Loss: 0.5077\n",
      "Test MAE: 0.3681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "R^2 Score: 0.3716\n",
      "MSE: 0.5077\n",
      "MAE: 0.3681\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # y is the last column in the dataset\n",
    "    y = dataset.iloc[:, -1]\n",
    "    X = dataset.iloc[:, :-1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Dimensionality Reduction\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # convert back to a dataframe\n",
    "    X_train_pca = pd.DataFrame(X_train_pca)\n",
    "    X_test_pca = pd.DataFrame(X_test_pca)\n",
    "\n",
    "    # split training data into training and validation data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_pca, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = NN_model(X_train, y_train, X_val, y_val, X_test_pca, y_test)\n",
    "\n",
    "    y_predicted[dataset.columns[-1]] = model.predict(X_test_pca).flatten()\n",
    "    y_truth[dataset.columns[-1]] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.639973</td>\n",
       "      <td>6.241774</td>\n",
       "      <td>0.941666</td>\n",
       "      <td>0.830453</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.414972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.473408</td>\n",
       "      <td>5.801205</td>\n",
       "      <td>0.087066</td>\n",
       "      <td>0.071283</td>\n",
       "      <td>0.021768</td>\n",
       "      <td>0.034079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.326695</td>\n",
       "      <td>6.053002</td>\n",
       "      <td>0.077514</td>\n",
       "      <td>0.087387</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>0.231419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.522985</td>\n",
       "      <td>18.556988</td>\n",
       "      <td>0.031337</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>3.682764</td>\n",
       "      <td>-0.010527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.298193</td>\n",
       "      <td>2.921015</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.881406</td>\n",
       "      <td>0.037265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      12.639973       6.241774       0.941666       0.830453       0.025640   \n",
       "1       8.473408       5.801205       0.087066       0.071283       0.021768   \n",
       "2       4.326695       6.053002       0.077514       0.087387       0.025963   \n",
       "3      19.522985      18.556988       0.031337       0.012789       3.682764   \n",
       "4       4.298193       2.921015       0.030391       0.047471       0.881406   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0       0.414972  \n",
       "1       0.034079  \n",
       "2       0.231419  \n",
       "3      -0.010527  \n",
       "4       0.037265  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <th>Formate (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.739658</td>\n",
       "      <td>40.735563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.91524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.660000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose (g/L)  Lactate (g/L)  Ethanol (g/L)  Acetate (g/L)  Biomass (g/L)  \\\n",
       "0      30.000000      25.000000            0.5            2.0        0.00000   \n",
       "1      50.000000       0.000000            0.0            0.0        0.00000   \n",
       "2       0.000000       0.000000            0.0            1.5        0.00000   \n",
       "3      34.739658      40.735563            0.0            0.0        3.91524   \n",
       "4       8.660000       2.180000            0.0            0.0        0.72000   \n",
       "\n",
       "   Formate (g/L)  \n",
       "0            1.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33809704738378416"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for all target variables\n",
    "r2 = r2_score(y_truth, y_predicted)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <td>0.069825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <td>0.182412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethanol (g/L)</th>\n",
       "      <td>0.157033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acetate (g/L)</th>\n",
       "      <td>0.253995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomass (g/L)</th>\n",
       "      <td>0.993745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formate (g/L)</th>\n",
       "      <td>0.371572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R^2 Score\n",
       "Glucose (g/L)   0.069825\n",
       "Lactate (g/L)   0.182412\n",
       "Ethanol (g/L)   0.157033\n",
       "Acetate (g/L)   0.253995\n",
       "Biomass (g/L)   0.993745\n",
       "Formate (g/L)   0.371572"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 score for each target variable\n",
    "r2 = r2_score(y_truth, y_predicted, multioutput='raw_values')\n",
    "\n",
    "# convert to a dataframe\n",
    "r2 = pd.DataFrame(r2, index=target.columns, columns=['R^2 Score'])\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined r2 score is: **0.42913293043177275** [1]\n",
    "\n",
    "The combined r2 score is: **0.35816286323129254** [2]\n",
    "\n",
    "The combined r2 score is: **0.2843934946185081** [3]\n",
    "\n",
    "### The combined r2 score is: **0.33809704738378416** [curr]\n",
    "\n",
    "Which is an average score. Worse than previous models.\n",
    "\n",
    "BUT\n",
    "\n",
    "Individually for each target variable, the r2 score has high variability. With Biomass being predicted most accurately with a score of ***0.993745***, and acetate being predicted most poorly with a score of 0.069825."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
